{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EC2 Auto Scaling?"}, {"role": "assistant", "content": "Amazon EC2 Auto Scaling is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. Amazon EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use Amazon EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. When should I use Amazon EC2 Auto Scaling vs. AWS Auto Scaling?"}, {"role": "assistant", "content": "You should use AWS Auto Scaling to manage scaling for multiple resources across multiple services. AWS Auto Scaling lets you define dynamic scaling policies for multiple EC2 Auto Scaling groups or other resources using predefined scaling strategies. Using AWS Auto Scaling to configure scaling policies for all of the scalable resources in your application is faster than managing scaling policies for each resource via its individual service console. It\u2019s also easier, as AWS Auto Scaling includes predefined scaling strategies that simplify the setup of scaling policies.\u00a0You should use EC2 Auto Scaling if you only need to scale Amazon EC2 Auto Scaling groups, or if you are only interested in maintaining the health of your EC2 fleet. You should also use EC2 Auto Scaling if you need to create or configure Amazon EC2 Auto Scaling groups, or if you need to set up scheduled or step scaling policies (as AWS Auto Scaling supports only target tracking scaling policies).EC2 Auto Scaling groups must be created and configured outside of AWS Auto Scaling, such as through the EC2 console, Auto Scaling API or via CloudFormation. AWS Auto Scaling can help you configure dynamic scaling policies for your existing EC2 Auto Scaling groups."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is Predictive Scaling Policy different from Predictive Scaling of AWS Auto Scaling plan?"}, {"role": "assistant", "content": "Predictive Scaling Policy brings the similar prediction algorithm offered through AWS Auto Scaling plan as a native scaling policy in EC2 Auto Scaling. You can use predictive scaling directly through AWS Command Line Interface (CLI), EC2 Auto Scaling Management Console, and AWS SDKs similar to how you use other scaling policies, such as Simple Scaling or Target Tracking etc. You don\u2019t have to create an AWS Auto Scaling plan just for using predictive scaling."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the benefits of using Amazon EC2 Auto Scaling?"}, {"role": "assistant", "content": "Amazon EC2 Auto Scaling helps to maintain your Amazon EC2 instance availability. Whether you are running one Amazon EC2 instance or thousands, you can use Amazon EC2 Auto Scaling to detect impaired Amazon EC2 instances, and replace the instances without intervention. This ensures that your application has the compute capacity that you expect. You can use Amazon EC2 Auto Scaling to automatically scale your Amazon EC2 fleet by following the demand curve for your applications, reducing the need to manually provision Amazon EC2 capacity in advance. For example, you can set a condition to add new Amazon EC2 instances in increments to the ASG when the average utilization of your Amazon EC2 fleet is high; and similarly, you can set a condition to remove instances in increments when CPU utilization is low. You can also use Amazon CloudWatch to send alarms to trigger scaling activities and Elastic Load Balancing (ELB) to distribute traffic to your instances within the ASG. If you have predictable load changes, you can use Predictive Scaling policy to proactively increase capacity ahead of upcoming demand. Amazon EC2 Auto Scaling enables you to run your Amazon EC2 fleet at optimal utilization."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is fleet management and how is it different from dynamic scaling?"}, {"role": "assistant", "content": "If your application runs on Amazon EC2 instances, then you have what\u2019s referred to as a \u2018fleet\u2019. Fleet management refers to the functionality that automatically replaces unhealthy instances and maintains your fleet at the desired capacity. Amazon EC2 Auto Scaling fleet management ensures that your application is able to receive traffic and that the instances themselves are working properly. When Auto Scaling detects a failed [health check](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html), it can replace the instance automatically.The dynamic scaling capabilities of Amazon EC2 Auto Scaling refers to the functionality that automatically increases or decreases capacity based on load or other metrics. For example, if your CPU spikes above 80% (and you have an alarm setup)\u00a0Amazon EC2 Auto Scaling can add a new instance dynamically."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is target tracking?"}, {"role": "assistant", "content": "Target tracking is a new type of scaling policy that you can use to set up dynamic scaling for your application in just a few simple steps. With target tracking, you select a load metric for your application, such as CPU utilization or request count, set the target value, and Amazon EC2 Auto Scaling adjusts the number of EC2 instances in your ASG as needed to maintain that target. It acts like a home thermostat, automatically adjusting the system to keep the environment at your desired temperature. For example, you can configure target tracking to keep CPU utilization for your fleet of web servers at 50%. From there, Amazon EC2 Auto Scaling launches or terminates EC2 instances as required to keep the average CPU utilization at 50%."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an EC2 Auto Scaling group (ASG)?"}, {"role": "assistant", "content": "An Amazon EC2 Auto Scaling group (ASG) contains a collection of EC2 instances that share similar characteristics and are treated as a logical grouping for the purposes of fleet management and dynamic scaling. For example, if a single application operates across multiple instances, you might want to increase the number of instances in that group to improve the performance of the application, or decrease the number of instances to reduce costs when demand is low. Amazon EC2 Auto Scaling will automaticallly adjust the number of instances in the group to maintain a fixed number of instances even if a instance becomes unhealthy, or based on criteria that you specify. You can find more information about ASG in the [Amazon EC2 Auto Scaling User Guide](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens to my Amazon EC2 instances if I delete my ASG?"}, {"role": "assistant", "content": "If you have an EC2 Auto Scaling group (ASG) with running instances and you choose to delete the ASG, the instances will be terminated and the ASG will be deleted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I know when EC2 Auto Scaling is launching or terminating the EC2 instances in an EC2 Auto Scaling group?"}, {"role": "assistant", "content": "When you use Amazon EC2 Auto Scaling to scale your applications automatically, it is useful to know when EC2 Auto Scaling is launching or terminating the EC2 instances in your EC2 Auto Scaling group. [Amazon SNS](https://web.archive.org/web/20240727090427/https://aws.amazon.com/sns/) coordinates and manages the delivery or sending of notifications to subscribing clients or endpoints. You can configure EC2 Auto Scaling to send an SNS notification whenever your EC2 Auto Scaling group scales. Amazon SNS can deliver notifications as HTTP or HTTPS POST, email (SMTP, either plain-text or in JSON format), or as a message posted to an Amazon SQS queue. For example, if you configure your EC2 Auto Scaling group to use the autoscaling: EC2_INSTANCE_TERMINATE notification type, and your EC2 Auto Scaling group terminates an instance, it sends an email notification. This email contains the details of the terminated instance, such as the instance ID and the reason that the instance was terminated.  For more information read\u00a0[Getting SNS Notifications when your EC2 Auto Scaling Group Scales](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/latest/userguide/ASGettingNotifications.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a launch configuration?"}, {"role": "assistant", "content": "A launch configuration is a template that an EC2 Auto Scaling group uses to launch EC2 instances. When you create a launch configuration, you specify information for the instances such as the ID of the Amazon Machine Image (AMI), the instance type, a key pair, one or more security groups, and a block device mapping. If you've launched an EC2 instance before, you specified the same information in order to launch the instance. When you create an EC2 Auto Scaling group, you must specify a launch configuration. You can specify your launch configuration with multiple EC2 Auto Scaling groups. However, you can only specify one launch configuration for an EC2 Auto Scaling group at a time, and you can't modify a launch configuration after you've created it. Therefore, if you want to change the launch configuration for your EC2 Auto Scaling group, you must create a launch configuration and then update your EC2 Auto Scaling group with the new launch configuration. When you change the launch configuration for your EC2 Auto Scaling group, any new instances are launched using the new configuration parameters, but existing instances are not affected. You can see the [launch configurations](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/ec2/userguide/LaunchConfiguration.html) section of the EC2 Auto Scaling User Guide for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many instances can an EC2 Auto Scaling group have?"}, {"role": "assistant", "content": "You can have as many instances in your EC2 Auto Scaling group as your EC2 quota allows."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if a scaling activity causes me to reach my Amazon EC2 limit of instances?"}, {"role": "assistant", "content": "Amazon EC2 Auto Scaling cannot scale past the Amazon EC2 limit of instances that you can run. If you need more Amazon EC2 instances, complete the [Amazon EC2 instance request form](https://web.archive.org/web/20240727090427/https://aws.amazon.com/contact-us/ec2-request/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can EC2 Auto Scaling groups span multiple AWS regions?"}, {"role": "assistant", "content": "EC2 Auto Scaling groups are regional constructs. They can span Availability Zones, but not AWS regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I implement changes across multiple instances in an EC2 Auto Scaling group?"}, {"role": "assistant", "content": "You can use AWS CodeDeploy or CloudFormation to orchestrate code changes to multiple instances in your EC2 Auto Scaling group."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I have data installed in an EC2 Auto Scaling group, and a new instance is dynamically created later, is the data copied over to the new instances?"}, {"role": "assistant", "content": "Data is not automatically copied from existing instances to new instances. You can use [lifecycle hooks](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/latest/userguide/lifecycle-hooks.html) to copy the data, or an [Amazon RDS](https://web.archive.org/web/20240727090427/https://aws.amazon.com/rds/) database including replicas."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When I create an EC2 Auto Scaling group from an existing instance, does it create a new AMI (Amazon Machine Image)?"}, {"role": "assistant", "content": "When you create an Auto Scaling group from an existing instance, it does not create a new AMI. For more information see [Creating an Auto Scaling Group Using an EC2 Instance](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/latest/userguide/create-asg-from-instance.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does Amazon EC2 Auto Scaling balance capacity?"}, {"role": "assistant", "content": "Balancing resources across [Availability Zones](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html) is a best practice for well-architected applications, as this greatly increases aggregate system availability. Amazon EC2 Auto Scaling automatically balances EC2 instances across zones when you [configure multiple zones](https://web.archive.org/web/20240727090427/http://docs.aws.amazon.com/autoscaling/latest/userguide/as-add-availability-zone.html) in your EC2 Auto Scaling group settings. Amazon EC2 Auto Scaling always launches new instances such that they are balanced between zones as evenly as possible across the entire fleet. What\u2019s more, Amazon EC2 Auto Scaling only launches into Availability Zones in which there is available capacity for the requested instance type."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are lifecycle hooks?"}, {"role": "assistant", "content": "Lifecycle hooks let you take action before an instance goes into service or before it gets terminated. This can be especially useful if you are not baking your software environment into an Amazon Machine Image (AMI). For example, launch hooks can perform software configuration on an instance to ensure that it\u2019s fully prepared to handle traffic before Amazon EC2 Auto Scaling proceeds to connect it to your load balancer. One way to do this is by connecting the launch hook to an AWS Lambda function that invokes RunCommand on the instance. Terminate hooks can be useful for collecting important data from an instance before it goes away. For example, you could use a terminate hook to preserve your fleet\u2019s log files by copying them to an Amazon S3 bucket when instances go out of service.Visit [lifecycle hooks](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/ec2/userguide/lifecycle-hooks.html) in our Amazon EC2 Auto Scaling User Guide for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the characteristics of an \u201cunhealthy\u201d instance?"}, {"role": "assistant", "content": "An unhealthy instance is one where the hardware has become impaired for some reason (bad disk, etc.), or it is not passing a user-configured ELB health check. Amazon EC2 Auto Scaling performs [health checks](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html) on each individual EC2 instance at regular intervals, and if the instance is connected to an Elastic Load Balancing load balancer, it can also perform [ELB health checks](https://web.archive.org/web/20240727090427/http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I customize a health check?"}, {"role": "assistant", "content": "Yes, there is an API called SetInstanceHealth that allows you to change an instance's state to UNHEALTHY, which will then result in a termination and replacement."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I suspend health checks (for example, to evaluate unhealthy instances)?"}, {"role": "assistant", "content": "Yes, you can temporarily suspend Amazon EC2 Auto Scaling health checks by using the SuspendProcesses API. You can use the ResumeProcesses API to resume automatic health checks."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which health check type should I select?"}, {"role": "assistant", "content": "If you are using Elastic Load Balancing (ELB) with your group, you should select an ELB health check. If you\u2019re not using ELB with your group, you should select the EC2 health check."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Amazon EC2 Auto Scaling for health checks and to replace unhealthy instances if I\u2019m not using Elastic Load Balancing (ELB)?"}, {"role": "assistant", "content": "You don't have to use ELB to use Auto Scaling. You can use the EC2 health check to identify and replace unhealthy instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do the Elastic Load Balancing (ELB) health checks work with Application Load Balancers and Network Load Balancers? Will an instance be marked as unhealthy if any target group associated with it becomes unhealthy?"}, {"role": "assistant", "content": "Yes, Amazon EC2 Auto Scaling works with Application Load Balancers and Network Load Balancers including their health check feature."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there any way to use Amazon EC2 Auto Scaling to only add a volume without adding an instance?"}, {"role": "assistant", "content": "A volume is attached to a new instance when it is added. Amazon EC2 Auto Scaling doesn't automatically add a volume when the existing one is approaching capacity. You can use the EC2 API to add a volume to an existing instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does the term \u201cstateful instances\u201d refer to?"}, {"role": "assistant", "content": "When we refer to a stateful instance, we mean an instance that has data on it, which exists only on that instance. In general, terminating a stateful instance means that the data (or state information) on the instance is lost. You may want to consider using lifecycle hooks to copy the data off of a stateful instance before it\u2019s terminated, or enable instance protection to prevent Amazon EC2 Auto Scaling from terminating it."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does Amazon EC2 Auto Scaling replace an impaired instance?"}, {"role": "assistant", "content": "When an impaired instance fails a health check, Amazon EC2 Auto Scaling automatically terminates it and replaces it with a new one. If you\u2019re using an Elastic Load Balancing load balancer, Amazon EC2 Auto Scaling gracefully detaches the impaired instance from the load balancer before provisioning a new one and attaching it to the load balancer. This is all done automatically, so you don\u2019t need to respond manually when an instance needs replacing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I control which instances Amazon EC2 Auto Scaling terminates when scaling in, and how do I protect data on an instance?"}, {"role": "assistant", "content": "With each Amazon EC2 Auto Scaling group, you control when Amazon EC2 Auto Scaling adds instances (referred to as scaling out) or remove instances (referred to as scaling in) from your group. You can scale the size of your group manually by attaching and detaching instances, or you can automate the process through the use of a scaling policy. When you have Amazon EC2 Auto Scaling automatically scale in, you must decide which instances Amazon EC2 Auto Scaling should terminate first. You can configure this through the use of a termination policy. You can also use instance protection to prevent Amazon EC2 Auto Scaling from selecting specific instances for termination when scaling in. If you have data on an instance, and you need that data to be persistent even if your instance is scaled in, then you can use a service like S3, RDS, or DynamoDB, to make sure that it is stored off the instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long is the turn-around time for Amazon EC2 Auto Scaling to spin up a new instance at inService state after detecting an unhealthy server?"}, {"role": "assistant", "content": "The turnaround time is within minutes. The majority of replacements happen within less than 5 minutes, and on average it is significantly less than 5 minutes. It depends on a variety of factors, including how long it takes to boot up the AMI of your instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If Elastic Load Balancing (ELB) determines that an instance is unhealthy, and moved offline, will the previous requests sent to the failed instance be queued and rerouted to other instances within the group?"}, {"role": "assistant", "content": "When ELB notices that the instance is unhealthy, it will stop routing requests to it. However, prior to discovering that the instance is unhealthy, some requests to that instance will fail."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If you don\u2019t use Elastic Load Balancing (ELB) how would users be directed to the other servers in a group if there was a failure?"}, {"role": "assistant", "content": "You can integrate with Route53 (which Amazon EC2 Auto Scaling does not currently support out of the box, but many customers use). You can also use your own reverse proxy, or for internal microservices, can use service discovery solutions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I control access to Amazon EC2 Auto Scaling resources?"}, {"role": "assistant", "content": "Amazon EC2 Auto Scaling integrates with [AWS Identity and Access Management](https://web.archive.org/web/20240727090427/https://aws.amazon.com/iam/) (IAM), a service that enables you to do the following:Create users and groups under your organization's AWS accountAssign unique security credentials to each user under your AWS accountControl each user's permissions to perform tasks using AWS resourcesAllow the users in another AWS account to share your AWS resourcesCreate roles for your AWS account and define the users or services that can assume themUse existing identities for your enterprise to grant permissions to perform tasks using AWS resourcesFor example, you could create an IAM policy that grants the Managers group permission to use only the DescribeAutoScalingGroups, DescribeLaunchConfigurations, DescribeScalingActivities, and DescribePolicies API operations. Users in the Managers group could then use those operations with any Amazon EC2 Auto Scaling groups and launch configurations. With Amazon EC2 Auto Scaling resource-level permissions, you can restrict access to a particular EC2 Auto Scaling group or launch configuration.For more information, see the [Controlling Access to Your Auto Scaling Resources](https://web.archive.org/web/20240727090427/https://docs.aws.amazon.com/autoscaling/latest/userguide/control-access-using-iam.html) section of the Amazon EC2 Auto Scaling user guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you define a default admin password on Windows instances with Amazon EC2 Auto Scaling?"}, {"role": "assistant", "content": "You can use the Key Name parameter to CreateLaunchConfiguration to associate a key pair with your instance. You can then use the GetPasswordData API in EC2. This is also possible through the AWS Management Console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are CloudWatch agents automatically installed on EC2 instances when you create an Amazon EC2 Auto Scaling group?"}, {"role": "assistant", "content": "If your AMI contains a CloudWatch agent, it\u2019s automatically installed on EC2 instances when you create an EC2 Auto Scaling group. With the stock Amazon Linux AMI, you need to install it (recommended, via yum)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I create a single ASG to scale instances across different purchase options?"}, {"role": "assistant", "content": "Yes. You can provision and automatically scale EC2 capacity across different EC2 instance types, Availability Zones, and On-Demand, RIs and Spot purchase options in a single Auto Scaling Group. You have the option to define the desired split between On-Demand and Spot capacity, select which instance types work for your application, and specify preference for how EC2 Auto Scaling should distribute the ASG capacity within each purchasing model."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use ASGs to launch and manage just Spot Instances or just On-Demand instances and RIs?"}, {"role": "assistant", "content": "Yes. You can configure your ASG specifying all capacity to be only Spot instances or all capacity to be only On-Demand instances and RIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I have a base capacity with On-Demand instances and RIs, and scale my ASG out on Spot instances?"}, {"role": "assistant", "content": "Yes. When setting up an ASG to combine purchasing models, you can specify the base capacity of the group to be fulfilled by On-Demand instances. As the ASG scales in or scale out, EC2 Auto Scaling ensures the base capacity be fulfilled with On-Demand instances and anything beyond that be fulfilled with either only Spot instances or a specified percentage mix of On-Demand or Spot instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I modify the configuration of an ASG to update the different properties pertaining to combining purchasing models and specifying multiple instance types?"}, {"role": "assistant", "content": "Yes. Similar to other ASG parameters, customers can update an existing ASG to modify one or all parameters pertaining to combining purchasing models and specifying multiple instance types, including instance types, prioritization order for On-Demand instances, percentage split between On-Demand and Spot instances, and allocation strategy."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use RI discounts with On-Demand Instances in an ASG?"}, {"role": "assistant", "content": "Yes. For example, if you have RIs for C4 instances and EC2 Auto Scaling launches a C4 you will receive your RI pricing for On-Demand Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I specify instances of different sizes (CPU cores, memory) in my Auto Scaling group?"}, {"role": "assistant", "content": "Yes. You can specify any instance type available in a region. Additionally, you can specify an optional weight for each instance type, which defines the capacity units that each instance would contribute to your application\u2019s performance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What if the instance types I like are not available in an Availability Zone?"}, {"role": "assistant", "content": "If none of the specified instance types are available in an Availability Zone, Auto Scaling will retarget the launches in other Availability Zones associated with the Auto Scaling group. Auto Scaling will always prefer keeping your compute balanced across Availability Zones and retarget if all instance types are not available in an Availability Zone."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the costs for using Amazon EC2 Auto Scaling?"}, {"role": "assistant", "content": "Amazon EC2 Auto Scaling fleet managment for EC2 instances carries no additional fees. The dynamic scaling capabilities of Amazon EC2 Auto Scaling are enabled by Amazon CloudWatch and also carry no additional fees. Amazon EC2 and Amazon CloudWatch service fees apply and are billed separately."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is AWS Batch?"}, {"role": "assistant", "content": "AWS Batch is a set of batch management capabilities that enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (e.g., CPU or memory optimized compute resources) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters, allowing you to instead focus on analyzing results and solving problems. AWS Batch plans, schedules, and executes your batch computing workloads using [Amazon ECS](http://web.archive.org/web/20240727090605/https://aws.amazon.com/ecs/), [Amazon EKS](http://web.archive.org/web/20240727090605/https://aws.amazon.com/eks/), and [AWS Fargate](http://web.archive.org/web/20240727090605/https://aws.amazon.com/fargate/) with an option to utilize spot instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is Batch Computing?"}, {"role": "assistant", "content": "Batch computing is the execution of a series of programs (\"jobs\") on one or more computers without manual intervention. Input parameters are pre-defined through scripts, command-line arguments, control files, or job control language. A given batch job may depend on the completion of preceding jobs, or on the availability of certain inputs, making the sequencing and scheduling of multiple jobs important, and incompatible with interactive processing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the benefits of batch computing?"}, {"role": "assistant", "content": "It can shift the time of job processing to periods when greater or less expensive capacity is available.It avoids idling compute resources with frequent manual intervention and supervision.It increases efficiency by driving higher utilization of compute resources.It enables the prioritization of jobs, aligning resource allocation with business objectives."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "When should I run my jobs in EKS vs. Fargate vs. ECS?"}, {"role": "assistant", "content": "You should run your jobs on Fargate when you want AWS Batch to handle provisioning of compute completely abstracted from ECS infrastructure. You should run your jobs on ECS if you need access to particular instance configurations (particular processors, GPUs, or architecture) or for very-large scale workloads. If you have chosen Kubernetes as your container orchestration technology, you can standardize your batch workloads using Batch integration with EKS.Depending on your use case, currently Fargate jobs will start faster in the case of initial scale-out of work, as there is no need to wait for EC2 instance or pods to launch. However, for larger workloads EKS or ECS may be faster as Batch reuses instances and container images to run subsequent jobs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "When should I run my jobs in Fargate vs. EC2?"}, {"role": "assistant", "content": "You should run your jobs on Fargate when you want AWS Batch to handle provisioning of compute completely abstracted from EC2 infrastructure. You should run your jobs on EC2 if you need access to particular instance configurations (particular processors, GPUs, or architecture) or for very-large scale workloads.Depending on your use case, your jobs may start faster using either EC2 or Fargate. Fargate jobs will start faster in the case of initial scale-out of work, as there is no need to wait for EC2 instance to launch. However, for larger workloads EC2 instances may be faster as Batch reuses instances and container images to run subsequent jobs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I spill over from a Fargate CE to a Fargate Spot CE, or vice versa?"}, {"role": "assistant", "content": "Yes. You can set Fargate CE\u2019s to have a max vCPU, which is the total amount of vCPU of all the jobs currently running in that CE. When your vCPU count hits max vCPU in a CE, Batch will begin scheduling jobs on the next Fargate CE in order attached to the queue, if there is one. This is useful if, for example, you want to set a Fargate CE to some minimum business requirement, then run the rest of your workload on Fargate Spot.While setting a Fargate Spot CE as first, followed by a Fargate CE, Batch will only spill over into Fargate when the vCPU used by your jobs is greater than max vCPU for that CE. In the event that Fargate Spot is reclaimed, max vCPU will not be met and Batch will not request Fargate resources in the subsequent CE to run your jobs.Connecting an AWS Batch job queue to Fargate/Fargate Spot CE and an EC2 or Spot CE is not allowed."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use AWS Batch?"}, {"role": "assistant", "content": "AWS Batch handles job execution and compute resource management, allowing you to focus on developing applications or analyzing results instead of setting up and managing infrastructure. If you are considering running or moving batch workloads to AWS, you should consider using AWS Batch."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What use cases is AWS Batch optimized for?"}, {"role": "assistant", "content": "AWS Batch is optimized for batch computing and applications that scale through the execution of multiple jobs in parallel. Deep learning, genomics analysis, financial risk models, Monte Carlo simulations, animation rendering, media transcoding, image processing, and engineering simulations are all excellent examples of batch computing applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use multi-container jobs for AWS Batch?"}, {"role": "assistant", "content": "You should use the multi-container jobs feature if you want to model your AWS Batch workload as a set of logically distinct elements, for example, the simulation environment and system under test (SUT), main application, or telemetry sidecar. Using this feature will simplify your operations, make it easier to follow best architectural practices, and allow you to align simulations with the multi-container architecture of your production system-of-systems. Whether you are looking to run separate containers for your SUTs and simulation environment or need to add an auxiliary sidecar, you no longer need to combine all workload elements into a monolithic container and rebuild it after every code change. As a result, you can simplify DevOps, keep containers small and fast to download, and facilitate parallelization of work."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Which job types can you run with multi-container jobs?"}, {"role": "assistant", "content": "AWS Batch supports running multiple containers in all job types including single-node regular jobs, array jobs, and multi-node parallel (MNP) jobs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Which compute environments can you use with multi-container jobs?"}, {"role": "assistant", "content": "You can run multi-container jobs in all AWS Batch compute environments including Amazon ECS, Amazon EC2, AWS Fargate, and Amazon EKS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the key features of AWS Batch?"}, {"role": "assistant", "content": "AWS Batch manages compute environments and job queues, allowing you to easily run thousands of jobs of any scale using [Amazon ECS](http://web.archive.org/web/20240727090605/https://aws.amazon.com/ecs/), [Amazon EKS](http://web.archive.org/web/20240727090605/https://aws.amazon.com/eks/), and [AWS Fargate](http://web.archive.org/web/20240727090605/https://aws.amazon.com/fargate/) with an option between Spot or on-demand resources. You simply define and submit your batch jobs to a queue. In response, AWS Batch chooses where to run the jobs, launching additional AWS capacity if needed. AWS Batch carefully monitors the progress of your jobs. When capacity is no longer needed, AWS Batch will remove it. AWS Batch also provides the ability to submit jobs that are part of a pipeline or workflow, enabling you to express any interdependencies that exist between them as you submit jobs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What types of batch jobs does AWS Batch support?"}, {"role": "assistant", "content": "AWS Batch supports any job that can executed as a Docker container. Jobs specify their memory requirements and number of vCPUs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Compute Resource?"}, {"role": "assistant", "content": "An AWS Batch Compute Resource is an EC2 instance or AWS Fargate compute resource."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Compute Environment?"}, {"role": "assistant", "content": "An AWS Batch Compute Environment is a collection of compute resources on which jobs are executed. AWS Batch supports two types of Compute Environments; Managed Compute Environments which are provisioned and managed by AWS and Unmanaged Compute Environments which are managed by customers. Unmanaged Compute Environments provide a mechanism to leverage specialized resources such as [Dedicated Hosts](http://web.archive.org/web/20240727090605/https://aws.amazon.com/ec2/dedicated-hosts/), larger storage configurations, and [Amazon EFS](http://web.archive.org/web/20240727090605/https://aws.amazon.com/efs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Job Definition?"}, {"role": "assistant", "content": "A Job Definition describes the job to be executed, parameters, environmental variables, compute requirements, and other information that is used to optimize the execution of a job. Job Definitions are defined in advance of submitting a job and can be shared with others."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the Amazon ECS Agent and how is it used by AWS Batch?"}, {"role": "assistant", "content": "AWS Batch uses Amazon ECS to execute containerized jobs and therefore requires the ECS Agent to be installed on compute resources within your AWS Batch Compute Environments. The ECS Agent is pre-installed in Managed Compute Environments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does AWS Batch make it easier to use Spot Instances?"}, {"role": "assistant", "content": "AWS Batch Compute Environments can be comprised of EC2 Spot Instances. When creating a Managed Compute Environment, simplify specify that you would like to use EC2 Spot Instances and provide a percentage of On-Demand pricing that you are willing to pay and AWS Batch will take care of the rest. Unmanaged Compute Environments can also include Spot Instances that you launch, including those launched by [EC2 Spot Fleet](http://web.archive.org/web/20240727090605/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the pricing for AWS Batch?"}, {"role": "assistant", "content": "There is no additional charge for AWS Batch. You only pay for the AWS Resources (e.g. EC2 instances or AWS Fargate) you create to store and run your batch jobs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use accelerators with AWS Batch?"}, {"role": "assistant", "content": "Yes, you can use Batch to specify the number and type of accelerators your jobs require as job definition input variables, alongside the current options of vCPU and memory. AWS Batch will scale up instances appropriate for your jobs based on the required accelerators and isolate the accelerators according to each job\u2019s needs, so only the appropriate containers can access them."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use accelerators with AWS Batch?"}, {"role": "assistant", "content": "By using accelerators with Batch, you can dynamically schedule and provision your jobs according to their accelerator needs, and Batch will ensure that the appropriate number of accelerators are reserved against your jobs. Batch will scale up your EC2 Accelerated Instances when you need them, and scale them down when you\u2019re done, allowing you to focus on your applications. Batch has native integration with the EC2 Spot, meaning your accelerated jobs can take advantage of up to 90% savings when using accelerated instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What accelerators can I use with AWS Batch?"}, {"role": "assistant", "content": "Currently you can use GPU\u2019s on P and G accelerated instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I submit jobs requiring accelerated instances to Batch?"}, {"role": "assistant", "content": "You can specify the number and type of accelerators in the Job Definition. You specify the accelerator by describing the accelerator type (e.g., GPU \u2013 currently the only supported accelerator) and the number of that type your job requires. Your specified accelerator type must be present on one of the instance types specified in your Compute Environments. For example, if your job needs 2 GPUs, also make sure that you have specified a P instance in your Compute Environment.From the API: { \"containerProperties\": { \"vcpus\": 1, \"image\": \"nvidia/cuda:9.0-base\", \"memory\": 2048, \"resourceRequirements\" : [ { \"type\" : \"GPU\", \"value\" : \"1\" } ],"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can accelerator variables in the job definition be overwritten at job submission?"}, {"role": "assistant", "content": "Similar to vCPU and memory requirements, you can overwrite the number and type of accelerators at job submission."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can accelerated instances be used for jobs that don't need the accelerators?"}, {"role": "assistant", "content": "With today's behavior, Batch will avoid scheduling jobs that do not require acceleration on accelerated instances when possible. This is to avoid cases where long-running jobs occupy the accelerated instance without taking advantage of the accelerator, increasing cost. In rare cases with Spot pricing and with accelerated instances as allowed types, it is possible that Batch will determine that an accelerated instance is the least expensive way to run your jobs, regardless of accelerator needs.If you submit a job to a CE that only allows Batch to launch accelerated instances, Batch will run the jobs on those instances, regardless of their accelerator needs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Batch use the ECS GPU-Optimized AMI?"}, {"role": "assistant", "content": "From now on, p-type instances will launch by default with the ECS GPU-optimized AMI. This AMI contains libraries and runtimes needed to run GPU-based applications. You can always point to a custom AMI as needed when creating a CE."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I get started?"}, {"role": "assistant", "content": "Follow the [Getting Started Guide](http://web.archive.org/web/20240727090605/https://docs.aws.amazon.com/batch/latest/userguide/Batch_GetStarted.html) in our documentation to get started."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do I need to provision to get started?"}, {"role": "assistant", "content": "There is no need to manually launch your own compute resources in order to get started. The AWS Batch web console will guide you through the process of creating your first Compute Environment and Job Queue so that you can submit your first job. Resources within your compute environment will scale up as additional jobs are ready to run and scale down as the number of runnable jobs decreases."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk makes it even easier for developers to quickly deploy and manage applications in the AWS Cloud. Developers simply upload their application, and Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who should use AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Those who want to deploy and manage their applications within minutes in the AWS Cloud. You don\u2019t need experience with [cloud computing](https://web.archive.org/web/20240727090637/https://aws.amazon.com/what-is-cloud-computing/) to get started. AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker web applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which languages and development stacks does AWS Elastic Beanstalk support?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk supports the following languages and development stacks:"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will AWS Elastic Beanstalk support other languages?"}, {"role": "assistant", "content": "Yes. AWS Elastic Beanstalk is designed so that it can be extended to support multiple development stacks and programming languages in the future. AWS is working with solution providers on the APIs and capabilities needed to create additional Elastic Beanstalk offerings."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What can developers now do with AWS Elastic Beanstalk that they could not before?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk automates the details of capacity provisioning, load balancing, auto scaling, and application deployment, creating an environment that runs a version of your application. You can simply upload your deployable code (e.g., WAR file), and AWS Elastic Beanstalk does the rest. The AWS Toolkit for Visual Studio and the AWS Toolkit for Eclipse allow you to deploy your application to AWS Elastic Beanstalk and manage it without leaving your IDE. Once your application is running, Elastic Beanstalk automates management tasks\u2013such as monitoring, application version deployment, a basic health check\u2013and facilitates log file access. By using Elastic Beanstalk, developers can focus on developing their application and are freed from deployment-oriented tasks, such as provisioning servers, setting up load balancing, or managing scaling."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is AWS Elastic Beanstalk different from existing application containers or platform-as-a-service solutions?"}, {"role": "assistant", "content": "Most existing application containers or platform-as-a-service solutions, while reducing the amount of programming required, significantly diminish developers\u2019 flexibility and control. Developers are forced to live with all the decisions predetermined by the vendor\u2013with little to no opportunity to take back control over various parts of their application\u2019s infrastructure. However, with AWS Elastic Beanstalk, developers retain full control over the AWS resources powering their application. If developers decide they want to manage some (or all) of the elements of their infrastructure, they can do so seamlessly by using Elastic Beanstalk\u2019s management capabilities."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What elements of my application can I control when using AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "With AWS Elastic Beanstalk, you can:"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the Cloud resources powering my AWS Elastic Beanstalk application?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk uses proven AWS features and services, such as Amazon EC2, Amazon RDS, Elastic Load Balancing, Auto Scaling, Amazon S3, and Amazon SNS, to create an environment that runs your application. The current version of AWS Elastic Beanstalk uses the Amazon Linux AMI or the Windows Server 2019."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What kinds of applications are supported by AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker, and is ideal for web applications. However, due to Elastic Beanstalk\u2019s open architecture, non-web applications can also be deployed using Elastic Beanstalk. We expect to support additional application types and programming languages in the future. See [Supported Platforms](https://web.archive.org/web/20240727090637/https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html) to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which operating systems does AWS Elastic Beanstalk use?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk runs on the Amazon Linux AMI and the Windows Server AMI. Both AMIs are supported and maintained by Amazon Web Services and are designed to provide a stable, secure, and high-performance execution environment for Amazon EC2 Cloud computing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I sign up for AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "To sign up for AWS Elastic Beanstalk, choose the Sign Up Now button on the Elastic Beanstalk detail page. You must have an Amazon Web Services account to access this service; if you do not already have one, you will be prompted to create one when you begin the Elastic Beanstalk process. After signing up, please refer to the AWS Elastic Beanstalk Getting Started Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I asked to verify my phone number when signing up for AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk registration requires you to have a valid phone number and email address on file with AWS in case we ever need to contact you. Verifying your phone number takes only a few minutes and involves receiving an automated phone call during the registration process and entering a PIN number using the phone key pad."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I get started after I have signed up?"}, {"role": "assistant", "content": "The best way to get started with AWS Elastic Beanstalk is to work through the AWS Elastic Beanstalk Getting Started Guide, part of our technical documentation. Within a few minutes, you will be able to deploy and use a sample application or upload your own application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there a sample application that I can use to check out AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Yes. AWS Elastic Beanstalk includes a sample application that you can use to test drive the offering and explore its functionality."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Elastic Beanstalk store anything in Amazon S3?"}, {"role": "assistant", "content": "Yes. AWS Elastic Beanstalk stores your application files and, optionally, server log files in Amazon S3. If you are using the AWS Management Console, the AWS Toolkit for Visual Studio, or AWS Toolkit for Eclipse, an Amazon S3 bucket will be created in your account for you and the files you upload will be automatically copied from your local client to Amazon S3. Optionally, you may configure Elastic Beanstalk to copy your server log files every hour to Amazon S3. You do this by editing the environment configuration settings."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Amazon S3 to store application data, like images?"}, {"role": "assistant", "content": "Yes. You can use Amazon S3 for application storage. The easiest way to do this is by including the AWS SDK as part of your application\u2019s deployable file. For example, you can include the AWS SDK for Java as part of your application's WAR file."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What database solutions can I use with AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk does not restrict you to any specific data persistence technology. You can choose to use Amazon Relational Database Service (Amazon RDS) or Amazon DynamoDB, or use Microsoft SQL Server, Oracle, or other relational databases running on Amazon EC2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I set up a database for use with AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Elastic Beanstalk can automatically provision an Amazon RDS DB instance. The information about connectivity to the DB instance is exposed to your application by environment variables. To learn more about how to configure RDS DB instances for your environment, see the Elastic Beanstalk Developer Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does this mean I need to modify the application code when moving from test to production?"}, {"role": "assistant", "content": "Not with AWS Elastic Beanstalk. With Elastic Beanstalk, you can specify the connection information in the environment configuration. By extracting the connection string from the application code, you can easily configure different Elastic Beanstalk environments to use different databases."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I make my application private?"}, {"role": "assistant", "content": "By default, your application is available publicly at myapp.elasticbeanstalk.com for anyone to access. You can use Amazon VPC to provision a private, isolated section of your application in a virtual network that you define. This virtual network can be made private through specific security group rules, network ACLs, and custom route tables. You can also easily control what other incoming traffic, such as SSH, is delivered or not to your application servers by changing the EC2 security group settings."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I run my application inside a Virtual Private Cloud (VPC)?"}, {"role": "assistant", "content": "Yes, you can run your applications in a VPC. For more details, see the AWS Elastic Beanstalk Developer Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find more information about security and running applications on AWS?"}, {"role": "assistant", "content": "For more information about security on AWS, please refer to our Amazon Web Services: Overview of Security Processes document and visit our Security Center."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is it possible to use Identity & Access Management (IAM) with AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Yes. IAM users with the appropriate permissions can now interact with AWS Elastic Beanstalk."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use IAM with AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "IAM allows you to manage users and groups in a centralized manner. You can control which IAM users have access to AWS Elastic Beanstalk, and limit permissions to read-only access to Elastic Beanstalk for operators who should not be able to perform actions against Elastic Beanstalk resources. All user activity within your account will be aggregated under a single AWS bill."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create IAM users?"}, {"role": "assistant", "content": "You can use the IAM console, IAM command line interface (CLI), or IAM API to provision IAM users. By default, IAM users have no access to AWS services until permissions are granted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I grant an IAM user access to AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "You can grant IAM users access to services by using policies. To simplify the process of granting access to AWS Elastic Beanstalk, you can use one of the policy templates in the IAM console to help you get started. Elastic Beanstalk offers two templates: a read-only access template and a full-access template. The read-only template grants read access to Elastic Beanstalk resources. The full-access template grants full access to all Elastic Beanstalk operations, as well as permissions to manage dependent resources, such as Elastic Load Balancing, Auto Scaling, and Amazon S3. You can also use the AWS Policy Generator to create custom policies. For more details, see the AWS Elastic Beanstalk Developer Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I restrict access to specific AWS Elastic Beanstalk resources?"}, {"role": "assistant", "content": "Yes. You can allow or deny permissions to specific AWS Elastic Beanstalk resources, such as applications, application versions, and environments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who gets billed for the AWS resources that an IAM user creates?"}, {"role": "assistant", "content": "All resources created by IAM users under a root account are owned and billed to the root account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who has access to an AWS Elastic Beanstalk environment launched by an IAM user?"}, {"role": "assistant", "content": "The root account has full access to all AWS Elastic Beanstalk environments launched by any IAM user under that account. If you use the Elastic Beanstalk template to grant read-only access to an IAM user, that user will be able to view all applications, application versions, environments, and any associated resources in that account. If you use the Elastic Beanstalk template to grant full access to an IAM user, that user will be able to create, modify, and terminate any Elastic Beanstalk resources under that account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can an IAM user access the AWS Elastic Beanstalk console?"}, {"role": "assistant", "content": "Yes. An IAM user can access the AWS Elastic Beanstalk console using their username and password."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can an IAM user call the AWS Elastic Beanstalk API?"}, {"role": "assistant", "content": "Yes. An IAM user can use their access key and secret key to perform operations using the Elastic Beanstalk API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can an IAM user use the AWS Elastic Beanstalk command line interface?"}, {"role": "assistant", "content": "Yes. An IAM user can use their access key and secret key to perform operations using the AWS Elastic Beanstalk command line interface (CLI)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I keep the underlying platform of the environment running my application automatically up-to-date?"}, {"role": "assistant", "content": "You can opt-in to having your AWS Elastic Beanstalk environments automatically updated to the latest version of the underlying platform running your application during a specified maintenance window. Elastic Beanstalk regularly releases new versions of supported platforms (Java, PHP, Ruby, Node.js, Python, .NET, Go, and Docker) with operating system, web and application server, and language and framework updates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I get started with managed platform updates?"}, {"role": "assistant", "content": "To let Elastic Beanstalk automatically manage your platform updates, you must enable managed platform updates in the Configuration tab of the Elastic Beanstalk console or use the EB CLI or API. After you have enabled the feature, you can configure which types of updates to allow and when updates can occur."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What kinds of platform version updates will managed platform updates apply?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk can automatically perform platform updates for new patch and minor platform versions. Elastic Beanstalk will not automatically perform major platform version updates (e.g., Java 7 Tomcat 7 to Java 8 Tomcat 8) because they include backwards incompatible changes and require additional testing. In these cases, you must manually initiate the update."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does AWS Elastic Beanstalk distinguish between \u201cmajor,\u201d \u201cminor,\u201d and \u201cpatch\u201d version releases?"}, {"role": "assistant", "content": "AWS Elastic Beanstalk platforms are versioned using this pattern: MAJOR.MINOR.PATCH (e.g., 2.0.0). Each portion is incremented as follows:"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When and how can I perform major version updates?"}, {"role": "assistant", "content": "You can perform major version updates at any time using the AWS Elastic Beanstalk management console, API, or CLI. You have the following options to perform a major version update:"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does Elastic Beanstalk apply managed platform updates?"}, {"role": "assistant", "content": "The updates are applied using an immutable deployment mechanism that ensures that no changes are made to the existing environment until a parallel fleet of Amazon EC2 instances, with the updates installed, is ready to be swapped with the existing instances, which are then terminated. In addition, if the Elastic Beanstalk health system detects any issues during the update, traffic is redirected to the existing fleet of instances, ensuring minimal impact to end users of your application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will my application be available during the maintenance windows?"}, {"role": "assistant", "content": "Since managed platform updates use an immutable deployment mechanism to perform the updates, your application will be available during the maintenance window and consumers of your application will not be impacted by the update."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does it cost to use managed platform updates?"}, {"role": "assistant", "content": "There is no additional charge for the managed platform updates feature. You simply pay for the additional EC2 instances necessary to perform the update for the duration of the update."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a maintenance window?"}, {"role": "assistant", "content": "A maintenance window is a weekly two-hour-long time slot during which AWS Elastic Beanstalk will initiate platform updates if managed platform updates is enabled and a new version of the platform is available. For example, if you select a maintenance window that begins every Sunday at 2 AM, AWS Elastic Beanstalk will initiate the platform update sometime between 2-4 AM every Sunday. It is important to note that, depending on the configuration of your applications, updates could complete outside of the maintenance window."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be notified of the availability of new platform versions?"}, {"role": "assistant", "content": "You will be notified about the availability of new platform versions through the AWS Management Console, forum announcements, and release notes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find details of changes between platform versions?"}, {"role": "assistant", "content": "Details on changes between platform versions can be found on the AWS Elastic Beanstalk Release Notes page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What operations can I perform on the environment while a managed update is in progress?"}, {"role": "assistant", "content": "The only action available to you while a managed platform update is in-progress is \u2018abort\u2019. This will allow you to stop the update immediately and roll back to the previous version."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which platform version will my environment be updated to if there are multiple new versions released in between maintenance windows?"}, {"role": "assistant", "content": "Your environment will always be updated to the latest version available based on the level (minor plus patch or patch only) you have selected."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find details of all the managed platform updates that have been performed on my environment?"}, {"role": "assistant", "content": "Details for every managed platform update are available on the events page and are tagged with an event type of \u201cMAINTENANCE.\u201d"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How often are platform version updates released?"}, {"role": "assistant", "content": "The number of version releases in a given year varies based on the frequency and content of releases and patches from the language/framework\u2019s vendor or core team, and the outcome of a thorough vetting of these releases and patches by our platform engineering team."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q:\u00a0How do I deploy a new workload with the Graviton processor from the Elastic Beanstalk console?"}, {"role": "assistant", "content": "To deploy your application with arm64-based processors on the Elastic Beanstalk console, you can select processor architecture and instance type from capacity tab in Configure more options settings."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q:\u00a0How do I deploy a new workload with the Graviton processor from the AWS CLI, Elastic Beanstalk CLI, or infrastructure as code services?"}, {"role": "assistant", "content": "To deploy your application using the Elastic Beanstalk CLI, AWS CLI, CFN, or AWS CDK, refer to [Elastic Beanstalk Developer Guide.](https://web.archive.org/web/20240727090637/https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.ec2.html)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to recompile my workload before migrating to Graviton?"}, {"role": "assistant", "content": "If your workload is on an interpreted programming language such as Node.js, Python, Tomcat, PHP, or Ruby, you do not need to recompile your workload to use Graviton. If you are using Go or .Net Core for your workload, you need to update the build command for the arm64 instance type. You also need to recompile binary dependencies or use an arm64 compatible release of binary dependencies. If you are using Docker, your Docker image must be multi-architecture and support deploying to both x86 and arm64."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which platform branches are supported by Graviton on Elastic Beanstalk?"}, {"role": "assistant", "content": "Elastic Beanstalk supports Graviton on 64bit Amazon Linux 2 for a variety of platform and branches. See the [documentation](https://web.archive.org/web/20240727090637/https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html) for a full list."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the use cases where I can use the Graviton processor?"}, {"role": "assistant", "content": "You can easily transition your workload to Graviton and take advantage of performance and cost benefits in the following use cases: Linux-based workloads built primarily on open-source technologies; containerized and microservices-based applications such as Docker and MC Docker; applications written in portable programming languages such as Java, Python, .NET Core, node.js, and PHP; Compiled C/C++, Rust, or Go applications; .NET Core (v3.1+) workloads running on Linux; multi-threaded workloads;non-uniform memory access (NUMA) sensitive workloads; and arm64-native software development and testing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much does AWS Elastic Beanstalk cost?"}, {"role": "assistant", "content": "There is no additional charge for AWS Elastic Beanstalk\u2013you pay only for the AWS resources actually used to store and run your application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much do the AWS resources powering my application on AWS Elastic Beanstalk cost?"}, {"role": "assistant", "content": "You pay only for what you use, and there is no minimum fee for the use of any AWS resources. For Amazon EC2 pricing information, please visit the pricing section on the EC2 detail page. For Amazon S3 pricing information, please visit the pricing section on the S3 detail page. You can use the AWS simple calculator to estimate your bill for different application sizes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I check how many AWS resources have been used by my application and access my bill?"}, {"role": "assistant", "content": "You can view your charges for the current billing period at any time on the Amazon Web Services web site by logging into your Amazon Web Services account and choosing Account Activity under Your Web Services Account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Support cover AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Yes. AWS Support covers issues related to your use of AWS Elastic Beanstalk. For further details and pricing, see the AWS Support page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What other support options are available?"}, {"role": "assistant", "content": "You can tap into the breadth of existing AWS community knowledge to help you with your development through the AWS Elastic Beanstalk discussion forum."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who are the primary users of AWS Data Exchange?"}, {"role": "assistant", "content": "AWS Data Exchange makes it easy for AWS customers to securely exchange and use third-party data on AWS. Data analysts, product managers, portfolio managers, data scientists, quants, clinical trial technicians, and developers in nearly every industry would like access to more data to drive analytics, train\u00a0machine learning (ML) models, and make data-driven decisions. But there is no one place to find data from multiple providers and no consistency in how providers deliver data, leaving them to deal with a mix of shipped physical media, FTP credentials, and bespoke API calls. Conversely, many organizations would like to make their data available for either research or commercial purposes, but it\u2019s too hard and expensive to build and maintain data delivery, entitlement, and billing technology, which further depresses the supply of valuable data."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What AWS Regions is AWS Data Exchange available in?"}, {"role": "assistant", "content": "AWS Data Exchange has a single global product catalog o\ufb00ered by providers available from any supported AWS Region. You can see the same catalog regardless of which Region you are using. The resources underlying the product (data sets, revisions, assets) are regional resources that you manage programmatically or through the AWS Data Exchange console in speci\ufb01c AWS Regions.\u00a0For a list of AWS Regions in which AWS Data Exchange is available today, see\u00a0[Service endpoints](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/general/latest/gr/dataexchange.html#dataexchange_region)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between AWS Data Exchange and the Registry of Open Data on AWS?"}, {"role": "assistant", "content": "All publicly available data sets on the <a></a>[Registry of Open Data](http://web.archive.org/web/20240727090632/https://registry.opendata.aws/) on AWS are also available through <a></a>[AWS Data Exchange](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/search/results"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is AWS Data Exchange for APIs?"}, {"role": "assistant", "content": "AWS Data Exchange for APIs is a feature that enables customers to find, subscribe to, and use third-party API products from providers on AWS Data Exchange. With AWS Data Exchange for APIs, customers can use AWS-native authentication and governance, explore consistent API documentation, and utilize supported AWS SDKs to make API calls.\u00a0Now, by adding their APIs to the AWS Data Exchange catalog, data providers can reach millions of AWS customers that consume API-based data and more easily manage subscriber authentication, entitlement, and billing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What type of data can I subscribe to on AWS Data Exchange?"}, {"role": "assistant", "content": "Today, AWS Data Exchange contains more than 3,500 data products from a broad range of domains, including financial services (for example, top US businesses by revenue); healthcare and life sciences (for example, population health management); geospatial (for example, satellite imagery); weather (for example, historical and future trajectories of temperature); and mapping (for example, street level imagery and foot traffic patterns). For a complete list of data providers,\u00a0navigate to\u00a0[the AWS Data Exchange catalog](http://web.archive.org/web/20240727090632/https://console.aws.amazon.com/dataexchange/home"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I see the catalog of AWS Data Exchange products?"}, {"role": "assistant", "content": "Anyone can browse the AWS Data Exchange catalog in [AWS Marketplace](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/b/2649387011"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I know when new revisions to data sets I\u2019m subscribed to become available?"}, {"role": "assistant", "content": "As a subscriber with an active subscription to a product,\u00a0you'll receive an Amazon CloudWatch Events event from AWS Data Exchange\u00a0every time the provider publishes new revisions. You can use this CloudWatch event to automate consumption of new data. For more information about CloudWatch Events, see [Logging and monitoring on AWS Data Exchange](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/logging-and-monitoring.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I migrate preexisting data subscriptions to be delivered by AWS Data Exchange?"}, {"role": "assistant", "content": "Yes. AWS Data Exchange allows qualified data providers to fulfill to existing subscribers using a Bring Your Own Subscription (BYOS) entitlement at no additional cost.\u00a0With a BYOS offer, the existing billing relationship will continue between you and the data provider. Talk to your data provider\u00a0about using this capability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the subscription durations that are available for AWS Data Exchange products?"}, {"role": "assistant", "content": "Data providers list products subscriptions with 1- to 36-month duration terms.\u00a0You can find subscription duration options on each product\u2019s detail page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I set my subscription to auto-renew?"}, {"role": "assistant", "content": "Providers have the option to enable auto-renewal on individual offers. As a subscriber, you can choose to set your subscription to auto-renew on the offers that have the auto-renewal functionality enabled. Auto-renewal is available for public and private offers that do not have payment schedules."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can data providers change the terms of the offer that I am subscribed to?"}, {"role": "assistant", "content": "How would it affect my subscription and renewal"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are refunds handled?"}, {"role": "assistant", "content": "AWS Data Exchange requires data providers to specify their refund policy, which you can see on the subscription details page. For any refund requests, you'll need to contact the provider directly. After a provider approves a refund request, AWS will process and issue the approved refund."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I remain compliant with applicable data privacy laws when subscribing to AWS Data Exchange products?"}, {"role": "assistant", "content": "Security and Compliance is a [shared responsibility](http://web.archive.org/web/20240727090632/https://aws.amazon.com/compliance/shared-responsibility-model/) among AWS, the data provider, and the subscriber. Detailed restrictions around eligible data sets and other related legal compliance matters are set forth in [Terms and Conditions for AWS Marketplace Providers](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/management/terms), which every data provider must agree to before listing any data products. If AWS learns that these terms are breached in any way, AWS will remove such content from AWS Data Exchange and the data provider may be suspended from the service.Providers and subscribers are responsible for conducting their own additional due-diligence to ensure compliance with any data privacy laws. If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on [Report Amazon AWS abuse](http://web.archive.org/web/20240727090632/https://support.aws.amazon.com/#/contacts/report-abuse)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there are any restrictions for how AWS Data Exchange and any data obtained through AWS Data Exchange can be used?"}, {"role": "assistant", "content": "Yes, AWS explicitly prohibits the use of AWS Data Exchange for any illegal or fraudulent activities. Data may not be used for any activities that result in the violation of an individual\u2019s rights or unlawfully discriminate against others based on race, ethnicity, sexual orientation, gender identity, or other related groups. Subscribers may not use any content obtained through AWS Data Exchange that was anonymized or aggregated (such that it is no longer associated with an identifiable individual) by the data provider to create, generate, or infer any information relating to a person\u2019s identity (for example, attempting to triangulate with other data sources)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I report abusive content or request information be removed from a product suspected of abuse?"}, {"role": "assistant", "content": "If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on [Report Amazon AWS abuse](http://web.archive.org/web/20240727090632/https://support.aws.amazon.com/#/contacts/report-abuse).\u00a0If AWS learns that our terms are breached in any way, AWS may remove the subscriber\u2019s access to the data product and the data provider or the subscriber may be suspended or terminated from future use of AWS Data Exchange"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I currently consume third-party data directly into my S3 bucket(s). Why should I consider using AWS Data Exchange to consume data from third parties instead?"}, {"role": "assistant", "content": "AWS Data Exchange centralizes, simplifies, and accelerates your data acquisition process.AWS Data Exchange allows you to consolidate your ingestion across data providers and receive your data using a single API. You can easily subscribe to new data products, and migrate any existing data feeds through the Bring Your Own Subscription feature.AWS Data Exchange sends you a CloudWatch Events event as new data is published, allowing you to automate ingestion without having to manage any physical media, FTP credentials, or other legacy technology. It also stores copies of data you've licensed, allowing you to access point-in-time history all in one secure location. AWS Data Exchange also centralizes your billing so you can receive one invoice from AWS instead of one for each data provider. With the AWS Data Exchange console, you can easily track your subscriptions in one place, and better manage your data pipeline."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I pay for my data product subscriptions?"}, {"role": "assistant", "content": "When you purchase a data product on AWS Data Exchange with upfront payments, you'll receive an invoice from AWS immediately. When you purchase a data product on AWS Data Exchange with multiple payments, you'll receive an invoice based on the dates specified in the [payment schedule](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/product-subscriptions.html) that will appear as part of your AWS Marketplace charges. You can see a breakout of charges for each data product by name in the Detail section of the invoice. You'll receive separate bills for usage of AWS infrastructure and analytics services such as Amazon Simple Storage Service (Amazon S3) or Amazon Athena.\u00a0For more information related to AWS Billing and Cost Management, see [Paying for products](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/marketplace/latest/buyerguide/buyer-paying-for-products.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I find API products in the AWS Data Exchange catalog?"}, {"role": "assistant", "content": "You can find products containing APIs in the <a></a>[AWS Marketplace catalog](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/search/results"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I subscribe to an API product?"}, {"role": "assistant", "content": "After you\u2019ve found the API that you want to subscribe to, select the product to learn more on the product detail page. Next, choose Continue to subscribe, review the subscription terms, and then choose the Subscribe button at the bottom of the page.  Note: You may be asked to submit information to the data provider before you can request to subscribe to their product. For more information on subscribing and using an API product, see the <a></a>[Subscribing to a product containing APIs](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/subscribing-to-product.html#subscribing-to-API-product.html)\u00a0topic in the <a></a><a>AWS Data Exchange User Guide</a>."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I make an API call?"}, {"role": "assistant", "content": "First, ensure you have successfully subscribed to a product containing an API data set. Then, navigate to the product\u2019s asset detail page to view API schemas and code snippets that will help you structure your API call. You can also utilize the AWS SDK to automatically sign your API requests with your AWS credentials. For more information about how to structure API calls to AWS Data Exchange products containing API data sets, see the <a></a>[Making an API call (console)](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/subscribing-to-product.html#make-api-call-console)\u00a0in\u00a0the <a></a>AWS Data Exchange User Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Data Exchange for APIs have a Service Level Agreement (SLA)?"}, {"role": "assistant", "content": "AWS Data Exchange for APIs does not currently offer an SLA."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any AWS Data Exchange for APIs-specific SDKs that I should be aware of?"}, {"role": "assistant", "content": "We have added AWS Data Exchange for APIs-specific operations to the following SDKs:For more information, see the [AWS Data Exchange API Reference](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/apireference/aws-data-exchange-api-reference.pdf)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I qualify to become a data provider on AWS Data Exchange?"}, {"role": "assistant", "content": "To become a data provider on AWS Data Exchange, data providers must agree to the [Terms and Conditions for AWS Marketplace Providers](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/management/terms) (\u201cAWS Marketplace Terms & Conditions\u201d). Data providers must use a valid legal entity domiciled in the United States or a member state of the EU, supply valid banking and taxation identification, and be qualified by the AWS Data Exchange business operations team. Each data provider will also undergo a detailed review by the AWS Data Exchange team prior to being granted permission to list data products on the catalog."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is data organized in AWS Data Exchange?"}, {"role": "assistant", "content": "Data in AWS Data Exchange is organized using three building blocks: data sets, revisions, and assets. A data set is a container for data that belongs together (for example, end of data pricing for equities trading in the US). Data sets contain a series of revisions, which data providers publish as needed to make new assets available. Revisions can represent changes or new data (for example, today\u2019s end of day prices), corrections to previous revisions, or entirely new snapshots. Assets are any file that can be stored in Amazon\u00a0Simple Storage Service (S3) (for example, CSV, Parquet, or image files).\u00a0For more information about working with data, see [Data in AWS Data Exchange](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/data-sets.html).\u00a0Using these building blocks, you can organize the data hierarchically to build complex data models or as single data files."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: After I create data sets, how do I publish and make them available to my subscribers?"}, {"role": "assistant", "content": "Data sets are made available to subscribers as part of a product. A product is a collection of one or more data sets, metadata that makes the product discoverable in the AWS Data Exchange catalog, pricing, and a Data Subscription Agreement with terms for your customers. For more information, see [Publishing a new product](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I choose which customers can subscribe to my data?"}, {"role": "assistant", "content": "Yes. You have an option to enable subscription verification on any public product, which will require prospective subscribers to fill out a subscription request form including their identity and intended use-case details before subscribing. For these products, you'll have up to 45 days to either approve or decline the subscription request. Note that public products that include personal data are required to have subscription verification enabled. For more information, see [Subscription verification for providers](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/subscription-verification-pro.html).You can also offer private products to specific subscribers by using their AWS Account ID. Private products can be custom-made from existing products on the public catalog or completely new products only offered to the specific customers of your choosing and not listed on the public catalog."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I have to package files in a specific format?"}, {"role": "assistant", "content": "AWS Data Exchange allows you to package files in any file format,\u00a0but you\u2019ll want to consider what will allow subscribers to most conveniently gain insight from the data. Parquet formatted files, for example, will allow subscribers to instantly run queries using Amazon Athena in a cost-effective way. Binary or other proprietary file formats will require that subscribers understand how to parse the information, which AWS recommends explaining in each product description."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who owns the data I am distributing as a provider through AWS Data Exchange?"}, {"role": "assistant", "content": "You retain ownership of the data you distribute as a data provider on AWS Data Exchange. The [Terms and Conditions for AWS Marketplace Providers](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/management/seller-settings/terms)\u00a0require each data provider to attest that they have the legal right to distribute the data they publish. Subscribers must legally agree to the Data Subscription Agreement specified by the data provider before gaining access to data sets contained in a product, which remains available for both data providers and subscribers. Consistent with the AWS acceptable use policy, AWS Data Exchange may suggest corrective action where there is evidence of abuse, but it is the data provider\u2019s responsibility to enforce and govern the terms of use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I specify the Data Subscription Agreement (DSA)?"}, {"role": "assistant", "content": "AWS Data Exchange provides an optional Data Subscription Agreement (DSA) template that incorporates inputs from multiple AWS customers and data providers. You can choose to use this DSA template, copy and edit it with their own terms and conditions, or specify custom terms by uploading a DSA of your choice. AWS Data Exchange will associate the DSA specified for the product without any further modifications.\u00a0For more information, see [Publishing a new product](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What ways can I price my data sets?"}, {"role": "assistant", "content": "AWS Data Exchange currently supports subscription-based pricing from 1- to 36-month duration terms."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is AWS Data Exchange suitable for data providers who want to distribute their data for free?"}, {"role": "assistant", "content": "Yes. Many data providers make their data products available for free for research, scientific, or other noncommercial use cases."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I customize pricing or terms for select customers?"}, {"role": "assistant", "content": "Yes. Private offers allow you to make public products available to select AWS customers and to set terms including price, duration, payment schedule, DSA, or refund policy. For more information, see <a></a>[Create private offers](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/private-offer-configuration.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any restrictions on what data can be made available on AWS Data Exchange?"}, {"role": "assistant", "content": "Yes. [Publishing guidelines](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-guidelines.html) for listing products on AWS Data Exchange and [Terms and Conditions for AWS Marketplace Providers](http://web.archive.org/web/20240727090632/https://aws.amazon.com/marketplace/management/terms)\u00a0restrict certain categories of data. Unless a provider is enrolled in the Extended Provider Program, data products listed on AWS Data Exchange may not include information that can be used to identify any person, except information that is already legally available to the public, such as newspaper articles, open court records, public company filings, or public online profiles. For more information about the Extended Provider Program, please [contact AWS Support](http://web.archive.org/web/20240727090632/https://console.aws.amazon.com/support/home#/case/create"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I remove a product that I published from the catalog?"}, {"role": "assistant", "content": "Yes. You can unpublish a product at any time to ensure that no new subscribers are able to view and subscribe to your product, including auto-renewal cancellation for existing subscribers. You'll need to keep data current for any existing subscribers until each subscription expires."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if I need to remove data from AWS Data Exchange?"}, {"role": "assistant", "content": "You can remove or change the price or Data Subscription Agreement (DSA) of a product at any time, although existing subscriptions will remain in effect until their next renewal. If a data provider erroneously publishes data, you can open a support case [open a support case](http://web.archive.org/web/20240727090632/https://console.aws.amazon.com/support/cases#/create"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I know who is subscribing to the data I have listed on AWS Data Exchange?"}, {"role": "assistant", "content": "AWS Data Exchange provides daily, weekly, and monthly reports detailing subscription activity."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When and how often will I receive payments?"}, {"role": "assistant", "content": "You will receive a disbursement for subscriptions less fulfillment fees once a month. AWS will disburse all funds that AWS has received from subscribers by that date to the bank account linked to the AWS account that you used at registration."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will AWS handle collection and remittances of US sales and use tax?"}, {"role": "assistant", "content": "When listing your data sets, you can enable collection and remittance of US sales and use tax. You can also configure your tax nexus to account for places where you have a physical presence to direct AWS to collect appropriate taxes. It's helpful to review the [AWS Marketplace U.S Tax Collection Support Terms and Conditions](http://web.archive.org/web/20240727090632/https://s3.amazonaws.com/aws-mp-seller-tax-terms/AWS_Marketplace_Tax_Support_Terms_and_Conditions.pdf). For details on sales tax collection in other geographies, see [AWS Marketplace Sellers & Tax Collection](http://web.archive.org/web/20240727090632/https://aws.amazon.com/tax-help/marketplace/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is Amazon.com or AWS providing customers\u2019 data on AWS Data Exchange?"}, {"role": "assistant", "content": "No. Neither Amazon.com nor AWS are providing customers\u2019 data on AWS Data Exchange."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can AWS access data products listed on AWS Data Exchange?"}, {"role": "assistant", "content": "AWS is vigilant about our customers\u2019 privacy. Companies listing data products on the AWS Data Exchange own them and are able to maintain control over who accesses their content. AWS does not access or use data products except as necessary to provide the AWS Data Exchange service."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I currently publish data directly into my subscribers' S3 buckets. Why should I consider using AWS Data Exchange to publish data to third parties instead?"}, {"role": "assistant", "content": "With AWS Data Exchange you can publish data simultaneously to all your customers and spend more time growing your business rather than managing logistics.AWS Data Exchange allows you to publish data to your customers through an easy-to-use API and console. The data model for AWS Data Exchange\u00a0simplifies managing and publishing data through three reusable constructs: data sets, revisions, and assets. AWS customers can subscribe to these published data products directly from AWS Marketplace. The service automatically grants entitlements to customers who have an active subscription to the product, which means that you don\u2019t have to manually configure and maintain custom permissions to an Amazon Simple Storage Service (S3) bucket for each subscription.  AWS Data Exchange automatically sends\u00a0an Amazon CloudWatch Events event to all subscribers when new revisions are published, which allows subscribers to automate their consumption of new data. When a subscription is no-longer active, AWS Data Exchange revokes that subscriber's entitlement to your data.  If your product is already available on AWS Data Exchange, you can simply use Bring Your Own Subscription (BYOS) to configure an entitlement to your existing subscribers for no additional cost and without any additional programming work. For more information\u00a0about using BYOS to migrate and fulfill existing subscriptions with AWS customers, see [Create Bring Your Own Subscription offers](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/create-byos-offers.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I publish a product containing APIs?"}, {"role": "assistant", "content": "As a provider, you first need to set up an AWS account and <a></a>[register as an AWS Marketplace seller](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/marketplace/latest/userguide/seller-registration-process.html). You can then publish an API product by following the steps detailed in the <a></a>[Publishing a product containing APIs](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html#publish-API-product) topic in the <a></a>AWS Data Exchange User Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do providers have to offer a Service Level Agreement (SLA) to AWS Data Exchange when offering an API product?"}, {"role": "assistant", "content": "AWS Data Exchange for APIs does not require providers to offer an uptime or availability SLA. Providers and subscribers can negotiate custom terms as part of a DSA. See <a></a>[Publishing Products](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html) for further information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What guidelines do I need to follow as a provider on AWS Data Exchange for APIs?"}, {"role": "assistant", "content": "In addition to following guidelines under the <a></a>[Terms and Conditions for AWS Marketplace Sellers](http://web.archive.org/web/20240727090632/http://aws.amazon.com/marketplace/management/seller-settings/terms) and the <a></a>[AWS Customer Agreement](http://web.archive.org/web/20240727090632/https://aws.amazon.com/agreement/), providers of products containing APIs must respond to subscriber support inquiries within 1 business day, as set forth in the AWS Data Exchange User Guide. Not following the guidelines may result in products being removed from AWS Data Exchange. For more information, see [Publishing guidelines](http://web.archive.org/web/20240727090632/https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-guidelines.html)\u00a0topic in\u00a0the <a></a><a>AWS Data Exchange User Guide</a>."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can products contain APIs, Amazon S3 objects, and Amazon Redshift data shares?"}, {"role": "assistant", "content": "Yes. As a data provider, you can publish products containing multiple data set types."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon Elastic Compute Cloud (Amazon EC2)?"}, {"role": "assistant", "content": "Amazon EC2 is a web service that provides resizable compute capacity in [the cloud](/web/20240727055400/https://aws.amazon.com/what-is-cloud-computing/). It is designed to make web-scale computing easier for developers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What can I do with Amazon EC2?"}, {"role": "assistant", "content": "Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables \u201ccompute\u201d in the cloud.\u00a0 The Amazon EC2 simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon\u2019s proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I get started with Amazon EC2?"}, {"role": "assistant", "content": "To sign up for Amazon EC2, select the \u201cSign up for This Web Service\u201d button on the Amazon EC2 detail page. You must have an AWS account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 signup process. After signing up, please refer to the [Amazon EC2 documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/ec2/index.html), which includes our Getting Started Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I asked to verify my phone number when signing up for Amazon EC2?"}, {"role": "assistant", "content": "Amazon EC2 registration requires you to have a valid phone number and email address on file with AWS in case we ever need to contact you. Verifying your phone number takes only a couple of minutes and involves receiving a phone call during the registration process and entering a PIN using the phone key pad."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What can developers now do that they could not before?"}, {"role": "assistant", "content": "Until now, small developers did not have the capital to acquire massive compute resources and ensure they had the capacity they needed to handle unexpected spikes in load. Amazon EC2 helps developers use Amazon\u2019s own benefits of massive scale with no upfront investment or performance compromises. Developers are now free to innovate knowing that no matter how successful their businesses become, it will be inexpensive and simple to ensure they have the compute capacity they need to meet their business requirements.The \u201cElastic\u201d nature of the service allows developers to instantly scale to meet spikes in traffic or demand. When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I run systems in the Amazon EC2 environment?"}, {"role": "assistant", "content": "Once you have set up your account and select or create your AMIs, you are ready to boot your instance. You can start your AMI on any number of On-Demand instances by using the RunInstances API call. You simply need to indicate how many instances you wish to launch.\u00a0If you wish to run more than your On-Demand quota, complete the [Amazon EC2 instance request form](/web/20240727055400/https://aws.amazon.com/contact-us/ec2-request/).If Amazon EC2 is able to fulfill your request, RunInstances will return success, and we will start launching your instances. You can check on the status of your instances using the DescribeInstances API call. You can also programmatically terminate any number of your instances using the TerminateInstances API call.If you have a running instance using an Amazon EBS boot partition, you can also use the StopInstances API call to release the compute resources but preserve the data on the boot partition. You can use the StartInstances API when you are ready to restart the associated instance with the Amazon EBS boot partition.In addition, you have the option to use Spot Instances to reduce your computing costs when you have flexibility in when your applications can run. Read more about Spot Instances for a more detailed explanation on how [Spot Instances](/web/20240727055400/https://aws.amazon.com/ec2/spot/) work.If you prefer, you can also perform all these actions from the [AWS Management Console](/web/20240727055400/https://aws.amazon.com/console/) or through the command line using our command line tools, which have been implemented with this web service API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between using the local instance store and Amazon Elastic Block Store (Amazon EBS) for the root device?"}, {"role": "assistant", "content": "When you launch your Amazon EC2 instances you have the ability to store your root device data on Amazon EBS or the local instance store. By using Amazon EBS, data on the root device will persist independently from the lifetime of the instance. This enables you to stop and restart the instance at a subsequent time, which is similar to shutting down your laptop and restarting it when you need it again.Alternatively, the local instance store only persists during the life of the instance. This is an inexpensive way to launch instances where data is not stored to the root device. For example, some customers use this option to run large web sites where each instance is a clone to handle web traffic."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How quickly will systems be running?"}, {"role": "assistant", "content": "It typically takes less than 10 minutes from the issue of the RunInstances call to the point where all requested instances begin their boot sequences. This time depends on a number of factors including: the size of your AMI, the number of instances you are launching, and how recently you have launched that AMI. Images launched for the first time may take slightly longer to boot."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I load and store my systems with Amazon EC2?"}, {"role": "assistant", "content": "Amazon EC2 allows you to set up and configure everything about your instances from your operating system up to your applications. An Amazon Machine Image (AMI) is simply a packaged-up environment that includes all the necessary bits to set up and boot your instance. Your AMIs are your unit of deployment. You might have just one AMI or you might compose your system out of several building block AMIs (e.g., webservers, appservers, and databases). Amazon EC2 provides a number of tools to make creating an AMI easy. Once you create a custom AMI, you will need to bundle it. If you are bundling an image with a root device backed by Amazon EBS, you can simply use the bundle command in the AWS Management Console. If you are bundling an image with a boot partition on the instance store, then you will need to use the AMI Tools to upload it to Amazon S3. Amazon EC2 uses Amazon EBS and Amazon S3 to provide reliable, scalable storage of your AMIs so that we can boot them when you ask us to do so.Or, if you want, you don\u2019t have to set up your own AMI from scratch. You can choose from a number of globally available AMIs that provide useful instances. For example, if you just want a simple Linux server, you can choose one of the standard Linux distribution AMIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I access my systems?"}, {"role": "assistant", "content": "The RunInstances call that initiates execution of your application stack will return a set of DNS names, one for each system that is being booted. This name can be used to access the system exactly as you would if it were in your own data center. You own that machine while your operating system stack is executing on it."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is Amazon EC2 used in conjunction with Amazon S3?"}, {"role": "assistant", "content": "Yes, Amazon EC2 is used jointly with Amazon S3 for instances with root devices backed by local instance storage. By using Amazon S3, developers have access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites. In order to execute systems in the Amazon EC2 environment, developers use the tools provided to load their AMIs into Amazon S3 and to move them between Amazon S3 and Amazon EC2. See [How do I load and store my systems with Amazon EC2"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many instances can I run in Amazon EC2?"}, {"role": "assistant", "content": "You are limited to running On-Demand Instances per your vCPU-based [On-Demand Instance limit](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html#ec2-on-demand-instances-limits), purchasing 20 Reserved Instances, and requesting Spot Instances per your [dynamic Spot limit](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html) per region. New AWS accounts may start with limits that are lower than the limits described here.If you need more instances, complete the [Amazon EC2 limit increase request form](/web/20240727055400/https://aws.amazon.com/contact-us/ec2-request/) with your use case, and your limit increase will be considered. Limit increases are tied to the region they were requested for."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any limitations in sending email from Amazon EC2 instances?"}, {"role": "assistant", "content": "Yes. In order to maintain the quality of Amazon EC2 addresses for sending email, we enforce default limits on the amount of email that can be sent from EC2 accounts. If you wish to send larger amounts of email from EC2, you can apply to have these limits removed from your account by [filling out this form](https://web.archive.org/web/20240727055400/https://portal.aws.amazon.com/gp/aws/html-forms-controller/contactus/ec2-email-limit-rdns-request)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How quickly can I scale my capacity both up and down?"}, {"role": "assistant", "content": "Amazon EC2 provides a truly elastic computing environment. Amazon EC2 enables you to increase or decrease capacity within minutes, not hours or days. You can commission one, hundreds or even thousands of server instances simultaneously. When you need more instances, you simply call RunInstances, and Amazon EC2 will typically set up your new instances in a matter of minutes. Of course, because this is all controlled with web service APIs, your application can automatically scale itself up and down depending on its needs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What operating system environments are supported?"}, {"role": "assistant", "content": "Amazon EC2 currently supports a variety of operating systems including: Amazon Linux, Ubuntu, Windows Server, Red Hat Enterprise Linux, SUSE Linux Enterprise Server, openSUSE Leap, Fedora, Fedora CoreOS, Debian, CentOS, Gentoo Linux, Oracle Linux, and FreeBSD. We are looking for ways to expand it to other platforms."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon EC2 use ECC memory?"}, {"role": "assistant", "content": "In our experience, ECC memory is necessary for server infrastructure, and all the hardware underlying Amazon EC2 uses ECC memory."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is this service different than a plain hosting service?"}, {"role": "assistant", "content": "Traditional hosting services generally provide a pre-configured resource for a fixed amount of time and at a predetermined cost. Amazon EC2 differs fundamentally in the flexibility, control and significant cost savings it offers developers, allowing them to treat Amazon EC2 as their own personal data center with the benefit of Amazon.com\u2019s robust infrastructure.When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals.Secondly, many hosting services don\u2019t provide full control over the compute resources being provided. Using Amazon EC2, developers can choose not only to initiate or shut down instances at any time, they can completely customize the configuration of their instances to suit their needs \u2013 and change it at any time. Most hosting services cater more towards groups of users with similar system requirements, and so offer limited ability to change these.Finally, with Amazon EC2 developers enjoy the benefit of paying only for their actual resource consumption \u2013 and at very low rates. Most hosting services require users to pay a fixed, upfront fee irrespective of their actual computing power used, and so users risk overbuying resources to compensate for the inability to quickly scale up resources within a short time frame."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is changing?"}, {"role": "assistant", "content": "Amazon EC2 is transitioning On-Demand Instance limits from the current instance count-based limits to the new vCPU-based limits to simplify the limit management experience for AWS customers. Usage toward the vCPU-based limit is measured in terms of number of vCPUs (virtual central processing units) for the [Amazon EC2 Instance Types](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/) to launch any combination of instance types that meet your application needs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are vCPU-based limits?"}, {"role": "assistant", "content": "You are limited to running one or more On-Demand Instances in an AWS account, and Amazon EC2 measures usage towards each limit based on the total number of vCPUs (virtual central processing unit) that are assigned to the running On-Demand instances in your AWS account. The following table shows the number of vCPUs for each instance size. The vCPU mapping for some instance types may differ; see [Amazon EC2 Instance Types](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/) for details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many On-Demand Instances can I run in Amazon EC2?"}, {"role": "assistant", "content": "There are five vCPU-based instance limits; each defines the amount of capacity you can use of a given instance family. All usage of instances in a given family, regardless of generation, size, or configuration variant (e.g. disk, processor type), will accrue towards the family\u2019s total vCPU limit, listed in the table below. New AWS accounts may start with limits that are lower than the limits described here."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are these On-Demand Instance vCPU-based limits regional?"}, {"role": "assistant", "content": "Yes, the On-Demand Instance limits for an AWS account are set on a per-region basis."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will these limits change over time?"}, {"role": "assistant", "content": "Yes, limits can change over time. Amazon EC2 is constantly monitoring your usage within each region and your limits are raised automatically based on your use of EC2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I request a limit increase?"}, {"role": "assistant", "content": "Even though EC2 automatically increases your On-Demand Instance limits based on your usage, if needed you can request a limit increase from the Limits Page on [Amazon EC2 console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/ec2/), the Amazon EC2 service page on the [Service Quotas console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/servicequotas), or the Service Quotas API/CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I calculate my new vCPU limit?"}, {"role": "assistant", "content": "You can find the vCPU mapping for each of the [Amazon EC2 Instance Types](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/) or use the [simplified vCPU Calculator](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/ec2/home#LimitsCalculator) to compute the total vCPU limit requirements for your AWS account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do vCPU limits apply when purchasing Reserved Instances or requesting Spot Instances?"}, {"role": "assistant", "content": "No, the vCPU-based limits only apply to running On-Demand instances and Spot Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I view my current On-Demand Instance limits?"}, {"role": "assistant", "content": "You can find your current On-Demand Instance limits on the EC2 Service Limits page in the [Amazon EC2 console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/ec2/), or from the [Service Quotas console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/servicequotas) and APIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will this affect running instances?"}, {"role": "assistant", "content": "No, opting into vCPU-based limits will not affect any running instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I still launch the same number of instances?"}, {"role": "assistant", "content": "Yes, the vCPU-based instance limits allow you to launch at least the same number of instances as count-based instance limits."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I be able to view instance usage against these limits?"}, {"role": "assistant", "content": "With the Amazon CloudWatch metrics integration, you can view EC2 usage against limits in the [Service Quotas console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/servicequotas). Service Quotas also enables customers to use CloudWatch for configuring alarms to warn customers of approaching limits. In addition, you can continue to track and inspect your instance usage in Trusted Advisor and Limit Monitor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I still be able to use the DescribeAccountAttributes API?"}, {"role": "assistant", "content": "With the vCPU limits, we no longer have total instance limits governing the usage. Hence the [DescribeAccountAttributes](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeAccountAttributes.html) API will no longer return the max-instances value. Instead you can now use the Service Quotas APIs to retrieve information about EC2 limits. You can find more information about the Service Quotas APIs in the [AWS documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/servicequotas/2019-06-24/apireference/Welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will the vCPU limits have an impact on my monthly bill?"}, {"role": "assistant", "content": "No. EC2 usage is still calculated either by the hour or the second, [depending on which AMI you're running](/web/20240727055400/https://aws.amazon.com/ec2/pricing/) and the instance type and size you\u2019ve launched."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will vCPU limits be available in all Regions?"}, {"role": "assistant", "content": "vCPU-based instance limits are available in all commercial AWS Regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is changing?"}, {"role": "assistant", "content": "As of Januaury 7, 2020, Amazon EC2 began rolling out a change to restrict email traffic over port 25 by default to protect customers and other recipients from spam and email abuse. Port 25 is typically used as the default SMTP port to send emails. AWS accounts that have requested and had Port 25 throttles removed in the past will not be impacted by this change."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I have a valid use case for sending emails to port 25 from EC2. How can I have these port 25 restrictions removed?"}, {"role": "assistant", "content": "If you have a valid use case for sending emails to port 25 (SMTP) from EC2, please submit a [Request to Remove Email Sending Limitations](/web/20240727055400/https://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/) to have these restrictions lifted. You can alternately send emails using a different port, or leverage an existing authenticated email relay service such as [Amazon Simple Email Service](/web/20240727055400/https://aws.amazon.com/ses/) (Amazon SES)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does your Amazon EC2 Service Level Agreement guarantee?"}, {"role": "assistant", "content": "Our SLA guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon EC2 and Amazon EBS within a Region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I know if I qualify for an SLA Service Credit?"}, {"role": "assistant", "content": "You are eligible for an SLA credit for either Amazon EC2 or Amazon EBS (whichever was Unavailable, or both if both were Unavailable) if the Region that you are operating in has an Monthly Uptime Percentage of less than 99.99% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, see the\u00a0[Amazon Compute Service Level Agreement](https://web.archive.org/web/20240727055400/http://aws.amazon.com/ec2/sla/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Accelerated Computing instances?"}, {"role": "assistant", "content": "The Accelerated Computing instance category includes instance families that\u00a0use hardware accelerators, or co-processors, to perform some functions, such as floating-point number calculation and graphics processing, more efficiently than is possible in software running on CPUs. Amazon EC2 provides three types of Accelerated Computing instances \u2013 GPU compute instances for general-purpose computing, GPU graphics instances for graphics intensive applications, and FPGA programmable hardware compute instances for advanced scientific workloads."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use GPU Graphics and Compute instances?"}, {"role": "assistant", "content": "GPU instances work best for applications with massive parallelism such as workloads using thousands of threads. Graphics processing is an example with huge computational requirements, where each of the tasks is relatively small, the set of operations performed form a pipeline, and the throughput of this pipeline is more important than the latency of the individual operations. To be able to build applications that exploit this level of parallelism, one needs GPU device specific knowledge by understanding how to program against various graphics APIs (DirectX, OpenGL) or GPU compute programming models (CUDA, OpenCL)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What applications can benefit from P4d?"}, {"role": "assistant", "content": "Some of the applications that we expect customers to use P4d for are machine learning (ML) workloads like natural language understanding, perception model training for autonomous vehicles, image classification, object detection and recommendation engines. The increased GPU performance can significantly reduce the time to train and the additional GPU memory will help customers train larger, more complex models. HPC customers can use P4\u2019s increased processing performance and GPU memory for seismic analysis, drug discovery, DNA sequencing, and insurance risk modeling."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do P4d instances compare to P3 instances?"}, {"role": "assistant", "content": "P4 instances feature NVIDIA\u2019s latest generation A100 Tensor Core GPUs to provide on average 2.5X increase in TFLOP performance over the previous generation V100 along with 2.5X the GPU memory. P4 instances feature Cascade Lake Intel CPU that has 24C per socket and an additional instruction set for vector neural network instructions. P4 instances will have 1.5X the total system memory and 4X the networking throughput of P3dn or 16x compared to P3.16xl. Another key difference is that the NVSwitch GPU interconnect throughput will double what was possible on P3 so each GPU can communicate with every other GPU at the same 600GB/s bidirectional throughput and with single-hop latency. This allows application development to consider multiple GPUs and memories as a single large GPU and a unified pool of memory. P4d instances are also deployed in tightly coupled hyperscale clusters, called EC2 UltraClusters, that enable you to run the most complex multi-node ML training and HPC applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 UltraClusters and how can I get access?"}, {"role": "assistant", "content": "P4d instances are deployed in hyperscale clusters called EC2 UltraClusters. Each EC2 UltraCluster is comprised of more than 4,000 NVIDIA A100 Tensor Core GPUs, Petabit-scale networking, and scalable low latency storage with FSx for Lustre. Each EC2 UltraCluster is one of the world\u2019s top supercomputers. Anyone can easily spin up P4d instances in EC2 SuperClusters. For additional help, [contact us](https://web.archive.org/web/20240727055400/https://pages.awscloud.com/p4d-ultracluster-contactus.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will AMIs that I used on P3 and P3dn work on P4?"}, {"role": "assistant", "content": "The P4 AMIs will need new NVIDIA drivers for the A100 GPUs and a newer version of the ENA driver installed. P4 instances are powered by Nitro System and they require AMIs with NVMe and ENA driver installed. P4 also comes with new Intel Cascade Lake CPUs, which come with an updated instruction set, so we recommend using the latest distributions of ML frameworks, which take advantage of these new instruction sets for data pre-processing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are P3 instances different from G3 instances?"}, {"role": "assistant", "content": "P3 instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Tesla V100 GPUs. These new instances significantly improve performance and scalability, and add many new features, including new Streaming Multiprocessor (SM) architecture for machine learning (ML)/deep learning (DL) performance optimization, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the benefits of NVIDIA Volta GV100 GPUs?"}, {"role": "assistant", "content": "The new NVIDIA Tesla V100 accelerator incorporates the powerful new Volta GV100 GPU. GV100 not only builds upon the advances of its predecessor, the Pascal GP100 GPU, it significantly improves performance and scalability, and adds many new features that improve programmability. These advances will supercharge HPC, data center, supercomputer, and deep learning systems and applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who will benefit from P3 instances?"}, {"role": "assistant", "content": "P3 instances with their high computational performance will benefit users in artificial intelligence (AI), machine learning (ML), deep learning (DL) and high performance computing (HPC) applications. Users include data scientists, data architects, data analysts, scientific researchers, ML engineers, IT managers and software developers. Key industries include transportation, energy/oil & gas, financial services (banking, insurance), healthcare, pharmaceutical, sciences, IT, retail, manufacturing, high-tech, transportation, government, and academia, among many others."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some key use cases of P3 instances?"}, {"role": "assistant", "content": "P3 instances use GPUs to accelerate numerous deep learning systems and applications including autonomous vehicle platforms, speech, image, and text recognition systems, intelligent video analytics, molecular simulations, drug discovery, disease diagnosis, weather forecasting, big data analytics, financial modeling, robotics, factory automation, real-time language translation, online search optimizations, and personalized user recommendations, to name just a few."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should customers use GPU-powered Amazon P3 instances for AI/ML and HPC?"}, {"role": "assistant", "content": "GPU-based compute instances provide greater throughput and performance because they are designed for massively parallel processing using thousands of specialized cores per GPU, versus CPUs offering sequential processing with a few cores. In addition, developers have built hundreds of GPU-optimized scientific HPC applications such as quantum chemistry, molecular dynamics, and meteorology, among many others. Research indicates that over 70% of the most popular HPC applications provide built-in support for GPUs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are G3 instances different from P2 instances?"}, {"role": "assistant", "content": "G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory, making them ideal for deep learning, high performance databases, computational fluid dynamics, computational finance, seismic analysis, molecular modeling, genomics, rendering, and other server-side GPU compute workloads."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are P3 instances different from P2 instances?"}, {"role": "assistant", "content": "P3 Instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Volta GV100 GPUs. These new instances significantly improve performance and scalability and add many new features, including new Streaming Multiprocessor (SM) architecture, optimized for machine learning (ML)/deep learning (DL) performance, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What APIs and programming models are supported by GPU Graphics and Compute instances?"}, {"role": "assistant", "content": "P3 instances support CUDA 9 and OpenCL, P2 instances support CUDA 8 and OpenCL 1.2 and G3 instances support DirectX 12, OpenGL 4.5, CUDA 8, and OpenCL 1.2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where do I get NVIDIA drivers for P3 and G3 instances?"}, {"role": "assistant", "content": "There are two methods by which NVIDIA drivers may be obtained. There are listings on the [AWS Marketplace](https://web.archive.org/web/20240727055400/https://aws.amazon.com/marketplace/search/results/"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs can I use with P3, P2 and G3 instances?"}, {"role": "assistant", "content": "You can currently use Windows Server, SUSE Enterprise Linux, Ubuntu, and Amazon Linux AMIs on P2 and G3 instances. P3 instances only support HVM AMIs. If you want to launch AMIs with operating systems not listed here, contact AWS [Customer Support](/web/20240727055400/https://aws.amazon.com/contact-us/) with your request or reach out through [EC2 Forums](https://web.archive.org/web/20240727055400/https://forums.aws.amazon.com/forum.jspa"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does the use of G3 instances require third-party licenses?"}, {"role": "assistant", "content": "Aside from the NVIDIA drivers and GRID SDK, the use G3 instances does not necessarily require any third-party licenses. However, you are responsible for determining whether your content or technology used on G3 instances requires any additional licensing. For example, if you are streaming content you may need licenses for some or all of that content. If you are using third-party technology such as operating systems, audio and/or video encoders, and decoders from Microsoft, Thomson, Fraunhofer IIS, Sisvel S.p.A., MPEG-LA, and Coding Technologies, please consult these providers to determine if a license is required. For example, if you leverage the on-board h.264 video encoder on the NVIDIA GRID GPU you should reach out to MPEG-LA for guidance, and if you use mp3 technology you should contact Thomson for guidance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I not getting NVIDIA GRID features on G3 instances using the driver downloaded from the NVIDIA website?"}, {"role": "assistant", "content": "The NVIDIA Tesla M60 GPU used in G3 instances requires a special NVIDIA GRID driver to enable all advanced graphics features, and 4 monitors support with resolution up to 4096x2160. You need to use an AMI with NVIDIA GRID driver pre-installed, or download and install the NVIDIA GRID driver following the AWS documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I unable to see the GPU when using Microsoft Remote Desktop?"}, {"role": "assistant", "content": "When using Remote Desktop, GPUs using the WDDM driver model are replaced with a non-accelerated Remote Desktop display driver. In order to access your GPU hardware, you need to utilize a different remote access tool, such as VNC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EC2 F1?"}, {"role": "assistant", "content": "Amazon EC2 F1 is a compute instance with programmable hardware you can use for application acceleration. The new F1 instance type provides a high performance, easy to access FPGA for developing and deploying custom hardware accelerations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are FPGAs and why do I need them?"}, {"role": "assistant", "content": "FPGAs are programmable integrated circuits that you can configure using software. By using FPGAs you can accelerate your applications up to 30x when compared with servers that use CPUs alone. And, FPGAs are reprogrammable, so you get the flexibility to update and optimize your hardware acceleration without having to redesign the hardware."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does F1 compare with traditional FPGA solutions?"}, {"role": "assistant", "content": "F1 is an AWS instance with programmable hardware for application acceleration. With F1, you have access to FPGA hardware in a few simple clicks, reducing the time and cost of full-cycle FPGA development and scale deployment from months or years to days. While FPGA technology has been available for decades, adoption of application acceleration has struggled to be successful in both the development of accelerators and the business model of selling custom hardware for traditional enterprises, due to time and cost in development infrastructure, hardware design, and at-scale deployment. With this offering, customers avoid the undifferentiated heavy lifting associated with developing FPGAs in on-premises data centers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an Amazon FPGA Image (AFI)?"}, {"role": "assistant", "content": "The design that you create to program your FPGA is called an Amazon FPGA Image (AFI). AWS provides a service to register, manage, copy, query, and delete AFIs. After an AFI is created, it can be loaded on a running F1 instance. You can load multiple AFIs to the same F1 instance, and can switch between AFIs in runtime without reboot. This lets you quickly test and run multiple hardware accelerations in rapid sequence. You can also offer to other customers on the AWS Marketplace a combination of your FPGA acceleration and an AMI with custom software or AFI drivers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I list my hardware acceleration on the AWS Marketplace?"}, {"role": "assistant", "content": "You would develop your AFI and the software drivers/tools to use this AFI. You would then package these software tools/drivers into an Amazon Machine Image (AMI) in an encrypted format. AWS manages all AFIs in the encrypted format you provide to maintain the security of your code. To sell a product in the AWS Marketplace, you or your company must sign up to be an AWS Marketplace reseller, you would then submit your AMI ID and the AFI ID(s) intended to be packaged in a single product. AWS Marketplace will take care of cloning the AMI and AFI(s) to create a product, and associate a product code to these artifacts, such that any end-user subscribing to this product code would have access to this AMI and the AFI(s)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is available with F1 instances?"}, {"role": "assistant", "content": "For developers, AWS is providing a Hardware Development Kit (HDK) to help accelerate development cycles, a FPGA Developer AMI for development in the cloud, an SDK for AMIs running the F1 instance, and a set of APIs to register, manage, copy, query, and delete AFIs. Both developers and customers have access to the AWS Marketplace where AFIs can be listed and purchased for use in application accelerations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to be an FPGA expert to use an F1 instance?"}, {"role": "assistant", "content": "AWS customers subscribing to an F1-optimized AMI from AWS Marketplace do not need to know anything about FPGAs to take advantage of the accelerations provided by the F1 instance and the AWS Marketplace. Simply subscribe to an F1-optimized AMI from the AWS Marketplace with an acceleration that matches the workload. The AMI contains all the software necessary for using the FPGA acceleration. Customers need only write software to the specific API for that accelerator and start using the accelerator."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I\u2019m an FPGA developer; how do I get started with F1 instances?"}, {"role": "assistant", "content": "Developers can get started on the F1 instance by creating an AWS account and downloading the AWS Hardware Development Kit (HDK). The HDK includes documentation on F1, internal FPGA interfaces, and compiler scripts for generating AFI. Developers can start writing their FPGA code to the documented interfaces included in the HDK to create their acceleration function. Developers can launch AWS instances with the FPGA Developer AMI. This AMI includes the development tools needed to compile and simulate the FPGA code. The Developer AMI is best run on the latest C5, M5, or R4 instances. Developers should have experience in the programming languages used for creating FPGA code (i.e. Verilog or VHDL) and an understanding of the operation they wish to accelerate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I\u2019m not an FPGA developer; how do I get started with F1 instances?"}, {"role": "assistant", "content": "Customers can get started with F1 instances by selecting an accelerator from the AWS Marketplace, provided by AWS Marketplace sellers, and launching an F1 instance with that AMI. The AMI includes all of the software and APIs for that accelerator. AWS manages programming the FPGA with the AFI for that accelerator. Customers do not need any FPGA experience or knowledge to use these accelerators. They can work completely at the software API level for that accelerator."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS provide a developer kit?"}, {"role": "assistant", "content": "Yes. The Hardware Development Kit (HDK) includes simulation tools and simulation models for developers to simulate, debug, build, and register their acceleration code. The HDK includes code samples, compile scripts, debug interfaces, and many other tools you will need to develop the FPGA code for your F1 instances. You can use the HDK either in an AWS provided AMI, or in your on-premises development environment. These models and scripts are available\u00a0publicly with an AWS account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use the HDK in my on-premises development environment?"}, {"role": "assistant", "content": "Yes. You can use the Hardware Development Kit HDK either in an AWS-provided AMI, or in your on-premises development environment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I add an FPGA to any EC2 instance type?"}, {"role": "assistant", "content": "No. F1 instances comes in two instance sizes: f1.2xlarge, f1.4xlarge, and f1.16 xlarge."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use the Inferentia chip in Inf1 instances?"}, {"role": "assistant", "content": "You can start your workflow by building and training your model in one of the popular ML frameworks such as TensorFlow, PyTorch, or MXNet using GPU instances such as P4, P3, or P3dn. Once the model is trained to your required accuracy, you can use the ML framework\u2019s API to invoke Neuron, a software development kit for Inferentia, to compile the model for execution on Inferentia chips, load it in to Inferentia\u2019s memory, and then execute inference calls. In order to get started quickly, you can use [AWS Deep Learning AMIs](/web/20240727055400/https://aws.amazon.com/machine-learning/amis/) that come pre-installed with ML frameworks and the Neuron SDK. For a fully managed experience you will be able to use Amazon SageMaker, which will enable you to seamlessly deploy your trained models on Inf1 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When would I use Inf1 vs. C6i or C5 vs. G4 instances for inference?"}, {"role": "assistant", "content": "Customers running machine learning models that are sensitive to inference latency and throughput can use Inf1 instances for high-performance cost-effective inference. For those ML models that are less sensitive to inference latency and throughput, customers can use EC2 C6i or C5 instances and utilize the AVX-512/VNNI instruction set. For ML models that require access to NVIDIA\u2019s CUDA, CuDNN or TensorRT libraries, we recommend using G4 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I choose Elastic Inference (EI) for inference vs Amazon EC2 Inf1 instances?"}, {"role": "assistant", "content": "There are two cases where developers would choose EI over Inf1 instances: (1) if you need different CPU and memory sizes than what Inf1 offers, then you can use EI to attach acceleration to the EC2 instance with the right mix of CPU and memory for your application (2) if your performance requirements are significantly lower than what the smallest Inf1 instance provides, then using EI could be a more cost effective choice. For example, if you only need 5 TOPS, enough for processing up to 6 concurrent video streams, then using the smallest slice of EI with a C5.large instance could be up to 50% cheaper than using the smallest size of an Inf1 instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What ML models types and operators are supported by EC2 Inf1 instances using the Inferentia chip?"}, {"role": "assistant", "content": "Inferentia chips support the commonly used machine learning models such as single shot detector (SSD) and ResNet for image recognition/classification and Transformer and BERT for natural language processing and translation and many others. A list of supported operators can be found on GitHub."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I take advantage of AWS Inferentia\u2019s NeuronCore Pipeline capability to lower latency?"}, {"role": "assistant", "content": "Inf1 instances with multiple Inferentia chips, such as Inf1.6xlarge or Inf1.24xlarge, support a fast chip-to-chip interconnect. Using the Neuron Processing Pipeline capability, you can split your model and load it to local cache memory across multiple chips. The Neuron compiler uses ahead-of-time (AOT) compilation technique to analyze the input model and compile it to fit across the on-chip memory of single or multiple Inferentia chips. Doing so enables the Neuron Cores to have high-speed access to models and not require access to off-chip memory, keeping latency bounded while increasing the overall inference throughput."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between AWS Neuron and Amazon SageMaker Neo?"}, {"role": "assistant", "content": "AWS Neuron is a specialized SDK for AWS Inferentia chips that optimizes the machine learning inference performance of Inferentia chips. It consists of a compiler, run-time, and profiling tools for AWS Inferentia and is required to run inference workloads on EC2 Inf1 instances. On the other hand, Amazon SageMaker Neo is a hardware agnostic service that consists of a compiler and run-time that enables developers to train machine learning models once, and run them on many different hardware platforms."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use the Trainium chips in Trn1 instances?"}, {"role": "assistant", "content": "The Trainium software stack, AWS Neuron SDK, integrates with leading ML frameworks, such as PyTorch and TensorFlow, so you can get started with minimal code changes. To get started quickly, you can use [AWS Deep Learning AMIs](/web/20240727055400/https://aws.amazon.com/machine-learning/amis/) and [AWS Deep Learning Containers](/web/20240727055400/https://aws.amazon.com/machine-learning/containers/), which come preconfigured with AWS Neuron. If you are using containerized applications, you can deploy AWS Neuron by using [Amazon Elastic Container Service (Amazon ECS)](/web/20240727055400/https://aws.amazon.com/ecs/), [Amazon Elastic Kubernetes Service (Amazon EKS)](/web/20240727055400/https://aws.amazon.com/eks/), or your preferred native container engine. AWS Neuron also supports [Amazon SageMaker](/web/20240727055400/https://aws.amazon.com/sagemaker/), which you can use to build, train, and deploy machine learning models."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I deploy deep learning models trained on Trn1?"}, {"role": "assistant", "content": "You can deploy deep learning models trained on Trn1 instances on any other Amazon EC2 instance that supports deep learning use cases, including instances based on CPUs, GPUs, or other accelerators. You can also deploy models trained on Trn1 instances outside of AWS, such as on-premises data centers or in embedded devices at the edge. For example, you can train your models on Trn1 instances and deploy them on Inf1 instances, G5 instances, G4 instances, or compute devices at the edge."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When would I use Trn1 instances over GPU-based instances for training ML models?"}, {"role": "assistant", "content": "Trn1 instances are a good fit for your natural language processing (NLP), large language model (LLM), and computer vision (CV) model training use cases. Trn1 instances focus on accelerating model training to deliver high performance while also lowering your model training costs. If you have ML models that need third-party proprietary libraries or languages, for example NVIDIA CUDA, CUDA Deep Neural Network (cuDNN), or TensorRT libraries, we recommend using the NVIDIA GPU-based instances (P4, P3)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do Amazon EC2 Flex instances (M7i-flex and C7i-flex) differentiate from comparable instances (M7i and C7i)?"}, {"role": "assistant", "content": "When should I use Flex instances over comparable instances"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What performance do Flex instances provide?"}, {"role": "assistant", "content": "Flex instances provide reliable CPU resources to deliver a baseline CPU performance of 40%, designed to meet the compute requirements of the majority of workloads. For times when workloads need more performance, Flex instances provide the ability to scale up to 100% CPU for 95% of the time over a 24-hour window."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some other use cases for M7i-flex instances?"}, {"role": "assistant", "content": "The M7i-flex instances provide a compelling upgrade path for workloads running on T3 larger-sized instances (large to 2xlarge) by offering better price performance, a fixed hourly price that includes baseline CPU and additional CPU usage beyond baseline, and larger instance sizes up to 8xlarge (32vCPUs and 128 GB). M7i-flex instances offer a simplified way to optimize your EC2 usage without CPU credits."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are Burstable Performance Instances different?"}, {"role": "assistant", "content": "Amazon EC2 allows you to choose between Fixed Performance Instances (e.g. C, M and R instance families) and [Burstable Performance Instances](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/#Burstable_Performance_Instances) (e.g. T2). Burstable Performance Instances provide a baseline level of CPU performance with the ability to burst above the baseline.T2 instances\u2019 baseline performance and ability to burst are governed by CPU Credits. Each T2 instance receives CPU Credits continuously, the rate of which depends on the instance size. T2 instances accrue CPU Credits when they are idle, and consume CPU credits when they are active. A CPU Credit provides the performance of a full CPU core for one minute.* For the t2.medium, single threaded applications can use 40% of 1 core, or if needed, multithreaded applications can use 20% each of 2 cores.**For the t2.large, single threaded applications can use 60% of 1 core, or if needed, multithreaded applications can use 30% each of 2 cores.*** For the t2.xlarge, single threaded applications can use 90% of 1 core, or if needed, multithreaded applications can use 45% each of 2 cores or 22.5% of all 4 cores.**** For the t2.2xlarge, single threaded applications can use all of 1 core, or if needed, multithreaded applications can use 67.5% each of 2 cores or 16.875% of all 8 cores."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I choose the right Amazon Machine Image (AMI) for my T2 instances?"}, {"role": "assistant", "content": "You will want to verify that the minimum memory requirements of your operating system and applications are within the memory allocated for each T2 instance size (for example, 512 MiB for t2.nano). Operating systems with Graphical User Interfaces (GUI) that consume significant memory and CPU, for example Microsoft Windows, might need a t2.micro or larger instance size for many use cases. You can find AMIs suitable for the t2.nano instance types on [AWS Marketplace](https://web.archive.org/web/20240727055400/https://aws.amazon.com/marketplace/search"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I choose a Burstable Performance Instance, such as T2?"}, {"role": "assistant", "content": "T2 instances provide a cost-effective platform for a broad range of general purpose production workloads. T2 Unlimited instances can sustain high CPU performance for as long as required.\u00a0If your workloads consistently require CPU usage much higher than the baseline, consider a dedicated CPU instances such as the M or C."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I see the CPU Credit balance for each T2 instance?"}, {"role": "assistant", "content": "You can see the CPU Credit balance for each T2 instance in EC2 per-Instance metrics in Amazon CloudWatch. T2 instances have four metrics, CPUCreditUsage, CPUCreditBalance, CPUSurplusCreditBalance and CPUSurplusCreditsCharged. CPUCreditUsage indicates the amount of CPU Credits used. CPUCreditBalance indicates the balance of CPU Credits. CPUSurplusCredit Balance indicates credits used for bursting in the absence of earned credits. CPUSurplusCreditsCharged indicates credits that are charged when average usage exceeds the baseline."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens to CPU performance if my T2 instance is running low on credits (CPU Credit balance is near zero)?"}, {"role": "assistant", "content": "If your T2 instance has a zero CPU Credit balance, performance will remain at baseline CPU performance. For example, the t2.micro provides baseline CPU performance of 10% of a physical CPU core. If your instance\u2019s CPU Credit balance is approaching zero, CPU performance will be lowered to baseline performance over a 15-minute interval."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does my T2 instance credit balance persist at stop / start?"}, {"role": "assistant", "content": "No, a stopped instance does not retain its previously earned credit balance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can T2 instances be purchased as Reserved Instances or Spot Instances?"}, {"role": "assistant", "content": "T2 instances can be purchased as On-Demand Instances, Reserved Instances or Spot Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 T4g instances?"}, {"role": "assistant", "content": "Amazon EC2 T4g instances are the next-generation of general purpose burstable instances powered by Arm-based AWS Graviton2 processors. T4g instances deliver up to 40% better price performance over T3 instances. They are built on the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the ideal use cases for T4g instances?"}, {"role": "assistant", "content": "T4g instances deliver up to 40% better price performance over T3 instances for a wide variety of burstable general purpose workloads such as micro-services, low-latency interactive applications, small and medium databases, virtual desktops, development environments, code repositories, and business-critical applications. Customers deploying applications built on open source software across T instances will find the T4g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can customers get access to the T4g free trial?"}, {"role": "assistant", "content": "Until December 31, 2024, all AWS customers will be enrolled automatically in the T4g free trial as detailed in the [AWS Free Tier](/web/20240727055400/https://aws.amazon.com/free/). During the free-trial period, customers who run a t4g.small instance will automatically get 750 free hours per month deducted from their bill during each month. The 750 hours are calculated in aggregate across all Regions in which the t4g.small instances are used. Customers must pay for surplus CPU credits when they exceed the instances allocated credits during the 750 free hours of the T4g free trial program. For more information about how CPU credits work, see [Key concepts and definitions for burstable performance instances](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-credits-baseline-concepts.html)\u00a0in the Amazon EC2 User Guide for Linux Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who is eligible for the T4g free trial?"}, {"role": "assistant", "content": "All existing and new customers with an AWS account can take advantage of the T4g free trial. The T4g free trial is available for a limited time until December 31, 2024. The start and end time of the free trial are based on the Coordinated Universal Time (UTC). The T4g free trial will be available in addition to the existing AWS Free Tier on t2.micro/t3.micro. Customers who have exhausted their t2.micro (or t3.micro, depending on the Region) Free Tier usage can still benefit from the T4g free trial."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the regional availability of T4g free trial?"}, {"role": "assistant", "content": "The T4g free trial is currently available across these AWS Regions: US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), South America (Sao Paulo), Asia Pacific (Hong Kong), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), and Europe (Stockholm). It is currently not available in the China (Beijing) and China (Ningxia) Regions.As part of the free trial, customers can run t4g.small instances across one or multiple Regions from a single cumulative bucket of 750 free hours per month until December 31, 2024. For example, a customer can run t4g.small in Oregon for 300 hours for a month and run another t4g.small in Tokyo for 450 hours during the same month. This would add up to 750 hours per month of the free-trial limit."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there an additional charge for running specific AMIs under the T4g free trial?"}, {"role": "assistant", "content": "Under the t4g.small free trial, there will be no Amazon Machine Image (AMI) charge for Amazon Linux 2, RHEL and SUSE Linux AMIs that are available through the EC2 console Quick Start for the first 750 free hours per month. After 750 free hours per month, regular On-Demand prices, including AMI charge (if any), will apply. The applicable software fees for AWS Marketplace offers with AMI fulfillment options is not included in the free trial. Only the t4g.small infrastructure cost is included and covered under the free trial."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will the t4g.small free trial be reflected on my AWS bill?"}, {"role": "assistant", "content": "The T4g free trial has a monthly billing cycle that starts on the first of every month and ends on the last day of that month. Under the T4g free-trial billing plan, customers using t4g.small will see a $0 line item on their bill under the On-Demand pricing plan for the first 750 aggregate hours of usage for every month during the free-trial period. Customers can start any time during the free-trial period and get 750 free hours for the remainder of that month. Any unused hours from the previous month will not be carried over. Customers can launch multiple t4g.small instances under the free trial. Customers will be notified automatically through email using AWS Budgets when their aggregate monthly usage reaches 85% of 750 free hours. When the aggregate instance usage exceeds 750 hours for the monthly billing cycle, customers will be charged based on regular On-Demand pricing for the exceeded hours for that month. For customers with a Compute Savings Plan or T4g Instance Savings Plan, Savings Plan (SV) discount will be applied to On-Demand pricing for hours exceeding the 750 free trial hours. If customers have purchased the T4g Reserved Instance (RI) plan, the RI plan applies first to any usage on an hourly basis. For any remaining usage after the RI plan has been applied, the free trial billing plan is in effect."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If customers sign up for consolidated billing (or a single payer account), can they get the T4g free trial for each account that is tied to the payer account?"}, {"role": "assistant", "content": "No, customers who use consolidated billing to consolidate payment across multiple accounts will have access to one free trial per Organization. Each payer account gets a total aggregate of 750 free hours a month. For more details about consolidated billing, see [Consolidated billing for AWS Organizations](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html)\u00a0in the AWS Billing and Cost Management User Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will customers get charged for surplus CPU credits as a part of T4g free trial?"}, {"role": "assistant", "content": "Customers must pay for surplus CPU credits when they exceed the instances allocated credits during the 750 free hours of the T4g free trial program. For details about how CPU credits work, see [Key concepts and definitions for burstable performance instances](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-credits-baseline-concepts.html)\u00a0in the Amazon EC2 User Guide for Linux Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: At the end of the free trial, how will customers be billed for t4g.small instances?"}, {"role": "assistant", "content": "Starting January 1, 2025, customers running on t4g.small instances will be automatically switched from the free trial plan to the On-Demand pricing plan (or Reserved Instance (RI)/Savings Plan (SV) plan, if purchased). Accumulated credits will be set to zero. Customers will receive an email notification seven days before the end of the free trial period stating that the free trial period will be ending in seven days. Starting January 1, 2025, if the RI plan is purchased, the RI plans will apply. Otherwise, customers will be charged regular On-Demand pricing for t4g.small instances. For customers who have the T4g Instance Savings Plan or a Compute Savings Plan, t4g.small instance billing will apply the Savings Plan discount on their On-Demand pricing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Compute Optimized instances?"}, {"role": "assistant", "content": "Compute Optimized instances are designed for applications that benefit from high compute power. These applications include compute-intensive applications like high-performance web servers, high-performance computing (HPC), scientific modelling, distributed analytics and machine learning inference."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 C7g instances?"}, {"role": "assistant", "content": "Amazon EC2 C7g instances, powered by the latest generation AWS Graviton3 processors, provide the best price performance in Amazon EC2 for compute-intensive workloads. C7g instances are ideal for high performance computing (HPC), batch processing, electronic design automation (EDA), gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad-serving. They offer up to 25% better performance over the sixth generation AWS Graviton2-based C6g instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 C6g instances?"}, {"role": "assistant", "content": "Amazon EC2 C6g instances are the next-generation of compute-optimized instances powered by Arm-based AWS Graviton2 Processors. C6g instances deliver up to 40% better price performance over C5 instances. They are built on the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the ideal use cases for C6g instances?"}, {"role": "assistant", "content": "C6g instances deliver significant price performance benefits for compute-intensive workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference.\u00a0Customers deploying applications built on open source software across C instances family will find the C6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the various storage options available on C6g instances?"}, {"role": "assistant", "content": "C6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. C6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes.\u00a0Additionally, options with local NVMe instance storage are also available through the C6gd instance types."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which network interface is supported on C6g instances?"}, {"role": "assistant", "content": "C6g instances support ENA based Enhanced Networking. With ENA, C6g instances can deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will customers need to modify their applications and workloads to be able to run on the C6g instances?"}, {"role": "assistant", "content": "The changes required are dependent on the application. Customers running applications built on open source software will find that the Arm ecosystem is well developed and already likely supports their applications. Most Linux distributions as well as containers (Docker, Kubernetes, Amazon ECS, Amazon EKS, Amazon ECR) support the Arm architecture. Customers will find Arm versions of commonly used software packages available for installation through the same mechanisms that they currently use. Applications that are based on interpreted languages (such as Java, Node, Python) not reliant on native CPU instruction sets should run with minimal to no changes. Applications developed using compiled languages (C, C++, GoLang) will need to be re-compiled to generate Arm binaries. The Arm architecture is well supported in these popular programming languages and modern code usually requires a simple \u2018Make\u2019 command. Refer to the [Getting Started guide on GitHub](https://web.archive.org/web/20240727055400/https://github.com/aws/aws-graviton-gettting-started) for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will there be more compute choices offered with the C6 instance families?"}, {"role": "assistant", "content": "Yes, we plan to offer Intel and AMD CPU powered instances in the future as part of the C6 instance families."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I launch C4 instances as Amazon EBS-optimized instances?"}, {"role": "assistant", "content": "Each C4 instance type is EBS-optimized by default. C4 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on C4 instances, launching a C4 instance explicitly as EBS-optimized will not affect the instance's behavior."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I use the processor state control feature available on the c4.8xlarge instance?"}, {"role": "assistant", "content": "The c4.8xlarge instance type provides the ability for an operating system to control processor C-states and P-states. This feature is currently available only on Linux instances. You may want to change C-state or P-state settings to increase processor performance consistency, reduce latency, or tune your instance for a specific workload. By default, Amazon Linux provides the highest-performance configuration that is optimal for most customer workloads; however, if your application would benefit from lower latency at the cost of higher single- or dual-core frequencies, or from lower-frequency sustained performance as opposed to bursty Turbo Boost frequencies, then you should consider experimenting with the C-state or P-state configuration options that are available to these instances. For additional information on this feature, see the Amazon EC2 User Guide section on [Processor State Control](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/processor_state_control.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instances are available within Compute Optimized instances category?"}, {"role": "assistant", "content": "C6g instances: Amazon EC2 C6g instances are powered by Arm-based AWS Graviton2 processors. They deliver up to 40% better price performance over C5 instances and are ideal for running advanced compute-intensive workloads. This includes workloads such as high performance computing (HPC), batch processing, ad serving, video encoding, gaming, scientific modelling, distributed analytics, and CPU-based machine learning inference.\u00a0C6a instances:\u00a0C6a instances are powered by 3rd generation AMD EPYC processors with an all-core turbo frequency of 3.6 GHz, offer up to 15% better price performance over C5a instances for a wide variety of workloads, and support always-on memory encryption using AMD [Transparent Single Key Memory Encryption](https://web.archive.org/web/20240727055400/https://developer.amd.com/sev/) (TSME). C6a instances provide new instance sizes with up to 192 vCPUs and 384 GiB of memory, double that of the largest C5a instance. C6a also gives customers up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the [Amazon Elastic Block Store](/web/20240727055400/https://aws.amazon.com/ebs/), more than twice that of C5a instances. C6i instances: C6i instances are powered by 3rd generation Intel Xeon Scalable processors with an all-core turbo frequency of 3.5 GHz, offer up to 15% better price performance over C5 instances for a wide variety of workloads, and always-on memory encryption using Intel Total Memory encryption (TME). C6i instances provide a new instance size (c6i.32xlarge) with 128 vCPUs and 256 GiB of memory, 33% more than the largest C5 instance. They also provide up to 9% higher memory bandwidth per vCPU compared to C5 instances. C6i also give customers up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the [Amazon Elastic Block Store](/web/20240727055400/https://aws.amazon.com/ebs/), twice that of C5 instances. C6i are also available with local NVMe-based SSD block-level storage (C6id instances) for applications that need high-speed, low-latency local storage. Compared to previous generation C5d instances, C6id instances offer up to 138% higher TB storage per vCPU and 56% lower cost per TB. C5 instances:\u00a0C5 instances are based on Intel Xeon Platinum processors, part of the Intel Xeon Scalable (codenamed Skylake-SP or Cascade Lake) processor family, are available in 9 sizes, and offer up to 96 vCPUs and 192 GiB memory. C5 instances deliver 25% improvement in price/performance compared to C4 instances. The C5d instances have local NVMe storage for workloads that require very low latency and storage access with high random read and write IOPS ability.C5a instances: C5a instances deliver leading x86 price-performance for a broad set of compute-intensive workloads including batch processing, distributed analytics, data transformations, log analysis, and web applications. C5a instances feature 2nd Gen 3.3GHz AMD EPYC processors with up to 96 vCPUs and up to 192 GiB of memory. The C5ad instances have local NVMe storage for workloads that require very low latency and storage access with high random read and write IOPS ability.C5n instances: C5n instances are ideal for applications requiring high network bandwidth and packet rate. The C5n instances are ideal for applications like HPC, data lakes, network appliances as well as applications that require inter-node communication and the Message Passing Interface (MPI). C5n offer a choice of Intel Xeon Platinum 3.0 GHz processors with up to 72 vCPUs and 192GiB of Memory.C4 instances: C4 instances are based on Intel Xeon E5-2666 v3 (codenamed Haswell) processors. C4 instances are available in 5 sizes and offer up to 36 vCPUs and 60 GiB memory."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should customers choose C6i instances over C5 instances?"}, {"role": "assistant", "content": "C6i instances offer up to 15% better price performance over C5 instances, and always-on memory encryption using Intel Total Memory encryption (TME). C6i instances provide a new instance size (c6i.32xlarge) with 128 vCPUs and 256 GiB of memory, 33% more than the largest C5 instance. They also provide up to 9% higher memory bandwidth per vCPU compared to C5 instances. C6i also give customers up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the [Amazon Elastic Block Store](/web/20240727055400/https://aws.amazon.com/ebs/), twice that of C5 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should customers choose C5 instances over C4 instances?"}, {"role": "assistant", "content": "The generational improvement in CPU performance and lower price of C5 instances, which combined result in a 25% price/performance improvement relative to C4 instances, benefit a broad spectrum of workloads that currently run on C3 or C4 instances. For floating point intensive applications, Intel AVX-512 enables significant improvements in delivered TFLOPS by effectively extracting data level parallelism. Customers looking for absolute performance for graphics rendering and HPC workloads that can be accelerated with GPUs or FPGAs should also evaluate other instance families in the Amazon EC2 portfolio that include those resources to find the ideal instance for their workload."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which storage interface is supported on C5 instances?"}, {"role": "assistant", "content": "C5 instances will support only NVMe EBS device model. EBS volumes attached to C5 instances will appear as NVMe devices. NVMe is a modern storage interface that provides latency reduction and results in increased disk I/O and throughput."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why does the total memory reported by the operating system not exactly match the advertised memory on instance types?"}, {"role": "assistant", "content": "Portions of the EC2 instance memory are reserved and used by the virtual BIOS for video RAM, DMI, and ACPI. In addition, for instances that are powered by the AWS Nitro Hypervisor, a small percentage of the instance memory is reserved by the Amazon EC2 Nitro Hypervisor to manage virtualization."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instances are available within the high performance computing (HPC) instances category?"}, {"role": "assistant", "content": "Hpc7g instances:\u00a0Hpc7g instances enable the best price performance for HPC workloads on AWS.\u00a0They deliver up to 70% better performance and almost 3x better price performance compared to previous-generation AWS Graviton-based instances for compute-intensive HPC workloads. Hpc7g instances are powered by AWS Graviton 3E processors and provide up to 35% higher vector instruction performance compared to existing AWS Graviton3 instances.\u00a0These instances provide up to 2x better floating-point performance compared to instances powered by Graviton2 processors.\u00a0Hpc7g instances are built on the\u00a0[AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/)\u00a0and provide 200 Gbps network bandwidth for low-latency internode communication for tightly coupled workloads that require highly parallelized, clustered compute resources.Hpc7a instances:\u00a0Amazon Elastic Compute Cloud (Amazon EC2) Hpc7a instances, powered by 4th Gen AMD EPYC processors, deliver up to 2.5x better performance compared to Amazon EC2 Hpc6a instances. Hpc7a instances feature 2x higher core density (up to 192 cores), 2.1x higher memory bandwidth throughput (up to 768 GB of memory), and 3x higher network bandwidth compared to Hpc6a instances. These instances offer 300 Gbps of\u00a0[Elastic Fabric Adapter (EFA)](/web/20240727055400/https://aws.amazon.com/hpc/efa/)\u00a0network bandwidth, powered by the\u00a0[AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), for fast and low latency inter-node communications.Hpc6id instances:\u00a0Hpc6id instances are powered by 64 cores of Intel 3rd Gen Xeon Scalable processors that run at frequencies up to 3.5 GHz for increased efficiency. These instances are designed to improve performance for memory-bound workloads by offering 5 GB/s memory bandwidth per vCPU. Hpc6id instances offer 200 Gbps EFA networking for high-throughput internode communications to help you run your HPC workloads at scale.Hpc6a instances:\u00a0Hpc6a instances are powered by 96 cores of 3rd Gen AMD EPYC processors with an all-core turbo frequency of 3.6 GHz and 384 GiB RAM. Hpc6a instances offer 100 Gbps EFA networking enabled for high throughput internode communications to help you run your HPC workloads at scale."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are Hpc7g instances different from other EC2 instances?"}, {"role": "assistant", "content": "Hpc7g instances are optimized to deliver capabilities suited for compute-intensive HPC workloads. Hpc7g instances are based on Arm-based Graviton3E processors that provide up to 35% higher vector instruction performance compared to existing instances based on Graviton3 processors. These instances deliver 64 physical cores, 128 GiB memory, and 200 Gbps network bandwidth optimized for traffic between instances in the same VPC and support EFA for increased network performance. Hpc7g instances are available in single Availability Zone deployments, enabling workloads to achieve the low-latency network performance necessary for tightly coupled node-to-node communication for HPC applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which pricing models do Hpc7g instances support?"}, {"role": "assistant", "content": "Hpc7g instances are available for purchase through the 1- and 3-year\u00a0[Amazon EC2 Instance Savings Plans](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html#plan-types),\u00a0[Compute Savings Plans](/web/20240727055400/https://aws.amazon.com/savingsplans/compute-pricing/),\u00a0[EC2 On-Demand Instances](/web/20240727055400/https://aws.amazon.com/ec2/pricing/),\u00a0and\u00a0[EC2 Reserved Instances.](/web/20240727055400/https://aws.amazon.com/ec2/pricing/reserved-instances/)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs are supported on Hpc7g instances?"}, {"role": "assistant", "content": "Hpc7g instances support Amazon EBS backed AMIs only."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are Hpc7a instances different from other EC2 instances?"}, {"role": "assistant", "content": "HPC-optimized EC2 Hpc7a instances are ideal for applications that benefit from high-performance processors such as large, complex simulations including computational fluid dynamics (CFD), numerical weather prediction, and multiphysics simulations. Hpc7a instances are designed to help you run tightly coupled, x86-based HPC workloads with better performance. Hpc7a instances feature 4th Gen AMD EPYC processors with 2x higher core density (up to 192 cores), 2.1x higher memory bandwidth throughput (768 GB of memory), and 3x higher network bandwidth compared to Hpc6a instances. These instances offer 300 Gbpsof\u00a0[EFA\u00a0](/web/20240727055400/https://aws.amazon.com/hpc/efa/)network bandwidth, powered by the\u00a0[AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), for\u00a0for fast and low latency internode communications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which pricing models do Hpc7a instances support?"}, {"role": "assistant", "content": "Hpc7a instances are available for purchase through the 1- and 3-year [Amazon\u00a0EC2 Instance Savings Plans](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html#plan-types),[\u00a0Compute Savings Plans](/web/20240727055400/https://aws.amazon.com/savingsplans/compute-pricing/),[\u00a0EC2 On-Demand Instances,](/web/20240727055400/https://aws.amazon.com/ec2/pricing/"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs are supported on Hpc7a instances?"}, {"role": "assistant", "content": "Hpc7a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.6 or later, SUSE Linux Enterprise Server 12 SP3 or later, CentOS 7 or later, and FreeBSD 11.1 or later."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which pricing models do Hpc6id instances support?"}, {"role": "assistant", "content": "Hpc6id instances are available for purchase through the 1-year and 3-year\u00a0[Amazon EC2 Instance Savings Plans](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html#plan-types),\u00a0[Compute Savings Plans](/web/20240727055400/https://aws.amazon.com/savingsplans/compute-pricing/),\u00a0[EC2 On-Demand Instances](/web/20240727055400/https://aws.amazon.com/ec2/pricing/"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are Hpc6id instances different from other EC2 instances?"}, {"role": "assistant", "content": "Hpc6id instances are optimized to deliver capabilities suited for memory-bound, data-intensive HPC workloads. Hyperthreading is disabled to increase per-vCPU CPU throughput and up to 5 GB/s memory bandwidth per vCPU. These instances deliver 200 Gbps network bandwidth optimized for traffic between instances in the same virtual private cloud (VPC), and support EFA for increased network performance. To optimize Hpc6id instances networking for tightly coupled workloads, you can access EC2 Hpc6id instances in a single Availability Zone in each Region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs are supported on Hpc6id instances?"}, {"role": "assistant", "content": "Hpc6id supports Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, Windows Server 2008 R2 or earlier, and FreeBSD 11.1 or later."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs are supported on Hpc6a instances?"}, {"role": "assistant", "content": "Hpc6a instances support Amazon Linux 2, Amazon Linux, Ubuntu 18.04 or later, Red Hat Enterprise Linux 7.4 or later, SUSE Linux Enterprise Server 12 SP2 or later, CentOS 7 or later, and FreeBSD 11.1 or later. These instances also support Windows Server 2012, 2012 R2, 2016, and 2019."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which pricing models do Hpc6a instances support?"}, {"role": "assistant", "content": "Hpc6a instances are available for purchase through 1-year and 3-year Standard Reserved Instances, Convertible Reserved Instances, Savings Plans, and On-Demand Instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 M6g instances?"}, {"role": "assistant", "content": "Amazon EC2 M6g instances are the next-generation of general-purpose instances powered by Arm-based AWS Graviton2 Processors. M6g instances deliver up to 40% better price/performance over M5 instances. They are built on the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the specifications of the new AWS Graviton2 Processors?"}, {"role": "assistant", "content": "The AWS Graviton2 processors deliver up to 7x performance, 4x the number of compute cores, 2x larger caches, 5x faster memory, and 50% faster per core encryption performance than first generation AWS Graviton processors. Each core of the AWS Graviton2 processor is a single-threaded vCPU. These processors also offer always-on fully encrypted DRAM memory, hardware acceleration for compression workloads, dedicated engines per vCPU that double the floating-point performance for workloads such as video encoding, and instructions for int8/fp16 CPU-based machine learning inference acceleration. The CPUs are built utilizing 64-bit Arm Neoverse cores and custom silicon designed by AWS on the advanced 7 nm manufacturing technology."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is memory encryption supported by AWS Graviton2 processors?"}, {"role": "assistant", "content": "AWS Graviton2 processors support always-on 256-bit memory encryption to further enhance security. Encryption keys are securely generated within the host system, do not leave the host system, and are irrecoverably destroyed when the host is rebooted or powered down. Memory encryption does not support integration with AWS Key Management Service (AWS KMS) and customers cannot bring their own keys."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the ideal use cases for M6g instances?"}, {"role": "assistant", "content": "M6g instances deliver significant performance and price performance benefits for a broad spectrum of general-purpose workloads such as application servers, gaming servers, microservices, mid-size databases, and caching fleets.\u00a0Customers deploying applications built on open source software across the M instances will find the M6g instances an appealing option to realize the best price performance. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the various storage options available on M6g instances?"}, {"role": "assistant", "content": "M6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. M6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes.\u00a0Additionally, options with local NVMe instance storage are also available through the M6gd instance types."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which network interface is supported on M6g instances?"}, {"role": "assistant", "content": "M6g instances support ENA based Enhanced Networking. With ENA, M6g instances can deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will customers need to modify their applications and workloads to be able to run on the M6g instances?"}, {"role": "assistant", "content": "The changes required are dependent on the application. Customers running applications built on open source software will find that the Arm ecosystem is well developed and already likely supports their applications. Most Linux distributions as well as containers (Docker, Kubernetes, Amazon ECS, Amazon EKS, Amazon ECR) support the Arm architecture. Customers will find Arm versions of commonly used software packages available for installation through the same mechanisms that they currently use. Applications that are based on interpreted languages (such as Java, Node, Python) not reliant on native CPU instruction sets should run with minimal to no changes. Applications developed using compiled languages (C, C++, GoLang) will need to be re-compiled to generate Arm binaries. The Arm architecture is well supported in these popular programming languages and modern code usually requires a simple \u2018Make\u2019 command. Refer to the [Getting Started guide on GitHub](https://web.archive.org/web/20240727055400/https://github.com/aws/aws-graviton-gettting-started) for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 A1 instances?"}, {"role": "assistant", "content": "Amazon EC2 A1 instances are general purpose instances powered by the first-generation AWS Graviton Processors that are custom designed by AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the specifications of the first-generation AWS Graviton Processors?"}, {"role": "assistant", "content": "AWS Graviton processors are custom designed by AWS utilizing Amazon\u2019s extensive expertise in building platform solutions for cloud applications running at scale. These processors are based on the 64-bit Arm instruction set and feature Arm Neoverse cores as well as custom silicon designed by AWS. The cores operate at a frequency of 2.3 GHz."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use A1 instances?"}, {"role": "assistant", "content": "A1 instances deliver significant cost savings for scale-out workloads that can fit within the available memory footprint. A1 instances are ideal for scale-out applications such as web servers, containerized microservices, and data/log processing. These instances will also appeal to developers, enthusiasts, and educators across the Arm developer community."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will customers have to modify applications and workloads to be able to run on the A1 instances?"}, {"role": "assistant", "content": "The changes required are dependent on the application. Applications based on interpreted or run-time compiled languages (e.g. Python, Java, PHP, Node.js) should run without modifications. Other applications may need to be recompiled and those that don't rely on x86 instructions will generally build with minimal to no changes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which operating systems/AMIs are supported on A1 Instances?"}, {"role": "assistant", "content": "The following AMIs are supported on A1 instances: Amazon Linux 2, Ubuntu 16.04.4 or newer, Red Hat Enterprise Linux (RHEL) 7.6 or newer, SUSE Linux Enterprise Server 15 or newer. Additional AMI support for Fedora, Debian, NGINX Plus are also available through community AMIs and the AWS Marketplace. EBS backed HVM AMIs launched on A1 instances require NVMe and ENA drivers installed at instance launch."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there specific AMI requirements to run on M6g and A1 instances?"}, {"role": "assistant", "content": "You will need to use the \u201carm64\u201d AMIs with the M6g and A1 instances. x86 AMIs are not compatible with M6g and A1 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should customers use A1 instances versus the new M6g instances?"}, {"role": "assistant", "content": "A1 instances continue to offer significant cost benefits for scale-out workloads that can run on multiple smaller cores and fit within the available memory footprint. The new M6g instances are a good fit for a broad spectrum of applications that require more compute, memory, networking resources and/or can benefit from scaling up across platform capabilities. M6g instances will deliver the best price-performance within the instance family for these applications. M6g supports up to 16xlarge instance size (A1 supports up to 4xlarge), 4GB of memory per vCPU (A1 supports 2GB memory per vCPU), and up to 25 Gbps of networking bandwidth (A1 supports up to 10 Gbps)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the various storage options available to A1 customers?"}, {"role": "assistant", "content": "A1 instances are EBS-optimized by default and offer up to 3,500 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. A1 instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. A1 instances will not support the blkfront interface."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which network interface is supported on A1 instances?"}, {"role": "assistant", "content": "A1 instances support ENA based Enhanced Networking. With ENA, A1 instances can deliver up to 10 Gbps of network bandwidth between instances when launched within a Placement Group."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do A1 instances support the AWS Nitro System?"}, {"role": "assistant", "content": "Yes, A1 instances are powered by the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should customers choose EC2 M5 Instances over EC2 M4 Instances?"}, {"role": "assistant", "content": "Compared with EC2 M4 Instances, the new EC2 M5 Instances deliver customers greater compute and storage performance, larger instance sizes for less cost, consistency and security. The biggest benefit of EC2 M5 Instances is based on its usage of the latest generation of Intel Xeon Scalable processors (Skylake-SP or Cascade Lake), which deliver up to 20% improvement in price/performance compared to M4. With AVX-512 support in M5 vs. the older AVX2 in M4, customers will gain 2x higher performance in workloads requiring floating point operations. M5 instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. M5 instances also feature significantly higher networking and Amazon EBS performance on smaller instance sizes with EBS burst capability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should customers choose M6i instances over M5 instances?"}, {"role": "assistant", "content": "Amazon [M6i instances](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/m6i/) are powered by 3rd generation Intel Xeon Scalable processors (code named Ice Lake) with an all-core turbo frequency of 3.5 GHz, offer up to 15% better compute price performance over M5 instances, and always-on memory encryption using Intel Total Memory Encryption (TME). Amazon EC2 M6i instances are the first to use a lower-case \u201ci\u201d to indicate they are Intel-powered instances. M6i instances provide a new instance size (m6i.32xlarge) with 128 vCPUs and 512 GiB of memory, 33% more than the largest M5 instance. They also provide up to 20% higher memory bandwidth per vCPU compared to M5 instances, allowing customers to efficiently perform real-time analysis for data-intensive AI/ML, gaming, and High Performance Computing (HPC) applications.\u00a0M6i also give customers up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the [Amazon\u00a0Elastic Block Store](/web/20240727055400/https://aws.amazon.com/ebs/), twice that of M5 instances.\u00a0M6i also allows customers to use [Elastic Fabric Adapter](/web/20240727055400/https://aws.amazon.com/hpc/efa/) on the 32xlarge size, enabling low latency and high scale inter-node communication.\u00a0For optimal networking performance on these new instances, Elastic Network Adapter (ENA) driver update may be required. For more information on optimal ENA driver for M6i, see [this article.](/web/20240727055400/https://aws.amazon.com/premiumsupport/knowledge-center/migrate-to-gen6-ec2-instance/)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does support for Intel AVX-512 benefit customers who use the EC2 M5 family or the M6i family?"}, {"role": "assistant", "content": "Intel Advanced Vector Extensions 512 (AVX-512) is a set of new CPU instructions available on the latest Intel Xeon Scalable processors, that can accelerate performance for workloads and usages such as scientific simulations, financial analytics, artificial intelligence, machine learning/deep learning, 3D modeling and analysis, image and video processing, cryptography and data compression, among others.\u00a0Intel AVX-512 offers exceptional processing of encryption algorithms, helping to reduce the performance overhead for cryptography, which means customers who use the EC2 M5 family or M6i family can deploy more secure data and services into distributed environments without compromising performance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are M5zn instances?"}, {"role": "assistant", "content": "M5zn instances are a variant of the M5 general purpose instances that are powered by the fastest Intel Xeon Scalable processor in the cloud, with an all-core turbo frequency of up to 4.5 GHz, along with 100 Gbps networking and support for Amazon EFA. M5zn instances are an ideal fit for workloads such as gaming, financial applications, simulation modeling applications such as those used in the automotive, aerospace, energy, and telecommunication industries, and other High Performance Computing applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are M5zn instances different than z1d instances?"}, {"role": "assistant", "content": "z1d instances are a memory-optimized instance, and feature a high frequency version of the Intel Xeon Scalable processors (up to 4.0 GHz), along with local NVMe storage. M5zn instances are a general purpose instance, and feature a high frequency version of the 2nd Generation Intel Xeon Scalable processors up to 4.5 GHz), along with up to 100 Gbps networking performance, and support for EFA. M5zn instances offer improved price performance compared to z1d."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 High Memory instances?"}, {"role": "assistant", "content": "Amazon EC2 High Memory (U-1 and U7i) instances offer 3, 6, 9, 12, 16, 18, 24, or 32 TiB of memory in a single instance. These instances are designed to run large in-memory databases, including production installations of SAP HANA, in the cloud.EC2 High Memory (U-1) instances with 3, 6, 9, and 12 TiB are powered by an 8-socket platform with Intel\u00ae Xeon\u00ae Platinum 8176M (Skylake) or 8280L (Cascade Lake) processors. EC2 High Memory (U-1) instances with 18 TiB and 24 TiB are powered by an 8-socket platform with 2nd Generation Intel\u00ae Xeon\u00ae Scalable 8280L (Cascade Lake) processors.Amazon EC2 U7i instances are powered by 1.9 GHz (Turbo Boost to 2.90 GHz) 4th Generation Intel Xeon Scalable processors (Sapphire Rapids). U7i instances are the first DDR5 memory based 8-socket offering by a leading cloud provider. U7i instances offer up to 45% better price performance over existing U-1 instances. U7i instances have support for 896 vCPUs, and 2.5x Elastic Block Store (EBS) bandwidth vs\u00a0[Amazon EC2 High Memory (U-1) instances](https://web.archive.org/web/20240727055400/https://aws.amazon.com/ec2/instance-types/high-memory/).Amazon EC2 High Memory instances offer up to 100Gbps of Elastic Block Store (EBS) bandwidth for storage volumes including io2 Block Express to support IO-intensive use cases such as data hydration, backup/restore."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are High Memory instances certified by SAP to run SAP HANA workloads?"}, {"role": "assistant", "content": "High Memory (U-1 and U7i) instances with 3, 6, 9, 12, 16, 18, 24 TiB of memory are certified by SAP for running Business Suite on HANA, the next-generation Business Suite S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, and SAP BW/4HANA in production environments.\u00a0For details, [see\u00a0SAP's Certified and Supported SAP HANA Hardware Directory](https://web.archive.org/web/20240727055400/https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN/#/solutions"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What instance types are available for High Memory instances?"}, {"role": "assistant", "content": "High Memory instances are available as both bare metal (U-1 only) and virtualized instances (U-1 and U7i), giving customers the choice to have direct access to the underlying hardware resources, or to take advantage of the additional flexibility that virtualized instances offer including On-Demand and 1-year and 3-year Savings Plan purchase options. Please check out available options for High Memory instances in the Memory optimized section of\u00a0[EC2 Instance types page](https://web.archive.org/web/20240727055400/https://aws.amazon.com/ec2/instance-types/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the benefits of using High Memory Virtualized instances over High Memory Bare Metal instances?"}, {"role": "assistant", "content": "Benefits of High Memory virtual instances over High Memory Metal instances include \u2013 significantly better launch/reboot times, flexible purchase options (On-Demand, Savings Plan, Reserved Instances, Dedicated Hosts), choice of tenancy type, self-service options and support for a higher number of EBS volumes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should a High Memory \u2018Metal\u2019 instance be used vs using High Memory \u2018Virtualized\u2019 instance?"}, {"role": "assistant", "content": "Though High Memory \u2018Virtualized\u2019 instances are in-general recommended to be used, there are specific situations where only High Memory Metal instances can work. These situations include \u2013 when using OS versions that are not supported on High Memory Virtual instances OR when using applications that need to run in non-virtualized mode to meet licensing / support requirements OR when using applications that require access to hardware feature set (such as Intel VT-x) OR when using custom hypervisor (e.g, ESXi)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I migrate from High Memory metal instances to High Memory virtualized instances?"}, {"role": "assistant", "content": "You can migrate your High Memory metal instance to a virtualized instance in just few steps. 1/Stop your instance, 2/ Change the instance and tenancy type through EC2 API and 3/ Start your instance back up. If you are using Red Hat Enterprise Linux for SAP or SUSE Linux Enterprise Server for SAP, you need to ensure that your operating system and kernel versions are compatible with virtualized High Memory instances. For further details, see\u00a0[Migrating SAP HANA on AWS to an EC2 High Memory Instance](Migrating%20SAP%20HANA%20on%20AWS%20to%20an%20EC2%20High%20Memory%20Instance)\u00a0documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the storage options available with High Memory instances?"}, {"role": "assistant", "content": "High Memory instances support Amazon EBS volumes for storage. High Memory instances are EBS-optimized by default."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which storage interface is supported on High Memory instances?"}, {"role": "assistant", "content": "High Memory instances access EBS volumes via\u00a0[PCI attached NVM Express (NVMe) interfaces](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/nvme-ebs-volumes.html). EBS volumes attached to High Memory instances appear as NVMe devices. NVMe is an efficient and scalable storage interface, which is commonly used for flash based SSDs and provides latency reduction and results in increased disk I/O and throughput. The EBS volumes are attached and detached by PCI hotplug."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What network performance is supported on High Memory instances?"}, {"role": "assistant", "content": "High Memory instances use the Elastic Network Adapter (ENA) for networking and enable\u00a0[Enhanced Networking](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html) by default. With ENA, High Memory instances can utilize up to 100 Gbps (U-1) and up to 200Gbps (U7i) of network bandwidth"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I run High Memory instances in my existing Amazon Virtual Private Cloud (Amazon VPC)?"}, {"role": "assistant", "content": "You can run High Memory instances in your existing and new Amazon VPCs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the underlying hypervisor on High Memory instances?"}, {"role": "assistant", "content": "High Memory instances use the lightweight Nitro Hypervisor that is based on core KVM technology."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do High Memory instances enable CPU power management state control?"}, {"role": "assistant", "content": "Yes. You can configure C-states and P-states on High Memory (U-1 metal) instances.\u00a0 You can configure C-states on both U-1 and U7i virtual instances.\u00a0\u00a0 You can use C-states to enable higher turbo frequencies (as much as 4.0 GHz). You can also use P-states to lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo, and running consistently at the base CPU clock speed."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What purchase options are available for High Memory instances?"}, {"role": "assistant", "content": "EC2 High Memory virtualized instances are available for purchase via On-Demand, 1-Yr and 3-Yr Savings Plan, and 1-Yr and 3-Yr Reserved Instance. EC2 High Memory metal instances are only available for purchase as EC2 Dedicated Hosts on a 1-Yr and 3-Yr Reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the lifecycle of a Dedicated Host?"}, {"role": "assistant", "content": "Once a Dedicated Host is allocated within your account, it will be standing by for your use. You can then launch an instance with a tenancy of \"host\" using the RunInstances API, and can also stop/start/terminate the instance through the API. You can use the AWS Management Console to manage the Dedicated Host and the instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I launch, stop/start, and terminate High Memory instances using AWS CLI/SDK?"}, {"role": "assistant", "content": "You can launch, stop/start, and terminate instances using AWS CLI/SDK."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which AMIs are supported with High memory instances?"}, {"role": "assistant", "content": "EBS-backed HVM AMIs with support for ENA networking can be used with High Memory instances. The latest Amazon Linux, Red Hat Enterprise Linux, SUSE Enterprise Linux Server, and Windows Server AMIs are supported. Operating system support for SAP HANA workloads on High Memory instances include: SUSE Linux Enterprise Server 12 SP3 for SAP, Red Hat Enterprise Linux 7.4 for SAP, Red Hat Enterprise Linux 7.5 for SAP, SUSE Linux Enterprise Server 12 SP4 for SAP, SUSE Linux Enterprise Server 15 for SAP, Red Had Enterprise Linux 7.6 for SAP. Refer to [SAP on AWS Technical Documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/sap/latest/sap-hana/migrating-hana-to-hm.html) for the latest details on supported operating systems."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there standard SAP HANA reference deployment frameworks available for the High Memory instance and the AWS Cloud?"}, {"role": "assistant", "content": "You can use the [AWS Quick Start reference SAP HANA](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/quickstart/latest/sap-hana/welcome.html) deployments to rapidly deploy all the necessary SAP HANA building blocks on High Memory instances following SAP\u2019s recommendations for high performance and reliability. AWS Quick Starts are modular and customizable, so you can layer additional functionality on top or modify them for your own implementations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use memory-optimized instances?"}, {"role": "assistant", "content": "Memory-optimized instances offer large memory size for memory intensive applications including in-memory applications, in-memory databases, in-memory analytics solutions, HPC, scientific computing, and other memory-intensive applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 R6g instances?"}, {"role": "assistant", "content": "Amazon EC2 R6g instances are the next-generation of memory-optimized instances powered by Arm-based AWS Graviton2 Processors. R6g instances deliver up to 40% better price performance over R5 instances. They are built on the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/), a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the ideal use cases for R6g instances?"}, {"role": "assistant", "content": "R6g instances deliver significant price performance benefits for memory-intensive workloads such as instances and are ideal for running memory-intensive workloads such as open-source databases, in-memory caches, and real time big data analytics. Customers deploying applications built on open source software across R instances will find the R6g instances an appealing option to realize the best price performance within the instance family. Arm developers can also build their applications directly on native Arm hardware as opposed to cross-compilation or emulation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the various storage options available on R6g instances?"}, {"role": "assistant", "content": "R6g instances are EBS-optimized by default and offer up to 19,000 Mbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes. R6g instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes.\u00a0Additionally, options with local NVMe instance storage are also available through the R6gd instance types."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which network interface is supported on R6g instances?"}, {"role": "assistant", "content": "R6g instances support ENA based Enhanced Networking. With ENA, R6g instances can deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will customers need to modify their applications and workloads to be able to run on the R6g instances?"}, {"role": "assistant", "content": "The changes required are dependent on the application. Customers running applications built on open source software will find that the Arm ecosystem is well developed and already likely supports their applications. Most Linux distributions as well as containers (Docker, Kubernetes, Amazon ECS, Amazon EKS, Amazon ECR) support the Arm architecture. Customers will find Arm versions of commonly used software packages available for installation through the same mechanisms that they currently use. Applications that are based on interpreted languages (such as Java, Node, Python) not reliant on native CPU instruction sets should run with minimal to no changes. Applications developed using compiled languages (C, C++, GoLang) will need to be re-compiled to generate Arm binaries. The Arm architecture is well supported in these popular programming languages and modern code usually requires a simple \u2018Make\u2019 command. Refer to the [Getting Started guide on GitHub](https://web.archive.org/web/20240727055400/https://github.com/aws/aws-graviton-gettting-started) for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should you choose R6i instances over R5 instances?"}, {"role": "assistant", "content": "[Amazon R6i instances](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/r6i/) are powered by 3rd Generation Intel Xeon Scalable processors (Ice Lake) with an all-core turbo frequency of 3.5 GHz, offer up to 15% better compute price performance over R5 instances, and always-on memory encryption using Intel Total Memory Encryption (TME). Amazon EC2 R6i instances use a lower-case \u201ci\u201d to indicate they are Intel-powered instances. R6i instances provide a new instance size (r6i.32xlarge) with 128 vCPUs and 1,024 GiB of memory, 33% more than the largest R5 instance. They also provide up to 20% higher memory bandwidth per vCPU compared to R5 instances, allowing you to efficiently perform real-time analysis for data-intensive AI/ML, gaming, and high performance computing (HPC) applications.\u00a0R6i instances also give you up to 50 Gbps of networking speed and 40 Gbps of bandwidth to the [Amazon\u00a0Elastic Block Store](/web/20240727055400/https://aws.amazon.com/ebs/), twice that of R5 instances.\u00a0With R6i instances, you can use Elastic Fabric Adapter allows customers to use [Elastic Fabric Adapter (EFA)](/web/20240727055400/https://aws.amazon.com/hpc/efa/) on the 32xlarge and metal sizes, enabling low-latency and high-scale inter-node communication. For optimal networking performance on these new instances, Elastic Network Adapter (ENA) driver update may be required. For more information\u00a0about an optimal ENA driver for R6i, see [\"What do I need to do before migrating my EC2 instance to a sixth-generation instance"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 R5b instances?"}, {"role": "assistant", "content": "R5b instances are EBS-optimized variants of memory-optimized R5 instances that deliver up to 3x better EBS performance compared to same sized R5 instances. R5b instances deliver up to 60 Gbps bandwidth and 260K IOPS of EBS performance, the fastest block storage performance on EC2. They are built on the AWS Nitro System, which is a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are some of the ideal use cases for R5b instances?"}, {"role": "assistant", "content": "R5b instances are ideal for large relational database workloads, including Microsoft SQL Server, SAP HANA, IBM DB2, and Oracle that run performance intensive applications such as commerce platforms, ERP systems, and health record systems. Customers looking to migrate large on-premises workloads with large storage performance requirements to AWS will find R5b instances to be a good fit."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the various storage options available on R5b instances?"}, {"role": "assistant", "content": "R5b instances are EBS-optimized by default and offer up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS for both encrypted and unencrypted EBS volumes. R5b instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. R5b is supported by all volume types, with the exception of io2 volumes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use R5b instances?"}, {"role": "assistant", "content": "Customers running workloads such as large relational databases and data analytics that want to take advantage of the increased EBS storage network performance can use R5b instances to deliver higher performance and bandwidth. Customers can also lower costs by migrating their workloads to smaller size R5b instances or by consolidating workloads on fewer R5b instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the storage options available with High Memory instances?"}, {"role": "assistant", "content": "High Memory instances support Amazon EBS volumes for storage. High Memory instances are EBS-optimized by default, and offer up to 38Gbps of storage bandwidth to both encrypted and unencrypted EBS volumes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 X2gd instances?"}, {"role": "assistant", "content": "Amazon EC2 X2gd instances are the next generation of memory-optimized instances powered by AWS-designed Arm-based AWS Graviton2 processors. X2gd instances deliver up to 55% better price performance compared to x86-based X1 instances and offer the lowest cost per GiB of memory in Amazon EC2.\u00a0They are the first of the X instances to be built on the AWS Nitro System, which is a combination of dedicated hardware and Nitro hypervisor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What workloads are suited for X2gd instances?"}, {"role": "assistant", "content": "X2gd is ideal for customers with Arm-compatible memory bound scale-out workloads such as Redis and Memcached in-memory databases, that need low latency memory access and benefit from more memory per vCPU. X2gd is also well suited for relational databases such as PostgreSQL, MariaDB, MySQL, and RDS Aurora. Customers who run memory intensive workloads such as Apache Hadoop, real-time analytics, and real-time caching servers will benefit from 1:16 vCPU to memory ratio of X2gd. Single threaded workloads such as EDA backend verification jobs will benefit from physical core and more memory of X2gd instances, allowing them to consolidate more workloads on to a single instance. X2gd instance also feature local NVMe SSD block storage to improve response times by acting as a caching layer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use X2gd instances compared to the X1, X2i, or R instances?"}, {"role": "assistant", "content": "X2gd instances are suitable for Arm-compatible memory bound scale-out workloads such as in-memory databases, memory analytics applications, open-source relational database workloads, EDA workloads, and large caching servers. X2gd instances offer customers the lowest cost per gigabyte of memory within EC2, with sizes up to 1 TiB. X2iezn, X2idn, X2iedn, X1, and X1e instances use x86 processors and are suitable for memory-intensive enterprise-class, scale-up workloads such as Windows workloads, in-memory databases (e.g. SAP HANA), and relational databases (e.g. OracleDB). Customers can leverage the x86-based X instances for larger memory sizes up to 4 TiB. R6g and R6gd instances are suitable for workloads such as web applications, databases, and search indexing queries that need more vCPUs during times of heavy data processing. Customers running memory bound workloads that need less than 1 TiB memory and have dependency on x86 instruction set such as Windows applications, and applications like Oracle or SAP can leverage R5 instances and R6 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use X2idn and X2iedn instances?"}, {"role": "assistant", "content": "X2idn and X2iedn instances are powered by 3rd generation Intel Xeon Scalable processors with an all-core turbo frequency up to 3.5 GHz and deliver up to 50% higher compute price performance than comparable X1 instances. X2idn and X2iedn instances both include up to 3.8 TB of local NVMe SSD storage and up to 100 Gbps of networking bandwidth, while X2idn offers up to 2 TiB of memory and X2iedn offers up to 4 TiB of memory. X2idn and X2iedn instances are SAP-Certified and are a great fit for workloads such as small-to large-scale traditional and in-memory databases, and analytics."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use X2iezn instances?"}, {"role": "assistant", "content": "[X2iezn instances](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/x2i/) feature the fastest Intel Xeon Scalable processors in the cloud and are a great fit for workloads that need high single-threaded performance combined with a high memory-to-vCPU ratio and high speed networking. X2iezn instances have an all-core turbo frequency up to 4.5 GHz, feature a 32:1 ratio of memory to vCPU, and deliver up to 55% higher compute price performance compared to X1e instances. X2iezn instances are a great fit for electronic design automation (EDA) workloads like physical verification, static timing analysis, power signoff, and full chip gate-level simulation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which operating systems/AMIs are supported on X2gd instances?"}, {"role": "assistant", "content": "The following AMIs are supported: Amazon Linux 2, Ubuntu 18.04 or newer, Red Hat Enterprise Linux 8.2 or newer, and SUSE Enterprise Server 15 or newer. Customers will find additional AMIs such as Fedora, Debian, NetBSD, and CentOS available through community AMIs and the AWS Marketplace. For containerized applications, Amazon ECS and EKS optimized AMIs are available as well."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use X1 instances?"}, {"role": "assistant", "content": "X1 instances are ideal for running in-memory databases like SAP HANA, big data processing engines like Apache Spark or Presto, and high performance computing (HPC) applications. X1 instances are certified by SAP to run production environments of the next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS cloud."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do X1 and X1e instances enable CPU power management state control?"}, {"role": "assistant", "content": "Yes. You can configure C-states and P-states on x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge and x1.16xlarge instances. You can use C-states to enable higher turbo frequencies (as much as 3.1 GHz with one or two core turbo). You can also use P-states to lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo, and running consistently at the base CPU clock speed.x1e.32xlarge will also support Windows Server 2012 R2 and 2012 RTM. x1e.xlarge, x1e.2xlarge, x1e.4xlarge, x1e.8xlarge, x1e.16xlarge and x1.32xlarge will also support Windows Server 2012 R2, 2012 RTM and 2008 R2 64bit (Windows Server 2008 SP2 and older versions will not be supported) and x1.16xlarge will support Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit (Windows Server 32bit versions will not be supported)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there standard SAP HANA reference deployment frameworks available for the High Memory instance and the AWS?"}, {"role": "assistant", "content": "You can use [AWS Launch Wizard for SAP](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/launchwizard/latest/userguide/what-is-launch-wizard-sap.html) or [AWS Quick Start reference SAP HANA](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/quickstart/latest/sap-hana/welcome.html) deployments to rapidly deploy all the necessary SAP HANA building blocks on High Memory instances following recommendations from AWS and SAP for high performance and reliability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why don\u2019t I see M1, C1, CC2 and HS1 instances on the pricing pages any more?"}, {"role": "assistant", "content": "These have been moved to the [Previous Generation Instance](/web/20240727055400/https://aws.amazon.com/ec2/previous-generation/) page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are these Previous Generation instances still being supported?"}, {"role": "assistant", "content": "Yes. Previous Generation instances are still fully supported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I still use/add more Previous Generation instances?"}, {"role": "assistant", "content": "Yes. Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instance, from our APIs, CLI and EC2 Management Console interface."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are my Previous Generation instances going to be deleted?"}, {"role": "assistant", "content": "No. Until instances reach end of life and are fully deprecated, previous generation instances will be fully functional and will not be deleted because of this change. If AWS decides to deprecate previous generation instances due to end of life considerations, you will be notified of that change."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are Previous Generation instances being discontinued soon?"}, {"role": "assistant", "content": "With any rapidly evolving technology the latest generation will typically provide the best performance for the price and we encourage our customers to take advantage of technological advancements. If AWS decides to deprecate previous generation instances due to end of life considerations, you will be notified of that change."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will my Previous Generation instances I purchased as a Reserved Instance be affected or changed?"}, {"role": "assistant", "content": "No. Your Reserved Instances will not change, and the Previous Generation instances are not going away."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a Dense-storage Instance?"}, {"role": "assistant", "content": "Dense-storage instances are designed for workloads that require high sequential read and write access to very large data sets, such as Hadoop distributed computing, massively parallel processing data warehousing, and log processing applications. The Dense-storage instances offer the best price/GB-storage and price/disk-throughput across other EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do dense-storage instances compare to High I/O instances?"}, {"role": "assistant", "content": "High I/O instances (Im4gn, Is4gen, I4i, I3, I3en) are targeted at workloads that demand low latency and high random I/O in addition to moderate storage density and provide the best price/IOPS across other EC2 instance types. Dense-storage instances (D3, D3en, D2) and HDD-storage instances (H1) are optimized for applications that require high sequential read/write access and low cost storage for very large data sets and provide the best price/GB-storage and price/disk-throughput across other EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much disk throughput can Dense-storage and HDD-storage instances deliver?"}, {"role": "assistant", "content": "The largest current generation of Dense HDD-storage instances, d3en.12xlarge, can deliver up to 6.2 GiB/s read and 6.2 GiB/s write disk throughput with a 128k block size. Please see the product detail page for additional performance information. To ensure the best disk throughput performance from your D2, D3 and D3en instances on Linux, we recommend that you use the most recent version of the Amazon Linux AMI, or another Linux AMI with a kernel version of 3.8 or later that supports persistent grants\u2014an extension to the Xen block ring protocol that significantly improves disk throughput and scalability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Dense-storage and HDD-storage instances provide any failover mechanisms or redundancy?"}, {"role": "assistant", "content": "D2 and H1 instances provide notifications for hardware failures. Like all instance storage, Dense HDD-storage volumes persist only for the life of the instance. Hence, we recommend that you build a degree of redundancy (e.g. RAID 1/5/6) or use file systems (e.g. HDFS and MapR-FS) that support redundancy and fault tolerance. You can also back up data periodically to more data storage solutions such as Amazon EBS or Amazon S3."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do dense HDD-storage instances differ from Amazon EBS?"}, {"role": "assistant", "content": "Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance instances with local HDD or NVMe storage provide directly attached, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I launch dense HDD-storage instances as Amazon EBS optimized instances?"}, {"role": "assistant", "content": "Each HDD-storage instance type (H1, D2, D3, and D3en) is EBS optimized by default. Since this feature is always enabled, launching one of these instances explicitly as EBS optimized will not affect the instance's behavior. For more information, see [Amazon EBS\u2013optimized instances](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I launch D2 instances as Amazon EBS optimized instances?"}, {"role": "assistant", "content": "Each D2 instance type is EBS optimized by default. D2 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on D2 instances, launching a D2 instance explicitly as EBS optimized will not affect the instance's behavior."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a High I/O instance?"}, {"role": "assistant", "content": "High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for low latency networking."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are all features of Amazon EC2 available for High I/O instances?"}, {"role": "assistant", "content": "High I/O instances support all Amazon EC2 features. Im4gn, Is4gen, I4i, I3 and I3en instances offer NVMe only storage, while previous generation I2 instances allow legacy blkfront storage access."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: AWS has other database and Big Data offerings. When or why should I use High I/O instances?"}, {"role": "assistant", "content": "High I/O instances are ideal for applications that require access to millions of low latency IOPS, and can leverage data stores and architectures that manage data redundancy and availability. Example applications are:NoSQL databases like Cassandra and MongoDBIn-memory databases like AerospikeElasticsearch and analytics workloadsOLTP systems"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do High I/O instances provide any failover mechanisms or redundancy?"}, {"role": "assistant", "content": "Like other Amazon EC2 instance types, instance storage on\u00a0Im4gn, Is4gen, I4i, I3 and I3en instances persists during the life of the instance. Customers are expected to build resilience into their applications. We recommend using databases and file systems that support redundancy and fault tolerance. Customers should back up data periodically to Amazon S3 for improved data durability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do High I/O instances support TRIM?"}, {"role": "assistant", "content": "The TRIM command allows the operating system to inform SSDs which blocks of data are no longer considered in use and can be wiped internally. In the absence of TRIM, future write operations to the involved blocks can slow down significantly. Im4gn, Is4gen, I4i, I3 and I3en instances support TRIM."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do D3 and D3en instances compare to D2 instances?"}, {"role": "assistant", "content": "D3 and D3en instances offer improved specifications over D2 on the following compute, storage and network attributes:D3 and D3en instances offer up to 30% higher compute performances than equivalent D2 instances. Exact performance benefit will depend on the specific workload.D3 and D3en instances provide up to 45% and 100% higher disk throughput than D2 instances, respectively.D3 instances are available at a price that is 5% lower than D2 instances. D3en instances lower cost per TB of storage by up to 80% compared to D2 instances.D3 and D3en instances offer Intel Advanced Vector Extensions (AVX 512), which offer up to 2X the FLOPS per cycle compared to AVX 2 on D2.D3en instances offer a new instance size (12xl) with 48 vCPUs and 7 TB of storage per vCPU for 336 TB of total storage, but have half the memory per vCPU compared to D2 and 48 TB of total storage.D3 and D3en instances offer up to 25 Gbps and 75 Gbps of network bandwidth respectively on their largest sizes to meet customer needs for network performance for running big data workloads and file system clusters."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do D3 and D3en instances encrypt storage volumes and network traffic?"}, {"role": "assistant", "content": "Yes; data written onto the storage volumes will be encrypted at rest using AES-256-XTS. Network traffic between D3 and D3en instances in the same VPC or a peered VPC are encrypted by default using a 256-bit key."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens to my data when a system terminates?"}, {"role": "assistant", "content": "The data stored on a local instance store will persist only as long as that instance is alive. However, data that is stored on an Amazon EBS volume will persist independently of the life of the instance. Therefore, we recommend that you use the local instance store for temporary data and, for data requiring a higher level of durability, we recommend using Amazon EBS volumes or backing up the data to Amazon S3. If you are using an Amazon EBS volume as a root partition, you will need to set the Delete On Terminate flag to \"N\" if you want your Amazon EBS volume to persist outside the life of the instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What kind of performance can I expect from Amazon EBS volumes?"}, {"role": "assistant", "content": "Amazon EBS provides four current generation volume types that are divided into two major categories: SSD-backed storage for transactional workloads and HDD-backed storage for throughput intensive workloads. These volume types differ in performance characteristics and price, allowing you to tailor your storage performance and cost to the needs of your applications. For more information, see the\u00a0[Amazon EBS overview](/web/20240727055400/https://aws.amazon.com/ebs/details/). For additional information on performance, see the [Amazon EC2 User Guide's EBS Performance section](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types?"}, {"role": "assistant", "content": "ST1 volumes are backed by hard disk drives (HDDs) and are ideal for frequently accessed, throughput intensive workloads with large datasets and large I/O sizes, such as MapReduce, Kafka, log processing, data warehouse, and ETL workloads. These volumes deliver performance in terms of throughput, measured in MB/s, and include the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB and a maximum throughput of 500 MB/s per volume. ST1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.SC1 volumes are backed by HDDs and provide the lowest cost per GB of all EBS volume types. It is ideal for less frequently accessed workloads with large, cold datasets. Similar to st1, sc1 provides a burst model: these volumes can burst up to 80 MB/s per TB, with a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. For infrequently accessed data, sc1 provides extremely inexpensive storage. SC1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.To maximize the performance of st1 and sc1, we recommend using [EBS-optimized EC2 instances](/web/20240727055400/https://aws.amazon.com/ebs/features/#Amazon_EBS-Optimized_instances)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which volume type should I choose?"}, {"role": "assistant", "content": "Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1 and io2) and General Purpose SSD (gp2 and gp3). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O patterns. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information, see the\u00a0[Amazon EBS overview](/web/20240727055400/https://aws.amazon.com/ebs/details/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do you support multiple instances accessing a single volume?"}, {"role": "assistant", "content": "Yes, you can enable Multi-Attach on an EBS Provisioned IOPS io1 volume to allow a volume to be concurrently attached to up to sixteen Nitro-based EC2 instances within the same Availability Zone. For more information on Amazon EBS Multi-Attach, see the [EBS product page](/web/20240727055400/https://aws.amazon.com/ebs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I be able to access my EBS snapshots using the regular Amazon S3 APIs?"}, {"role": "assistant", "content": "No, EBS snapshots are only available through the Amazon EC2 APIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do volumes need to be un-mounted in order to take a snapshot?"}, {"role": "assistant", "content": "Does the snapshot need to complete before the volume can be used again"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are snapshots versioned?"}, {"role": "assistant", "content": "Can I read an older snapshot to do a point-in-time recovery"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What charges apply when using Amazon EBS shared snapshots?"}, {"role": "assistant", "content": "If you share a snapshot, you won\u2019t be charged when other users make a copy of your snapshot. If you make a copy of another user\u2019s shared volume, you will be charged normal EBS rates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can users of my Amazon EBS shared snapshots change any of my data?"}, {"role": "assistant", "content": "Users who have permission to create volumes based on your shared snapshots will first make a copy of the snapshot into their account. Users can modify their own copies of the data, but the data on your original snapshot and any other volumes created by other users from your original snapshot will remain unmodified."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I discover Amazon EBS snapshots that have been shared with me?"}, {"role": "assistant", "content": "You can find snapshots that have been shared with you by selecting \u201cPrivate Snapshots\u201d from the viewing dropdown in the Snapshots section of the AWS Management Console. This section will list both snapshots you own and snapshots that have been shared with you."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I find what Amazon EBS snapshots are shared globally?"}, {"role": "assistant", "content": "You can find snapshots that have been shared globally by selecting \u201cPublic Snapshots\u201d from the viewing dropdown in the Snapshots section of the AWS Management Console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do you offer encryption on Amazon EBS volumes and snapshots?"}, {"role": "assistant", "content": "Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I find a list of Amazon Public Data Sets?"}, {"role": "assistant", "content": "All information on Public Data Sets is available in our [Public Data Sets Resource Center](https://web.archive.org/web/20240727055400/https://registry.opendata.aws/). You can also obtain a listing of Public Data Sets within the AWS Management Console by choosing \u201cAmazon Snapshots\u201d from the viewing dropdown in the Snapshots section."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I learn more about EBS?"}, {"role": "assistant", "content": "See\u00a0[Amazon EBS FAQ](/web/20240727055400/https://aws.amazon.com/ebs/faqs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I access a file system from an Amazon EC2 instance?"}, {"role": "assistant", "content": "To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system\u2019s DNS name. Once you\u2019ve mounted, you can work with the files and directories in your file system just like you would with a local file system.Amazon EFS uses the NFSv4.1 protocol. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the [Amazon EFS Getting Started guide](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/efs/latest/ug/gs-mount-fs-on-ec2instance-and-test.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What Amazon EC2 instance types and AMIs work with Amazon EFS?"}, {"role": "assistant", "content": "Amazon EFS is compatible with all Amazon EC2 instance types and is accessible from Linux-based AMIs. You can mix and match the instance types connected to a single file system. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the [Amazon EFS Getting Started guide](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/efs/latest/ug/gs-mount-fs-on-ec2instance-and-test.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I load data into a file system?"}, {"role": "assistant", "content": "You can load data into an Amazon EFS file system from your Amazon EC2 instances or from your on-premises datacenter servers.Amazon EFS file systems can be mounted on an Amazon EC2 instance, so any data that is accessible to an Amazon EC2 instance can also be read and written to Amazon EFS. To load data that is not currently stored on the Amazon cloud, you can use the same methods you use to transfer files to Amazon EC2 today, such as Secure Copy (SCP).Amazon EFS file systems can also be mounted on an on-premises server, so any data that is accessible to an on-premises server can be read and written to Amazon EFS using standard Linux tools. For more information about accessing a file system from an on-premises server, please see the [On-premises Access section](/web/20240727055400/https://aws.amazon.com/efs/faq/#On-premises_Access) of the Amazon EFS FAQ.For more information about moving data to the Amazon cloud, please see the [Cloud Data Migration page](/web/20240727055400/https://aws.amazon.com/cloud-data-migration/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I access my file system from outside my VPC?"}, {"role": "assistant", "content": "Amazon EC2 instances within your VPC can access your file system directly. On-premises servers can mount your file systems via an [AWS Direct Connect](/web/20240727055400/https://aws.amazon.com/directconnect/) connection to your VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many Amazon EC2 instances can connect to a file system?"}, {"role": "assistant", "content": "Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I learn more about EFS?"}, {"role": "assistant", "content": "You can visit the [Amazon EFS FAQ page](/web/20240727055400/https://aws.amazon.com/efs/faq/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is data stored on Amazon EC2 NVMe instance storage encrypted?"}, {"role": "assistant", "content": "Yes, all data is encrypted in an [AWS Nitro](/web/20240727055400/https://aws.amazon.com/ec2/nitro/) hardware module prior to being written on the locally attached SSDs offered via NVMe instance storage."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What encryption algorithm is used to encrypt Amazon EC2 NVMe instance storage?"}, {"role": "assistant", "content": "Amazon EC2 NVMe instance storage is encrypted using an XTS-AES-256 block cipher."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are encryption keys unique to an instance or a particular device for NVMe instance storage?"}, {"role": "assistant", "content": "Encryption keys are securely generated within the [Nitro](/web/20240727055400/https://aws.amazon.com/ec2/nitro/) hardware module, and are unique to each NVMe instance storage device that is provided with an EC2 instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the lifetime of encryption keys on NVMe instance storage?"}, {"role": "assistant", "content": "All keys are irrecoverably destroyed on any de-allocation of the storage, including instance stop and instance terminate actions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I disable NVMe instance storage encryption?"}, {"role": "assistant", "content": "No, NVMe instance storage encryption is always on, and cannot be disabled."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do the published IOPS performance numbers on I3 and I3en include data encryption?"}, {"role": "assistant", "content": "Yes, the [documented IOPS numbers](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html) for Im4gn, Is4gen, I4i, I3 and I3en NVMe instance storage include encryption."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon EC2 NVMe instance storage support AWS Key Management Service (KMS)?"}, {"role": "assistant", "content": "No, disk encryption on NVMe instance storage does not support integration with AWS KMS system. Customers cannot bring in their own keys to use with NVMe instance storage."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is ENA Express?"}, {"role": "assistant", "content": "ENA Express is an enhancement on the Elastic Network Adapter that brings the Scalable Reliable Datagram (SRD) protocol to traditional TCP and UDP networking. Transparent to the application, ENA Express improves single flow bandwidths and reduces tail latencies in throughput intensive workloads."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does ENA Express work?"}, {"role": "assistant", "content": "When configured, ENA Express works between any two supported instances in an Availability Zone (AZ). ENA Express detects compatibility between your EC2 instances and establishes an SRD connection when both communicating instances have ENA Express enabled. Once a connection is established, your traffic can take advantage of SRD and its performance benefits."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use ENA Express?"}, {"role": "assistant", "content": "ENA Express works best for applications requiring high, single-flow throughput, like distributed storage systems and live media encoding. These workloads require high single flow bandwidth and low tail latency."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I enable ENA Express?"}, {"role": "assistant", "content": "ENA Express can be enabled on a per-ENI basis. While attaching a network card to an instance or while running a modify command, ENA Express can be enabled. ENA Express must be enabled on both communicating ENIs to establish point-to-point communication with it. Additionally, if you are using Jumbo Frames, you must adjust your maximum MTU to 8900 to use ENA Express."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What protocols are supported by ENA Express?"}, {"role": "assistant", "content": "ENA Express supports TCP by default. UDP can optionally be enabled through an API argument or within the management console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What instances are supported?"}, {"role": "assistant", "content": "ENA Express is supported on Graviton-, Intel-, and AMD-based EC2 instances. It is supported on compute-optimized, memory-optimized, general purpose and storage-optimized based instances. For a complete list of supported instances, please see the ENA Express [user guide](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ena-express.html#ena-express-supported-instance-types)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between Elastic Fabric Adapter (EFA)\u00a0and ENA Express?"}, {"role": "assistant", "content": "EFA is a network interface built for HPC and ML applications, and it also leverages the SRD protocol. EFA requires a different network programming model, which uses the LibFabric interface to pass communication to the ENI. Unlike EFA, ENA Express helps you run your application transparently on TCP and UDP."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if I\u2019m running ENA Express on one instance, and it is communicating with another instance that doesn\u2019t support ENA Express or hasn\u2019t enabled it on the ENI?"}, {"role": "assistant", "content": "ENA Express will detect if ENA Express has been enabled on another instance. If that instance doesn\u2019t support or hasn\u2019t enabled ENA Express, your instance will fallback to normal ENA operation. You will not be able to achieve any of the SRD performance benefits in this case, but there are no adverse effects either."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What operating systems are supported?"}, {"role": "assistant", "content": "The SRD functionality will be supported on all operating systems, but please note that ENA Express monitoring metrics will be available on only the EthTool in the latest Amazon Linux AMI or by installing the ENA driver version 2.8.0 or later from GitHub, with all operating systems supporting the metrics in the future."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What monitoring tools are available to track this?"}, {"role": "assistant", "content": "ENA Express offers EthTool counters to track packets that are eligible for SRD transmission in addition to those actually sent and received with SRD. Additionally, EthTool will support an SRD resource utilization metric on a percent basis, providing insight into when you should consider scaling out your architecture. Finally, a Boolean will provide on and off status for ENA Express and the UDP protocol."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where is ENA Express available?"}, {"role": "assistant", "content": "ENA Express is available in all commercial Regions. It can be used to establish communication between any two enabled instances within the same AZ."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any additional costs to running ENA Express?"}, {"role": "assistant", "content": "No, ENA Express is free to use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use EFA?"}, {"role": "assistant", "content": "EFA brings the scalability, flexibility, and elasticity of cloud to tightly coupled HPC applications. With EFA, tightly coupled HPC applications have access to lower and more consistent latency and higher throughput than traditional TCP channels, enabling them to scale better. EFA support can be enabled dynamically, on-demand on any supported EC2 instance without pre-reservation, giving you the flexibility to respond to changing business/workload priorities."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What types of applications can benefit from using EFA?"}, {"role": "assistant", "content": "HPC applications distribute computational workloads across a cluster of instances for parallel processing. Examples of HPC applications include computational fluid dynamics (CFD), crash simulations, and weather simulations. HPC applications are generally written using the Message Passing Interface (MPI) and impose stringent requirements for inter-instance communication in terms of both latency and bandwidth. Applications using MPI and other HPC middleware that supports the libfabric communication stack can benefit from EFA."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does EFA communication work?"}, {"role": "assistant", "content": "EFA devices provide all ENA devices' functionalities plus a new OS bypass hardware interface that allows user-space applications to communicate directly with the hardware-provided reliable transport functionality. Most applications will use existing middleware, such as the MPI, to interface with EFA. AWS has worked with a number of middleware providers to ensure support for the OS bypass functionality of EFA. Please note that communication using the OS bypass functionality is limited to instances within an Availability Zone (AZ)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where is EFA available?"}, {"role": "assistant", "content": "EFA is available in all commercial Regions. It can be used to establish communication between any two enabled instances within the same AZ."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instance types support EFA?"}, {"role": "assistant", "content": "For a full list of supported EC2 instances, refer to [this page](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html#efa-instance-types) in our documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the differences between an EFA ENI and an ENA ENI?"}, {"role": "assistant", "content": "An ENA ENI provides traditional IP networking features necessary to support VPC networking. An EFA ENI provides all the functionality of an ENA ENI, plus hardware support for applications to communicate directly with the EFA ENI without involving the instance kernel (OS-bypass communication) using an extended programming interface. Due to the advanced capabilities of the EFA ENI, EFA ENIs can only be attached at launch or to stopped instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the pre-requisites to enabling EFA on an instance?"}, {"role": "assistant", "content": "EFA support can be enabled either at the launch of the instance or added to a stopped instance. EFA devices cannot be attached to a running instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What networking capabilities are included in this feature?"}, {"role": "assistant", "content": "We currently support enhanced networking capabilities using SR-IOV (Single Root I/O Virtualization). SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization compared to traditional implementations. For supported Amazon EC2 instances, this feature provides higher packet per second (PPS) performance, lower inter-instance latencies, and very low network jitter."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use Enhanced Networking?"}, {"role": "assistant", "content": "If your applications benefit from high packet-per-second performance and/or low latency networking, Enhanced Networking will provide significantly improved performance, consistence of performance and scalability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I enable Enhanced Networking on supported instances?"}, {"role": "assistant", "content": "In order to enable this feature, you must launch an HVM AMI with the appropriate drivers. The instances listed as [current generation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes) use ENA for enhanced networking. Amazon Linux AMI includes both of these drivers by default. For AMIs that do not contain these drivers, you will need to download and install the appropriate drivers based on the instance types you plan to use. You can use Linux or Windows instructions to enable Enhanced Networking in AMIs that do not include the SR-IOV driver by default. Enhanced Networking is only supported in Amazon VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to pay an additional fee to use Enhanced Networking?"}, {"role": "assistant", "content": "No, there is no additional fee for Enhanced Networking. To take advantage of Enhanced Networking you need to launch the appropriate AMI on a supported instance type in a VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instance types support Enhanced Networking?"}, {"role": "assistant", "content": "Depending on your instance type,\u00a0you can enable enhanced networking by using one of the following mechanisms:Intel 82599 Virtual Function (VF) interface - The Intel 82599 Virtual Function interface supports network speeds of up to 10 Gbps for supported instance types. C3, C4, D2, I2, M4 (excluding m4.16xlarge), and R3 instances use the Intel 82599 VF interface for enhanced networking.Elastic Network Adapter (ENA) -\u00a0The Elastic Network Adapter (ENA) supports network speeds of up to 200 Gbps for supported instance types. The instances listed as [current generation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#current-gen-instances) use ENA for enhanced networking, with the exception of C4, D2, and M4 instances smaller than m4.16xlarge."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does it mean to have multiple network cards for an EC2 instance?"}, {"role": "assistant", "content": "Why are they needed"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instance types support multiple network cards?"}, {"role": "assistant", "content": "Multiple network cards are supported on accelerated instances such as p4d.24xlarge, and network optimized instances, such as c6in.32xlarge. For a full list of instances supporting multiple network cards, see the [Elastic network interfaces.](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the default number of network interfaces a multiple card instance can launch with?"}, {"role": "assistant", "content": "This depends on the instance type. Accelerated instances, such as p4 scale, up to 15 network interfaces per network card. High network instances such as the recently launched c6in instances support an aggregate 14 network interfaces split evenly (7 and 7) across the two network cards. For information about the network interface scale per network cards, see [Network cards.](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#network-cards)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What load balancing options does the Elastic Load Balancing service offer?"}, {"role": "assistant", "content": "Elastic Load Balancing offers two types of load balancers that both feature high availability, automatic scaling, and robust security. These include the [Classic Load Balancer](/web/20240727055400/https://aws.amazon.com/elasticloadbalancing/classicloadbalancer/) that routes traffic based on either application or network level information, and the [Application Load Balancer](/web/20240727055400/https://aws.amazon.com/elasticloadbalancing/applicationloadbalancer/) that routes traffic based on advanced application level information that includes the content of the request."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use the Classic Load Balancer and when should I use the Application Load Balancer?"}, {"role": "assistant", "content": "The Classic Load Balancer is ideal for simple load balancing of traffic across multiple EC2 instances, while the Application Load Balancer is ideal for applications needing advanced routing capabilities, microservices, and container-based architectures. Please visit [Elastic Load Balancing](/web/20240727055400/https://aws.amazon.com/elasticloadbalancing/) for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I limited to 5 Elastic IP addresses per region?"}, {"role": "assistant", "content": "Public (IPV4) internet addresses are a scarce resource. There is only a limited amount of public IP space available, and Amazon EC2 is committed to helping use that space efficiently.By default, all accounts are limited to 5 Elastic IP addresses per region. If you need more than 5 Elastic IP addresses, we ask that you apply for your limit to be raised. We will ask you to think through your use case and help us understand your need for additional addresses. You can [apply for more Elastic IP addresses here](/web/20240727055400/https://aws.amazon.com/contact-us/eip_limit_request/). Any increases will be specific to the region they have been requested for."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why am I charged when my Elastic IP address is not associated with a running instance?"}, {"role": "assistant", "content": "In order to help ensure our customers are efficiently using the Elastic IP addresses, we impose a small hourly charge for each address when it is not associated with a running instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need one Elastic IP address for every instance that I have running?"}, {"role": "assistant", "content": "No. You do not need an Elastic IP address for all your instances. By default, every instance comes with a private IP address and an internet routable public IP address. The private IP address remains associated with the network interface when the instance is stopped and restarted, and is released when the instance is terminated. The public address is associated exclusively with the instance until it is stopped, terminated or replaced with an Elastic IP address. These IP addresses should be adequate for many applications where you do not need a long lived internet routable end point. Compute clusters, web crawling, and backend services are all examples of applications that typically do not require Elastic IP addresses."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long does it take to remap an Elastic IP address?"}, {"role": "assistant", "content": "The remap process currently takes several minutes from when you instruct us to remap the Elastic IP until it fully propagates through our system."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I configure the reverse DNS record for my Elastic IP address?"}, {"role": "assistant", "content": "All Elastic IP addresses come with reverse DNS, in a standard template of the form ec2-1-2-3-4.region.compute.amazonaws.com. For customers requiring custom reverse DNS settings for internet-facing applications that use IP-based mutual authentication (such as sending email from EC2 instances), you can configure the reverse DNS record of your Elastic IP address by filling out [this form](https://web.archive.org/web/20240727055400/https://portal.aws.amazon.com/gp/aws/html-forms-controller/contactus/ec2-email-limit-rdns-request). Alternatively, please contact AWS Customer Support if you want AWS to delegate the management of the reverse DNS for your Elastic IPs to your authoritative DNS name servers (such as Amazon Route 53), so that you can manage your own reverse DNS PTR records to support these use-cases. Note that a corresponding forward DNS record pointing to that Elastic IP address must exist before we can create the reverse DNS record."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I prevent other people from viewing my systems?"}, {"role": "assistant", "content": "You have complete control over the visibility of your systems. The Amazon EC2 security systems allow you to place your running instances into arbitrary groups of your choice. Using the web services interface, you can then specify which groups may communicate with which other groups, and also which IP subnets on the Internet may talk to which groups. This allows you to control access to your instances in our highly dynamic environment. Of course, you should also secure your instance as you would any other server."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I get a history of all EC2 API calls made on my account for security analysis and operational troubleshooting purposes?"}, {"role": "assistant", "content": "Yes. To receive a history of all EC2 API calls (including VPC and EBS) made on your account, you simply turn on CloudTrail in the [AWS Management Console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/cloudtrail/home). For more information, visit the [CloudTrail](/web/20240727055400/https://aws.amazon.com/cloudtrail/) home page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find more information about security on AWS?"}, {"role": "assistant", "content": "For more information on security on AWS please refer to our [Amazon Web Services: Overview of Security Processes](https://web.archive.org/web/20240727055400/https://d1.awsstatic.com/whitepapers/aws-security-whitepaper.pdf) white paper and to our [Amazon EC2 running Windows Security Guide](/web/20240727055400/https://aws.amazon.com/answers/security/aws-securing-windows-instances/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?"}, {"role": "assistant", "content": "Metrics are received and aggregated at 1 minute intervals."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which operating systems does Amazon CloudWatch support?"}, {"role": "assistant", "content": "Amazon CloudWatch receives and provides metrics for all Amazon EC2 instances and should work with any operating system currently supported by the Amazon EC2 service."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I lose the metrics data if I disable monitoring for an Amazon EC2 instance?"}, {"role": "assistant", "content": "You can retrieve metrics data for any Amazon EC2 instance up to 2 weeks from the time you started to monitor it. After 2 weeks, metrics data for an Amazon EC2 instance will not be available if monitoring was disabled for that Amazon EC2 instance. If you want to archive metrics beyond 2 weeks you can do so by calling mon-get-stats command from the command line and storing the results in Amazon S3 or Amazon SimpleDB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I access the metrics data for a terminated Amazon EC2 instance or a deleted Elastic Load Balancer?"}, {"role": "assistant", "content": "Yes. Amazon CloudWatch stores metrics for terminated Amazon EC2 instances or deleted Elastic Load Balancers for 2 weeks."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does the Amazon CloudWatch monitoring charge change depending on which type of Amazon EC2 instance I monitor?"}, {"role": "assistant", "content": "No, the Amazon CloudWatch monitoring charge does not vary by Amazon EC2 instance type."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why does the graphing of the same time window look different when I view in 5 minute and 1 minute periods?"}, {"role": "assistant", "content": "If you view the same time window in a 5 minute period versus a 1 minute period, you may see that data points are displayed in different places on the graph. For the period you specify in your graph, Amazon CloudWatch will find all the available data points and calculates a single, aggregate point to represent the entire period. In the case of a 5 minute period, the single data point is placed at the beginning of the 5 minute time window. In the case of a 1 minute period, the single data point is placed at the 1 minute mark. We recommend using a 1 minute period for troubleshooting and other activities that require the most precise graphing of time periods."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I automatically scale Amazon EC2 Auto Scaling Groups?"}, {"role": "assistant", "content": "Yes. [Amazon EC2 Auto Scaling](/web/20240727055400/https://aws.amazon.com/ec2/autoscaling/) is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.Allocation strategies in EC2 Auto Scaling determine how Spot Instances in your fleet are fulfilled from Spot Instance pools. The capacity-optimized allocation strategy attempts to provision Spot Instances from the most available Spot Instance pools by analyzing capacity metrics. This strategy is a good choice for workloads that have a higher cost of interruption such as big data and analytics, image and media rendering, machine learning, and high performance computing. The lowest-price allocation strategy launches Spot Instances strictly based on diversification across \u2018N\u2019 lowest priced pools. For more information see the [Amazon EC2 Auto Scaling FAQ](/web/20240727055400/https://aws.amazon.com/ec2/autoscaling/faqs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I hibernate an instance?"}, {"role": "assistant", "content": "You can hibernate an instance to get your instance and applications up and running quickly, if they take a long time to bootstrap (e.g. load memory caches). You can start instances, bring them to a desired state and hibernate them. These \u201cpre-warmed\u201d instances can then be resumed to reduce the time it takes for an instance to return to service. Hibernation retains memory state across Stop/Start cycles."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens when I hibernate my instance?"}, {"role": "assistant", "content": "When you hibernate an instance, data from your EBS root volume and any attached EBS data volumes is persisted. Additionally, contents from the instance\u2019s memory (RAM) are persisted to EBS root volume. When the instance is restarted, it returns to its previous state and reloads the RAM contents."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between hibernate and stop?"}, {"role": "assistant", "content": "In the case of hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shut down and RAM is cleared.In both the cases, data from your EBS root volume and any attached EBS data volumes is persisted. Your private IP address remains the same, as does your elastic IP address (if applicable). The network layer behavior will be similar to that of EC2 Stop-Start workflow. Stop and hibernate are available for Amazon EBS backed instances only. Local instance storage is not persisted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much does it cost to hibernate an instance?"}, {"role": "assistant", "content": "Hibernating instances are charged at standard EBS rates for storage. As with a stopped instance, you do not incur instance usage fees while an instance is hibernating."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I hibernate an instance?"}, {"role": "assistant", "content": "Hibernation needs to be enabled when you launch the instance. Once enabled, you can use the StopInstances API with an additional \u2018Hibernate\u2019 parameter to trigger hibernation. You can also do this through the console by selecting your instance, then clicking Actions> Instance State > Stop - Hibernate. For more information on using hibernation, refer to the user [guide](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I resume a hibernating instance?"}, {"role": "assistant", "content": "You can resume by calling the StartInstances API as you would for a regular stopped instance. You can also do this through the console by selecting your instance, then clicking Actions > Instance State > Start."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I enable hibernation on an existing instance?"}, {"role": "assistant", "content": "No, you cannot enable hibernation on an existing instance (running or stopped). This needs to be enabled during instance launch."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I tell that an instance is hibernated?"}, {"role": "assistant", "content": "You can tell that an instance is hibernated by looking at the state reason. It should be \u2018Client.UserInitiatedHibernate\u2019. This is visible on the console under \u201cInstances - Details\u201d view or in the DescribeInstances API response as the \u201creason\u201d field."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the state of an instance when it is hibernating?"}, {"role": "assistant", "content": "Hibernated instances are in \u2018Stopped\u2019 state."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What data is saved when I hibernate an instance?"}, {"role": "assistant", "content": "EBS volume storage (boot volume and attached data volumes) and memory (RAM) are saved. Your private IP address remains the same (for VPC), as does your elastic IP address (if applicable). The network layer behavior will be similar to that of EC2 Stop-Start workflow."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where is my data stored when I hibernate an instance?"}, {"role": "assistant", "content": "As with the Stop feature, root device and attached device data are stored on the corresponding EBS volumes. Memory (RAM) contents are stored on the EBS root volume."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is my memory (RAM) data encrypted when it is moved to EBS?"}, {"role": "assistant", "content": "Yes, RAM data is always encrypted when it is moved to the EBS root volume. Encryption on the EBS root volume is enforced at instance launch time. This is to ensure protection for any sensitive content that is in memory at the time of hibernation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long can I keep my instance hibernated?"}, {"role": "assistant", "content": "We do not support keeping an instance hibernated for more than 60 days. You need to resume the instance and go through Stop and Start (without hibernation) if you wish to keep the instance around for a longer duration. We are constantly working to keep our platform up-to-date with upgrades and security patches, some of which can conflict with the old hibernated instances. We will notify you for critical updates that require you to resume the hibernated instance to perform a shutdown or a reboot."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the prerequisites to hibernate an instance?"}, {"role": "assistant", "content": "To use hibernation, the root volume must be an encrypted EBS volume. The instance needs to be configured to receive the ACPID signal for hibernation (or use the Amazon published AMIs that are configured for hibernation). Additionally, your instance should have sufficient space available on your EBS root volume to write data from memory."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instances and operating systems support hibernation?"}, {"role": "assistant", "content": "For instances running Amazon Linux, Amazon Linux 2, Ubuntu, and Windows, Hibernation is supported across C3, C4, C5, C5d, I3, M3, M4, M5, M5a, M5ad, M5d, R3, R4, R5, R5a, R5ad, R5d, T2, T3, and T3a instances.\u00a0For instances running CentOS, Fedora, and Red Hat Enterprise Linux, Hibernation is supported across C5, C5d, M5, M5a, M5ad, M5d, R5, R5a, R5ad, R5d, T3, and T3a instances.For Windows, Hibernation is supported for instances up to 16 GB of RAM. For other operating systems, Hibernation is supported for instances with less than 150 GB of RAM. To review the list of supported OS versions and instance types, refer to the [user guide](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Should I use specific Amazon Machine Image (AMIs) if I want to hibernate my instance?"}, {"role": "assistant", "content": "You can use any AMI that is configured to support hibernation. You can use AWS published AMIs that support hibernation by default. Alternatively, you can create a custom image from an instance after following the hibernation pre-requisite checklist and configuring your instance appropriately."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What if my EBS root volume is not large enough to store memory state (RAM) for hibernation?"}, {"role": "assistant", "content": "To enable hibernation, space is allocated on the root volume to store the instance memory (RAM). Make sure that the root volume is large enough to store the RAM contents and accommodate your expected usage, e.g. OS, applications. If the EBS root volume does not have enough space, hibernation will fail and the instance will get shut down instead."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is VM Import/Export?"}, {"role": "assistant", "content": "VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What operating systems are supported?"}, {"role": "assistant", "content": "VM Import/Export currently supports Windows and Linux VMs, including multiple editions of Windows Server, Red Hat Enterprise Linux (RHEL), CentOS, Ubuntu, Debian and others. For more details on VM Import, including supported file formats, architectures, and operating system configurations, please see the VM Import/Export section of the [VM Import/Export.](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/vm-import/latest/userguide/prerequisites.html)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What VM file formats are supported?"}, {"role": "assistant", "content": "You can import VMware ESX VMDK images, Citrix Xen VHD images, Microsoft Hyper-V VHD images and RAW images as Amazon EC2 instances. You can export EC2 instances to VMware ESX VMDK, VMware ESX OVA, Microsoft Hyper-V VHD or Citrix Xen VHD images. For a full list of supported operating systems, please see [What operating systems are supported"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is VMDK?"}, {"role": "assistant", "content": "VMDK is a file format that specifies a virtual machine hard disk encapsulated within a single file. It is typically used by virtual IT infrastructures such as those sold by VMware, Inc."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I prepare a VMDK file for import using the VMware vSphere client?"}, {"role": "assistant", "content": "The VMDK file can be prepared by calling File-Export-Export to OVF template in VMware vSphere Client. The resulting VMDK file is compressed to reduce the image size and is compatible with VM Import/Export. No special preparation is required if you are using the Amazon EC2 VM Import Connector vApp for VMware vCenter."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is VHD?"}, {"role": "assistant", "content": "VHD (Virtual Hard Disk) is a file format that specifies a virtual machine hard disk encapsulated within a single file. The VHD image format is used by virtualization platforms such as Microsoft Hyper-V and Citrix Xen."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I prepare a VHD file for import from Citrix Xen?"}, {"role": "assistant", "content": "Open Citrix XenCenter and select the virtual machine you want to export. Under the Tools menu, choose \"Virtual Appliance Tools\" and select \"Export Appliance\" to initiate the export task. When the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I prepare a VHD file for import from Microsoft Hyper-V?"}, {"role": "assistant", "content": "Open the Hyper-V Manager and select the virtual machine you want to export. In the Actions pane for the virtual machine, select \"Export\" to initiate the export task. Once the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any other requirements when importing a VM into Amazon EC2?"}, {"role": "assistant", "content": "The virtual machine must be in a stopped state before generating the VMDK or VHD image. The VM cannot be in a paused or suspended state. We suggest that you export the virtual machine with only the boot volume attached. You can import additional disks using the ImportVolume command and attach them to the virtual machine using AttachVolume. Additionally, encrypted disks (e.g. Bit Locker) and encrypted image files are not supported. You are also responsible for ensuring that you have all necessary rights and licenses to import into AWS and run any software included in your VM image."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does the virtual machine need to be configured in any particular manner to enable import to Amazon EC2?"}, {"role": "assistant", "content": "Ensure Remote Desktop (RDP) or Secure Shell (SSH) is enabled for remote access and verify that your host firewall (Windows firewall, iptables, or similar), if configured, allows access to RDP or SSH. Otherwise, you will not be able to access your instance after the import is complete. Please also ensure that Windows VMs are configured to use strong passwords for all users including the administrator and that Linux VMs are configured with a public key for SSH access."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I import a virtual machine to an Amazon EC2 instance?"}, {"role": "assistant", "content": "You can import your VM images using the Amazon EC2 API tools:Import the VMDK, VHD or RAW file via the ec2-import-instance API. The import instance task captures the parameters necessary to properly configure the Amazon EC2 instance properties (instance size, Availability Zone, and security groups) and uploads the disk image into Amazon S3.If ec2-import-instance is interrupted or terminates without completing the upload, use ec2-resume-import to resume the upload. The import task will resume where it left off.Use the ec2-describe-conversion-tasks command to monitor the import progress and obtain the resulting Amazon EC2 instance ID.Once your import task is completed, you can boot the Amazon EC2 instance by specifying its instance ID to the ec2-run-instances API.Finally, use the ec2-delete-disk-image command line tool to delete your disk image from Amazon S3 as it is no longer needed. Alternatively, if you use the VMware vSphere virtualization platform, you can import your virtual machine to Amazon EC2 using a graphical user interface provided through [AWS Management Portal for vCenter](/web/20240727055400/https://aws.amazon.com/ec2/vcenter-portal/). Please refer to the Getting Started Guide in AWS Management Portal for vCenter. AWS Management Portal for vCenter includes integrated support for VM Import. Once the portal is installed within vCenter, you can right-click on a VM and select \u201cMigrate to EC2\u201d to create an EC2 instance from the VM. The portal will handle exporting the VM from vCenter, uploading it to S3, and converting it into an EC2 instance for you, with no additional work required. You can also track the progress of your VM migrations within the portal."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I export an Amazon EC2 instance back to my on-premise virtualization environment?"}, {"role": "assistant", "content": "You can export your Amazon EC2 instance using the Amazon EC2 CLI tools:Export the instance using the ec2-create-instance-export-task command. The export command captures the parameters necessary (instance ID, S3 bucket to hold the exported image, name of the exported image, VMDK, OVA or VHD format) to properly export the instance to your chosen format. The exported file is saved in an S3 bucket that you previously created.Use ec2-describe-export-tasks to monitor the export progress.Use ec2-cancel-export-task to cancel an export task prior to completion."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any other requirements when exporting an EC2 instance using VM Import/Export?"}, {"role": "assistant", "content": "You can export running or stopped EC2 instances that you previously imported using VM Import/Export. If the instance is running, it will be momentarily stopped to snapshot the boot volume. EBS data volumes cannot be exported. EC2 instances with more than one network interface cannot be exported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I export Amazon EC2 instances that have one or more EBS data volumes attached?"}, {"role": "assistant", "content": "Yes, but VM Import/Export will only export the boot volume of the EC2 instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does it cost to import a virtual machine?"}, {"role": "assistant", "content": "You will be charged standard Amazon S3 data transfer and storage fees for uploading and storing your VM image file. Once your VM is imported, standard Amazon EC2 instance hour and EBS service fees apply. If you no longer wish to store your VM image file in S3 after the import process completes, use the ec2-delete-disk-image command line tool to delete your disk image from Amazon S3."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What does it cost to export a VM?"}, {"role": "assistant", "content": "You will be charged standard Amazon S3 storage fees for storing your exported VM image file. You will also be charged standard S3 data transfer charges when you download the exported VM file to your on-premise virtualization environment. Finally, you will be charged standard EBS charges for storing a temporary snapshot of your EC2 instance. To minimize storage charges, delete the VM image file in S3 after downloading it to your virtualization environment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When I import a VM of Windows Server 2003 or 2008, who is responsible for supplying the operating system license?"}, {"role": "assistant", "content": "When you launch an imported VM using Microsoft Windows Server 2003 or 2008, you will be charged standard instance hour rates for Amazon EC2 running the appropriate Windows Server version, which includes the right to utilize that operating system within Amazon EC2. You are responsible for ensuring that all other installed software is properly licensed.So then, what happens to my on-premise Microsoft Windows license key when I import a VM of Windows Server 2003 or 2008"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I continue to use the AWS provided Microsoft Windows license key after exporting an EC2 instance back to my on-premises virtualization environment?"}, {"role": "assistant", "content": "No. After an EC2 instance has been exported, the license key utilized in the EC2 instance is no longer available. You will need to reactivate and specify a new license key for the exported VM after it is launched in your on-premises virtualization platform."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When I import a VM with Red Hat Enterprise Linux (RHEL), who is responsible for supplying the operating system license?"}, {"role": "assistant", "content": "When you import Red Hat Enterprise Linux (RHEL) VM images, you can use license portability for your RHEL instances. With license portability, you are responsible for maintaining the RHEL licenses for imported instances, which you can do using Cloud Access subscriptions for Red Hat Enterprise Linux. Please contact Red Hat to learn more about Cloud Access and to verify your eligibility."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long does it take to import a virtual machine?"}, {"role": "assistant", "content": "The length of time to import a virtual machine depends on the size of the disk image and your network connection speed. As an example, a 10 GB Windows Server 2008 SP2 VMDK image takes approximately 2 hours to import when it\u2019s transferred over a 10 Mbps network connection. If you have a slower network connection or a large disk to upload, your import may take significantly longer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: In which Amazon EC2 Regions can I use VM Import/Export?"}, {"role": "assistant", "content": "Visit the [Region Table](/web/20240727055400/https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/) page to see product service availability by Region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many simultaneous import or export tasks can I have?"}, {"role": "assistant", "content": "Each account can have up to five active import tasks and five export tasks per region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I run imported virtual machines in Amazon Virtual Private Cloud (Amazon VPC)?"}, {"role": "assistant", "content": "Yes, you can launch imported virtual machines within Amazon VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use the AWS Management Console with VM Import/Export?"}, {"role": "assistant", "content": "No. VM Import/Export commands are available via EC2 CLI and API. You can also use the [AWS Management Portal for vCenter](/web/20240727055400/https://aws.amazon.com/ec2/vcenter-portal/) to import VMs into Amazon EC2. Once imported, the resulting instances are available for use via the AWS Management Console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be charged and billed for my use of Amazon EC2?"}, {"role": "assistant", "content": "You pay only for what you use. Displayed pricing is an hourly rate but depending on which instances you choose, you pay by the hour or second (minimum of 60 seconds) for each instance type. Partial instance-hours consumed are billed based on instance usage. Data transferred between AWS services in different regions is charged at standard inter-region data transfer rates. Usage for other Amazon Web Services is billed separately from Amazon EC2.For EC2 pricing information, please visit the [pricing section on the EC2 detail page](/web/20240727055400/https://aws.amazon.com/ec2/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When does billing of my Amazon EC2 systems begin and end?"}, {"role": "assistant", "content": "Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running \"shutdown -h\", or through instance failure. When you stop an instance, we shut it down but don't charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the [AWS Documentation](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What defines billable EC2 instance usage?"}, {"role": "assistant", "content": "Instance usages are billed for any time your instances are in a \"running\" state. If you no longer wish to be charged for your instance, you must \"stop\" or \"terminate\" the instance to avoid being billed for additional instance usage. Billing starts when an instance transitions into the running state."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I have two instances in different availability zones, how will I be charged for regional data transfer?"}, {"role": "assistant", "content": "Each instance is charged for its data in and data out at corresponding Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at \"Data Transfer Out from EC2 to Another AWS Region\" for the first instance and at \"Data Transfer In from Another AWS Region\" for the second instance. Please refer to [this page](/web/20240727055400/https://aws.amazon.com/ec2/pricing/on-demand/) for detailed data transfer pricing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I have two instances in different Regions, how will I be charged for data transfer?"}, {"role": "assistant", "content": "Each instance is charged for its data in and data out at Inter-Region Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at Inter-Region Data Transfer Out for the first instance and at Inter-Region Data Transfer In for the second instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will my monthly bill show per-second versus per-hour?"}, {"role": "assistant", "content": "Although EC2 charges in your monthly bill will now be calculated based on a per second basis, for consistency, the monthly EC2 bill will show cumulative usage for each instance that ran in a given month in decimal hours. For example, an instance running for 1 hour 10 minutes and 4 seconds would look like 1.1677. Read [this](https://web.archive.org/web/20240727055400/https://aws.amazon.com/blogs/aws/new-per-second-billing-for-ec2-instances-and-ebs-volumes/) blog for an example of the detailed billing report."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do your prices include taxes?"}, {"role": "assistant", "content": "Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax. For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. [Learn more](/web/20240727055400/https://aws.amazon.com/c-tax-faqs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I incur any data transfer out to the internet charges when I move my data out of AWS?"}, {"role": "assistant", "content": "AWS offers eligible customers free data transfer out to the internet when they move all of their data off of AWS, in accordance with the process below."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I want to move my data out of AWS. How do I request free data transfer out to the internet?"}, {"role": "assistant", "content": "Complete the following steps:1) If you have a dedicated AWS account team, contact them first and inform them of your plans. In some cases, if you have a negotiated commitment with AWS, you'll want to discuss your options with your AWS account team.2) Review the criteria and process described on this page.3) Contact [AWS Customer Support](/web/20240727055400/https://aws.amazon.com/contact-us/) and indicate that your request is for \u201cfree data transfer to move off AWS.\u201d AWS Customer Support will ask that you provide information, so they can review your moving plans, evaluate whether you qualify for free data transfer out, and calculate a proper credit amount.4) If AWS Customer Support approves your move, you will receive a temporary credit for the cost of data transfer out based on the volume of all data you have stored across AWS services at the time of AWS\u2019 calculation. AWS Customer Support will notify you if you are approved, and you will then have 60 days to complete your move off of AWS. The credit will count against data transfer out usage only, and it will not be applied to other service usage. After your move away from AWS services, within the 60-day period, you must delete all remaining data and workloads from your AWS account, or you can close your AWS account.Free data transfers for moving IT providers are also subject to the following criteria:a) Only customers with an active AWS account in good standing are eligible for free data transfer out.b) If you have less than 100 GB of data stored in your AWS account you may move this data off of AWS for free under AWS\u2019s existing 100 GB monthly free tier for data transfer out. Customers with less than 100 GB of data stored in their AWS account are not eligible for additional credits.c) AWS will provide you with free data transfer out to the internet when you move all of your data off of AWS. If you only want to move your total usage of a single service, but not everything, contact [AWS Customer Support](/web/20240727055400/https://aws.amazon.com/contact-us/).d) If your plans change, or you cannot complete your move off of AWS within 60 days, you must notify [AWS Customer Support](/web/20240727055400/https://aws.amazon.com/contact-us/).e) Standard services charges for use of AWS services are not included. Only data transfer out charges in support of your move off of AWS are eligible for credits. However, data transfer out from specialized data transfer services, such as Amazon CloudFront, AWS Direct Connect, AWS Snow Family, and AWS Global Accelerator, are not included.f) AWS may review your service usage to verify compliance with these requirements. If we determine your use of data transfer out was for a purpose other than moving off of AWS, we may charge you for the data transfer out that had been credited.g) AWS may make changes with respect to free data transfers out to the internet at any time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why do I have to request AWS\u2019 pre-approval for free data transfer out to the internet before moving my data out of AWS?"}, {"role": "assistant", "content": "AWS customers make hundreds of millions of data transfers each day, and we generally don\u2019t know the reason for any given data transfer. For example, customers may be transferring data to an end user of their application, to a visitor of their website, or to another cloud or on-premises environment for backup purposes. Accordingly, the only way we know that your data transfer is to support your move off of AWS is if you tell us beforehand."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a Convertible RI?"}, {"role": "assistant", "content": "A Convertible RI is a type of Reserved Instance with attributes that can be changed during the term."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I purchase a Convertible RI instead of a Standard RI?"}, {"role": "assistant", "content": "The Convertible RI is useful for customers who can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What term length options are available on Convertible RIs?"}, {"role": "assistant", "content": "Like Standard RIs, Convertible RIs are available for purchase for a one-year or three-year term."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I exchange my Convertible RI to benefit from a Convertible RI matching a different instance type, operating system, tenancy, or payment option?"}, {"role": "assistant", "content": "Yes, you can select a new instance type, operating system, tenancy, or payment option when you exchange your Convertible RIs. You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I transfer a Convertible or Standard RI from one region to another?"}, {"role": "assistant", "content": "No, an RI is associated with a specific region, which is fixed for the duration of the reservation's term."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I change the configuration of a Convertible RI?"}, {"role": "assistant", "content": "You can change the configuration of your Convertible RI using the EC2 Management Console or the [GetReservedInstancesExchangeQuote API](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_GetReservedInstancesExchangeQuote.html). You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange. [Click here](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-convertible-exchange.html) to learn more about exchanging Convertible RIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to pay a fee when I exchange my Convertible RIs?"}, {"role": "assistant", "content": "No, you do not pay a fee when you exchange your RIs. However you may need to pay a one-time true-up charge that accounts for differences in pricing between the Convertible RIs that you have and the Convertible RIs that you want."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do Convertible RI exchanges work?"}, {"role": "assistant", "content": "When you exchange one Convertible RI for another, EC2 ensures that the total value of the Convertible RIs is maintained through a conversion. So, if you are converting your RI with a total value of $1000 for another RI, you will receive a quantity of Convertible RIs with a value that\u2019s equal to or greater than $1000. You cannot convert your Convertible RI for Convertible RI(s) of a lesser total value."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you define total value?"}, {"role": "assistant", "content": "The total value is the sum of all expected payments that you\u2019d make during the term for the RI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you walk me through how the true-up cost is calculated for a conversion between two All Upfront Convertible RIs?"}, {"role": "assistant", "content": "Sure, let\u2019s say you purchased an All Upfront Convertible RI for $1000 upfront, and halfway through the term you decide to change the attributes of the RI. Since you\u2019re halfway through the RI term, you have $500 left of prorated value remaining on the RI. The All Upfront Convertible RI that you want to convert into costs $1,200 upfront today. Since you only have half of the term left on your existing Convertible RI, there is $600 of value remaining on the desired new Convertible RI. The true-up charge that you\u2019ll pay will be the difference in upfront value between original and desired Convertible RIs, or $100 ($600 - $500)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you walk me through a conversion between No Upfront Convertible RIs?"}, {"role": "assistant", "content": "Unlike conversions between Convertible RIs with an upfront value, since you\u2019re converting between RIs without an upfront cost, there will not be a true-up charge. However, the amount you pay on an hourly basis before the exchange will need to be greater than or equal to the amount you pay on a total hourly basis after the exchange.For example, let\u2019s say you purchased one No Upfront Convertible RI (A) with a $0.10/hr rate, and you decide to exchange Convertible RI A for another RI (B) that costs $0.06/hr. When you convert, you will receive two RIs of B because the amount that you pay on an hourly basis must be greater than or equal to the amount you\u2019re paying for A on an hourly basis."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I customize the number of instances that I receive as a result of a Convertible RI exchange?"}, {"role": "assistant", "content": "No, EC2 uses the value of the Convertible RIs you\u2019re trading in to calculate the minimal number of Convertible RIs you\u2019ll receive while ensuring the result of the exchange gives you Convertible RIs of equal or greater value."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there exchange limits for Convertible RIs?"}, {"role": "assistant", "content": "No, there are no exchange limits for Convertible RIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I have the freedom to choose any instance type when I exchange my Convertible RIs?"}, {"role": "assistant", "content": "No, you can only exchange into Convertible RIs that are currently offered by AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I upgrade the payment option associated with my Convertible RI?"}, {"role": "assistant", "content": "Yes, you can upgrade the payment option associated with your RI. For example, you can exchange your No Upfront RIs for Partial or All Upfront RIs to benefit from better pricing. You cannot change the payment option from All Upfront to No Upfront, and cannot change from Partial Upfront to No Upfront."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Convertible RIs allow me to benefit from price reductions when they happen?"}, {"role": "assistant", "content": "Yes, you can exchange your RIs to benefit from lower pricing. For example, if the price of new Convertible RIs reduces by 10%, you can exchange your Convertible RIs and benefit from the 10% reduction in price."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EC2 Fleet?"}, {"role": "assistant", "content": "With a single API call, EC2 Fleet lets you provision compute capacity across different instance types, Availability Zones and across On-Demand, Reserved Instances (RI) and Spot Instances purchase models to help optimize scale, performance and cost."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I currently use Amazon EC2 Spot Fleet should I migrate to Amazon EC2 Fleet?"}, {"role": "assistant", "content": "If you are leveraging Amazon EC2 Spot Instances with Spot Fleet, you can continue to use that. Spot Fleet and EC2 Fleet offer the same functionality. There is no requirement to migrate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Reserved Instance (RI) discounts with Amazon EC2 Fleet?"}, {"role": "assistant", "content": "Yes. Similar to other EC2 APIs or other AWS services that launch EC2 instances, if the On-Demand instance launched by EC2 Fleet matches an existing RI, that instance will receive the RI discount. For example, if you own Regional RIs for M4 instances and you have specified only M4 instances in your EC2 Fleet, RI discounts will be automatically applied to this usage of M4."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will Amazon EC2 Fleet failover to On-Demand if EC2 Spot capacity is not fully fulfilled?"}, {"role": "assistant", "content": "No, EC2 Fleet will continue to attempt to meet your desired Spot capacity based on the number of Spot instances you requested in your Fleet launch specification."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the pricing for Amazon EC2 Fleet?"}, {"role": "assistant", "content": "EC2 Fleet comes at no additional charge; you only pay for the underlying resources that EC2 Fleet launches."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you provide a real world example of how I can use Amazon EC2 Fleet?"}, {"role": "assistant", "content": "There are a number of ways to take advantage of Amazon EC2 Fleet, such as in big data workloads, containerized application, grid processing workloads, etc. In [this](https://web.archive.org/web/20240727055400/https://aws.amazon.com/blogs/aws/ec2-fleet-manage-thousands-of-on-demand-and-spot-instances-with-one-request/) example of a genomic sequencing workload, you can launch a grid of worker nodes with a single API call: select your favorite instances, assign weights for these instances, specify target capacity for On-Demand and Spot Instances, and build a fleet within seconds to crunch through genomic data quickly."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I allocate resources in an Amazon EC2 Fleet?"}, {"role": "assistant", "content": "By default, EC2 Fleet will launch the On-Demand option that is the lowest price. For Spot Instances, EC2 Fleet provides three allocation strategies: capacity-optimized, lowest price and diversified. The capacity-optimized allocation strategy attempts to provision Spot Instances from the most available Spot Instance pools by analyzing capacity metrics. This strategy is a good choice for workloads that have a higher cost of interruption such as big data and analytics, image and media rendering, machine learning, and high performance computing. The lowest price strategy allows you to provision Spot Instances in pools that provide the lowest price per unit of capacity at the time of the request. The diversified strategy allows you to provision Spot Instances across multiple Spot pools and you can maintain your fleet\u2019s target capacity to increase application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I submit a multi-region Amazon EC2 Fleet request?"}, {"role": "assistant", "content": "No, we do not support multi-region EC2 Fleet requests."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I tag an Amazon EC2 Fleet?"}, {"role": "assistant", "content": "Yes. You can tag an EC2 Fleet request to create business-relevant tag groupings to organize resources along technical, business, and security dimensions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I modify my Amazon EC2 Fleet?"}, {"role": "assistant", "content": "Yes, you can modify the total target capacity of your EC2 Fleet when in maintain mode. You may need to cancel the request and submit a new one to change other request configuration parameters."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I specify a different AMI for each instance type that I want to use?"}, {"role": "assistant", "content": "Yes, simply specify the AMI you\u2019d like to use in each launch specification you provide in your EC2 Fleet."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 Capacity Blocks for ML?"}, {"role": "assistant", "content": "Amazon EC2 Capacity Blocks for ML allow you to reserve GPU instances\u00a0in an Amazon EC2 UltraClusters to run your machine learning (ML) workloads. With Amazon EC2 Capacity Blocks, you can reserve GPU capacity starting on a future date for durations up to 28 days and in cluster sizes of one to 64 instances. When your EC2 Capacity Block reservation date and time arrives, you will be able to launch your instances and use them until your reservation time ends."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use EC2 Capacity Blocks?"}, {"role": "assistant", "content": "EC2 Capacity Blocks make it easy to access the highest-performing GPU instances in Amazon EC2 for ML, even in the face of industry-wide GPU shortages. Use EC2 Capacity Blocks to ensure capacity availability for GPU instances to plan your ML development with confidence. EC2 Capacity Blocks are delivered in [EC2 UltraClusters](/web/20240727055400/https://aws.amazon.com/ec2/ultraclusters/) so you can leverage the best network latency and throughput performance available in EC2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Amazon EC2 Capacity Blocks instead of On-Demand Capacity Reservations?"}, {"role": "assistant", "content": "You should use EC2 Capacity Blocks when you need short-term capacity assurance to train or fine-tune ML models, run experiments, build prototypes, or handle surges in demand for ML applications. With EC2 Capacity Blocks, you can have peace of mind knowing you\u2019ll have access to GPU resources on a specific date to run your ML workloads. You should use [On-Demand Capacity Reservations](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) for all other workload types that need assurance, such as business-critical applications, regulatory requirements, or disaster recovery."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I get started with EC2 Capacity Blocks?"}, {"role": "assistant", "content": "You can search for available EC2 Capacity Blocks based on your capacity needs in the [AWS Management Console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/), [AWS Command Line Interface (AWS CLI)](/web/20240727055400/https://aws.amazon.com/cli/), and [AWS SDKs](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/EC2.html). Once you purchase an EC2 Capacity Block, a reservation is created in your account. When the EC2 Capacity Block start time arrives, EC2 will emit an event through Amazon EventBridge to indicate that the reservation is now active and available for use. To use an active EC2 Capacity Block, select the \u201cCapacity Block\u201d purchase option and target the capacity reservation ID for your EC2 Capacity Block while launching EC2 instances. As your EC2 Capacity Block end time approaches, EC2 will emit event through EventBridge letting you know your reservation is ending soon so you can checkpoint your workload. Around 30 minutes before your EC2 Capacity Block expires, AWS will begin terminating any running instances. The amount you are charged for your EC2 Capacity Block does not include the last 30 minutes of the reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which instance types do EC2 Capacity Blocks support, and which AWS Regions are they available in?"}, {"role": "assistant", "content": "EC2 Capacity Blocks support EC2 p5.48xlarge instances in the AWS US East (N. Virginia) and US East (Ohio) regions and EC2 p4d.24xlarge instances in US East (Ohio) and US West (Oregon) regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What size options are available with EC2 Capacity Blocks?"}, {"role": "assistant", "content": "EC2 Capacity Blocks are available in cluster sizes of 1, 2, 4, 8, 16, 32, and 64 instances, and they can be reserved for up to 14 days in one-day increments, or up to 28 days in seven-day increments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How far in advance can I reserve an EC2 Capacity Block?"}, {"role": "assistant", "content": "You can purchase an EC2 Capacity Block as far out as eight weeks into the future. All EC2 Capacity Blocks reservations start at 11:30 AM Coordinated Universal Time (UTC)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if there are no EC2 Capacity Blocks available that meet my specifications?"}, {"role": "assistant", "content": "If there are no EC2 Capacity Blocks that match your requirements, you can retry your request with different input parameters. We recommend that you use the widest date range possible in your search requests for the best chance at finding an EC2 Capacity Block."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I modify or cancel my EC2 Capacity Block?"}, {"role": "assistant", "content": "No, an EC2 Capacity Block cannot be modified or canceled once it is reserved."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much do EC2 Capacity Blocks cost?"}, {"role": "assistant", "content": "When you search for an EC2 Capacity Block across dates, AWS returns the lowest-priced offering available that meets your specifications in the date range you provide. The price for an EC2 Capacity Block depends on total available supply and demand at the time you purchase the reservation. You can view the price of an EC2 Capacity Block offering before you reserve it, and the price of an EC2 Capacity Block is charged up front at the time the reservation is made. The price of an EC2 Capacity Block does not change after it is reserved. When you launch instances in an active EC2 Capacity Block, you will only be charged for the usage of any premium operating system on a pay-as-you-go basis."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Savings Plans and Reserved Instances (RI) discounts apply to EC2 Capacity Blocks?"}, {"role": "assistant", "content": "No, EC2 Capacity Blocks are not covered by Savings Plans or RI discounts."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use EC2 Capacity Blocks with Amazon SageMaker?"}, {"role": "assistant", "content": "At this time, EC2 Capacity Blocks only support EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much do On-Demand Capacity Reservations cost?"}, {"role": "assistant", "content": "When the On-Demand Capacity Reservation is active, you will pay equivalent instance charges whether you run the instances or not. If you do not use the reservation, the charge will show up as an unused reservation on your EC2 bill. When you run an instance that matches the attributes of a reservation, you just pay for the instance and nothing for the reservation. There are no upfront or additional charges.For example, if you create an\u00a0On-Demand Capacity Reservation for 20 c5.2xlarge instances and you run 15 c5.2xlarge instances, you will be charged for 15 instances and five unused instances in the reservation (effectively charged for 20 instances)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I get a discount for On-Demand Capacity Reservation usage?"}, {"role": "assistant", "content": "Yes. Savings Plans or Regional RI (RI scoped to a Region) discounts apply to On-Demand Capacity Reservations. When you are running an instance within your reservation, you are not charged for the reservation. Savings Plans or Regional RIs will apply to this usage as if it were On-Demand usage. When the reservation is not used, AWS Billing will automatically apply your discount when the attributes of the unused On-Demand Capacity Reservation match the attributes of an active Savings Plan or Regional RI. For example, if you have a Regional RI for 10 c5.2xlarge instances and an unused On-Demand Capacity Reservation for 10 c5.2xlarge instances in the same Region, the RI discount will apply to all 10 instances on the reservation. Note that we apply Regional RI discounts preferentially to running instance usage before covering unused On-Demand Capacity Reservations. Meaning, if you have any other C5 instances running in the Region, we will apply the Regional RI first to those instances, and then we will apply the remaining discount to the unused On-Demand Capacity Reservation. Note: A Regional RI is an EC2 RI scoped to an AWS Region. Zonal RIs (RIs scoped to an AZ within a Region) discounts do not apply to On-Demand Capacity Reservations, as Zonal RIs already come with a capacity reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Savings Plans, EC2 RIs, and On-Demand Capacity Reservations?"}, {"role": "assistant", "content": "Use Savings Plans or Regional RIs to reduce your bill while committing to a one- or three-year term. Savings Plans offer significant savings over On-Demand, just like EC2 RIs, but automatically reduce customers\u2019 bills on compute usage across any AWS Region, even as usage changes. Use On-Demand Capacity Reservations if you need the additional confidence in your ability to launch instances. On-Demand\u00a0Capacity Reservations can be created for any duration and can be managed independently of your Savings Plans or RIs. If you have Savings Plans or Regional RIs, they will automatically apply to matching On-Demand\u00a0Capacity Reservations. This gives you the flexibility to selectively add On-Demand Capacity Reservations to a portion of your instance footprint and still reduce your bill for that usage."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I have a Zonal RI (RI scoped to an AZ) that also provides a capacity reservation. How does this compare with an On-Demand\u00a0Capacity Reservation?"}, {"role": "assistant", "content": "A Zonal RI provides both a discount and a capacity reservation in a specific AZ in return for a one- to three-year commitment. An On-Demand\u00a0Capacity Reservation allows you to create and manage reserved capacity independently of your RI commitment and term length.You can use On-Demand Capacity Reservations with a Savings Plan or a Regional RI to get, at the minimum, all the benefits of a Zonal RI for no additional cost. You also get the enhanced flexibility of a Savings Plan (or Regional RI) and the features of an On-Demand Capacity Reservation: the ability to add or subtract from the reservation at any time, view reservation utilization in real time, and the ability to target an\u00a0On-Demand Capacity Reservation for specific workloads.Rescoping your Zonal RIs to a Region immediately gives you the AZ and instance-size flexibility in how RI discounts are applied. You can convert your Standard Zonal RIs to a Regional RI by modifying the scope of the RI from a specific AZ to a Region using the EC2 console or the ModifyReservedInstances API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I created an\u00a0On-Demand Capacity Reservation. How can I use it?"}, {"role": "assistant", "content": "An\u00a0On-Demand Capacity Reservation is tied to a specific AZ and is, by default, automatically used by running instances in that AZ. When you launch new instances that match the reservation attributes, they will automatically match to the reservation.You can also target a reservation for specific workloads/instances if you prefer. Refer to [Linux](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) or [Windows](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) technical documentation to learn more about the targeting option."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many instances am I allowed to reserve?"}, {"role": "assistant", "content": "The number of instances that you are allowed to reserve is based on your account's On-Demand instance limit. You can reserve as many instances as that limit allows, minus the number of instances that are already running.If you need a higher limit, contact your AWS sales representative or complete the Amazon EC2 instance [request form](/web/20240727055400/https://aws.amazon.com/contact-us/ec2-request/) with your use case and your instance increase will be considered. Limit increases are tied to the region they are requested for."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I modify an\u00a0On-Demand Capacity Reservation after it has started?"}, {"role": "assistant", "content": "Yes. You can reduce the number of instances that you reserved at any time. You can also increase the number of instances (subject to availability). You can also modify the end time of your reservation. You cannot modify an\u00a0On-Demand Capacity Reservation that has ended or has been deleted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I end an\u00a0On-Demand Capacity Reservation after it has started?"}, {"role": "assistant", "content": "Yes. You can end an\u00a0On-Demand Capacity Reservation by canceling it using the console or API/SDK, or by modifying your reservation to specify an end time that makes it expire automatically. Running instances are unaffected by changes to your On-Demand\u00a0Capacity Reservation, including deletion or expiration of a reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find more information about using On-Demand\u00a0Capacity Reservations?"}, {"role": "assistant", "content": "Refer to [Linux](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) or [Windows](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) technical documentation to learn about creating and using an\u00a0On-Demand Capacity Reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I share an\u00a0On-Demand Capacity Reservation with another AWS account?"}, {"role": "assistant", "content": "Yes, you can share\u00a0On-Demand Capacity Reservations with other AWS accounts or within your AWS Organization through\u00a0[AWS Resource Access Manager](/web/20240727055400/https://aws.amazon.com/ram/) (AWS RAM). You can share EC2 On-Demand\u00a0Capacity Reservations in three easy steps: Create a Resource Share using AWS RAM, add resources (On-Demand Capacity Reservations) to the Resource Share, and specify the target accounts that you wish to share the resources with.Note that sharing of an On-Demand\u00a0Capacity Reservation is not available to new AWS accounts or AWS accounts that have a limited billing history. New accounts that are linked to a qualified primary (payer) account or through an AWS Organization are exempt from this restriction."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens when I share an\u00a0On-Demand Capacity Reservation with another AWS account?"}, {"role": "assistant", "content": "When an\u00a0On-Demand Capacity Reservation is shared with other accounts, those accounts can consume the reserved capacity to run their EC2 instances. The exact behavior depends on the preferences set on the On-Demand\u00a0Capacity Reservation. By default, On-Demand\u00a0Capacity Reservations automatically match existing and new instances from other accounts that have shared access to the reservation. You can also target an\u00a0On-Demand Capacity Reservation for specific workloads/instances. Individual accounts can control which of their instances consume On-Demand\u00a0Capacity Reservations. Refer to [Linux](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) or [Windows](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) technical documentation to learn more about the instance matching options."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there an additional charge for sharing a reservation?"}, {"role": "assistant", "content": "No, there is no additional charge for sharing a reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who gets charged when an\u00a0On-Demand Capacity Reservation is shared across multiple accounts?"}, {"role": "assistant", "content": "If multiple accounts are consuming an\u00a0On-Demand Capacity Reservation, each account gets charged for its own instance usage. Unused reserved capacity, if any, gets charged to the account that owns the On-Demand\u00a0Capacity Reservation. If there is a consolidated billing arrangement among the accounts that share an\u00a0On-Demand Capacity Reservation, the primary account gets billed for instance usage across all the linked accounts."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I prioritize access to an On-Demand\u00a0Capacity Reservation among the AWS accounts that have shared access?"}, {"role": "assistant", "content": "No. Instance spots in an On-Demand Capacity Reservation are available on a first-come, first-served basis to any account that has shared access."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I communicate the AZ of an On-Demand Capacity Reservation with another account, given AZ name mappings could be different across AWS accounts?"}, {"role": "assistant", "content": "You can now use an Availability Zone ID (AZ ID) instead of an AZ name. An AZ ID is a static reference and provides a consistent way of identifying the location of a resource across all your accounts. This makes it easier for you to provision resources centrally in a single account and share them across multiple accounts."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I stop sharing my On-Demand Capacity Reservation once I have shared it?"}, {"role": "assistant", "content": "Yes, you can stop sharing a reservation after you have shared it. When you stop sharing an On-Demand Capacity Reservation with specific accounts or stop sharing entirely, other accounts lose the ability to launch new instances into the On-Demand Capacity Reservation. Any capacity occupied by instances running from other accounts will be restored to the On-Demand Capacity Reservation for your use (subject to availability)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where can I find more information about sharing On-Demand Capacity Reservations?"}, {"role": "assistant", "content": "Refer to [Linux](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/capacity-reservation-sharing.html) or [Windows](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/capacity-reservation-sharing.html) technical documentation to learn about sharing On-Demand Capacity Reservations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I get a discount for On-Demand Capacity Reservation usage?"}, {"role": "assistant", "content": "Yes. Savings Plans or Regional RI discounts apply to On-Demand Capacity Reservations. AWS Billing automatically applies the discount when the attributes of an On-Demand Capacity Reservation match the attributes of a Savings Plan or Regional RI. When an On-Demand Capacity Reservation is used by an instance, you are only charged for the instance (with Savings Plan or RI discounts applied). Discounts are preferentially applied to instance usage before covering unused On-Demand Capacity Reservations. Note: A Regional RI is an EC2 RI scoped to an AWS Region. Zonal RI (RIs scoped to an AZ within a Region) discounts do not apply to On-Demand Capacity Reservations, as Zonal RIs already come with a capacity reservation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a Reserved Instance?"}, {"role": "assistant", "content": "A Reserved Instance (RI) is an EC2 offering that provides you with a significant discount on EC2 usage when you commit to a one-year or three-year term."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the differences between Standard RIs and Convertible RIs?"}, {"role": "assistant", "content": "Standard RIs offer a significant discount on EC2 instance usage when you commit to a particular instance family. Convertible RIs offer you the option to change your instance configuration during the term, and still receive a discount on your EC2 usage. For more information on Convertible RIs, please click [here](#Convertible_Reserved_Instances)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do RIs provide a capacity reservation?"}, {"role": "assistant", "content": "Yes, when a Standard or Convertible RI is scoped to a specific Availability Zone (AZ), instance capacity matching the exact RI configuration is reserved for your use (these are referred to as \u201czonal RIs\u201d). Zonal RIs give you additional confidence in your ability to launch instances when you need them.You can also choose to forgo the capacity reservation and purchase Standard or Convertible RIs that are scoped to a region (referred to as \u201cregional RIs\u201d). Regional RIs automatically apply the discount to usage across AZs and instance sizes in a region, making it easier for you to take advantage of the RI\u2019s discounted rate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I purchase a zonal RI?"}, {"role": "assistant", "content": "If you want to take advantage of the capacity reservation, then you should buy an RI in a specific AZ."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I purchase a regional RI?"}, {"role": "assistant", "content": "If you do not require the capacity reservation, then you should buy a regional RI. Regional RIs provide AZ and instance size flexibility, which offer broader applicability of the RI\u2019s discounted rate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are AZ and instance size flexibility?"}, {"role": "assistant", "content": "AZ and instance size flexibility make it easier for you to take advantage of your regional RI\u2019s discounted rate. AZ flexibility applies your RI\u2019s discounted rate to usage in any AZ in a Region, while instance size flexibility applies your RI\u2019s discounted rate to usage of any size within an instance family. Let\u2019s say you own an m5.2xlarge Linux/Unix regional RI with default tenancy in US East (N. Virginia). Then this RI\u2019s discounted rate can automatically apply to two m5.xlarge instances in us-east-1a or four m5.large instances in us-east-1b."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What types of RIs provide instance size flexibility?"}, {"role": "assistant", "content": "Linux/Unix regional RIs with the default tenancy provide instance size flexibility. Instance size flexibility is not available on RIs of other platforms such as Windows, Windows with SQL Standard, Windows with SQL Server Enterprise, Windows with SQL Server Web, RHEL, and SLES or G4 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to take any action to take advantage of AZ and instance size flexibility?"}, {"role": "assistant", "content": "Regional RIs do not require any action to take advantage of AZ and instance size flexibility."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I own zonal RIs. How do I assign them to a region?"}, {"role": "assistant", "content": "You can assign your Standard zonal RIs to a region by modifying the scope of the RI from a specific AZ to a Region from the EC2 console or by using the ModifyReservedInstances API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I purchase an RI?"}, {"role": "assistant", "content": "To get started, you can purchase an RI from the EC2 console or by using the AWS CLI. Simply specify the instance type, platform, tenancy, term, payment option, and region or AZ."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I purchase an RI for a running instance?"}, {"role": "assistant", "content": "Yes, AWS will automatically apply an RI\u2019s discounted rate to any applicable instance usage from the time of purchase. Visit the [Getting Started page](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#apply_ri) to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I control which instances are billed at the discounted rate?"}, {"role": "assistant", "content": "No. AWS automatically optimizes which instances are charged at the discounted rate to ensure you always pay the lowest amount. For information about billing, and how it applies to RIs, see [Billing Benefits and Payment Options](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does instance size flexibility work?"}, {"role": "assistant", "content": "EC2 uses the scale shown below to compare different sizes within an instance family. In the case of instance size flexibility on RIs, this scale is used to apply the discounted rate of RIs to the normalized usage of the instance family. For example, if you have an m5.2xlarge RI that is scoped to a region, then your discounted rate could apply towards the usage of 1 m5.2xlarge or 2 m5.xlarge instances.[Click here](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#apply_ri) to learn more about how instance size flexibility of RIs applies to your EC2 usage. And [click here](https://web.archive.org/web/20240727055400/http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports.html#enhanced-RI) to learn about how instance size flexibility of RIs is presented in the Cost and Usage Report."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I change my RI during its term?"}, {"role": "assistant", "content": "Yes, you can modify the AZ of the RI, change the scope of the RI from AZ to Region (and the other way around), or modify instance sizes within the same instance family (on the Linux/Unix platform)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I change the instance type of my RI during its term?"}, {"role": "assistant", "content": "Yes. Convertible RIs offer you the option to change the instance type, operating system, tenancy or payment option of your RI during its term. Please refer to the Convertible RI section of the FAQ for additional information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the different payment options for RIs?"}, {"role": "assistant", "content": "You can choose from three payment options when you purchase an RI. With the All Upfront option, you pay for the entire RI term with one upfront payment. With the Partial Upfront option, you make a low upfront payment and are then charged a discounted hourly rate for the instance for the duration of the RI term. The No Upfront option does not require any upfront payment and provides a discounted hourly rate for the duration of the term."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When are RIs activated?"}, {"role": "assistant", "content": "The billing discount and capacity reservation (if applicable) is activated once your payment has successfully been authorized. You can view the status (pending | active | retired) of your RIs on the \"Reserved Instances\" page of the Amazon EC2 console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do RIs apply to Spot instances or instances running on a Dedicated Host?"}, {"role": "assistant", "content": "No, RIs do not apply to Spot instances or instances running on Dedicated Hosts. To lower the cost of using Dedicated Hosts, purchase Dedicated Host Reservations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do RIs work with Consolidated Billing?"}, {"role": "assistant", "content": "Our system automatically optimizes which instances are charged at the discounted rate to ensure that the consolidated accounts always pay the lowest amount. If you own RIs that apply to an AZ, then only the account which owns the RI will receive the capacity reservation. However, the discount will automatically apply to usage in any account across your consolidated billing family."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I get a discount on RI purchases?"}, {"role": "assistant", "content": "Yes, EC2 provides tiered discounts on RI purchases. These discounts are determined based on the total list value (non-discounted price) for the active RIs you have per Region. Your total list value is the sum of all expected payments for an RI within the term, including both the upfront and recurring hourly payments. The tier ranges and corresponding discounts are shown below."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you help me understand how volume discounts are applied to my RI purchases?"}, {"role": "assistant", "content": "Sure. Let's assume that you currently have $400,000 worth of active RIs in the US-east-1 region. Now, if you purchase RIs worth $150,000 in the same region, then the first $100,000 of this purchase would not receive a discount. However, the remaining $50,000 of this purchase would be discounted by 5 percent, so you would only be charged $47,500 for this portion of the purchase over the term based on your payment option.To learn more, please visit the [Understanding Reserved Instance Discount Pricing Tier](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#reserved-instances-discounts) portion of the [Amazon EC2 User Guide](https://web.archive.org/web/20240727055400/http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I calculate the list value of an RI?"}, {"role": "assistant", "content": "Here is a sample list value calculation for three-year Partial Upfront Reserved Instances:"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are volume discounts calculated if I use Consolidated Billing?"}, {"role": "assistant", "content": "If you leverage Consolidated Billing, AWS will use the aggregate total list price of active RIs across all of your consolidated accounts to determine which volume discount tier to apply. Volume discount tiers are determined at the time of purchase, so you should activate Consolidated Billing prior to purchasing RIs to ensure that you benefit from the largest possible volume discount that your consolidated accounts are eligible to receive."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Convertible RIs qualify for Volume Discounts?"}, {"role": "assistant", "content": "No, but the value of each Convertible RI that you purchase contributes to your volume discount tier standing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I determine which volume discount tier applies to me?"}, {"role": "assistant", "content": "To determine your current volume discount tier, please consult the [Understanding Reserved Instance Discount Pricing Tiers](https://web.archive.org/web/20240727055400/http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-tiers.html) portion of the [Amazon EC2 User Guide](https://web.archive.org/web/20240727055400/http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will the cost of my RIs change, if my future volume qualifies me for other discount tiers?"}, {"role": "assistant", "content": "No. Volume discounts are determined at the time of purchase, therefore the cost of your RIs will continue to remain the same as you qualify for other discount tiers. Any new purchase will be discounted according to your eligible volume discount tier at the time of purchase."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to take any action at the time of purchase to receive volume discounts?"}, {"role": "assistant", "content": "No, you will automatically receive volume discounts when you use the existing PurchaseReservedInstance API or EC2 Management Console interface to purchase RIs. If you purchase more than $10M worth of RIs [contact us](/web/20240727055400/https://aws.amazon.com/contact-us/aws-sales/) about receiving discounts beyond those that are automatically provided."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the Reserved Instance (RI) Marketplace?"}, {"role": "assistant", "content": "The RI Marketplace is an online marketplace that provides AWS customers the flexibility to sell their Amazon EC2 RIs to other businesses and organizations. Customers can also browse the RI Marketplace to find an even wider selection of RI term lengths and pricing options sold by other AWS customers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When can I list an RI on the RI Marketplace?"}, {"role": "assistant", "content": "You can list an RI when:You've registered as a seller in the RI Marketplace.You've paid for your RI.You've owned the RI for longer than 30 days."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can RIs be transferred?"}, {"role": "assistant", "content": "EC2 Reserved Instances are only transferrable in accordance with the requirements of the RI Marketplace provided in [AWS Service Terms](https://web.archive.org/web/20240727055400/https://aws.amazon.com/service-terms/) and cannot otherwise be transferred."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I sell any RI on the EC2 RI Marketplace?"}, {"role": "assistant", "content": "No, AWS prohibits the resale of RIs purchased as part of a discount program per [AWS Service Terms](https://web.archive.org/web/20240727055400/https://aws.amazon.com/service-terms/). Any All Upfront, Partial Upfront, or No Unfront RIs that were purchased directly from AWS or from EC2 RI Marketplace that received a discount from AWS (for example, [RI Volume Discount](https://web.archive.org/web/20240727055400/https://aws.amazon.com/ec2/pricing/reserved-instances/pricing/) or other discount programs) are not eligible for sale on the EC2 RI Marketplace."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I register as a seller for the RI Marketplace?"}, {"role": "assistant", "content": "To register for the RI Marketplace, you can enter the registration workflow by selling an RI from the [EC2 Management Console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/) or setting up your profile from the \"Account Settings\" page on the AWS portal. No matter the route, you will need to complete the following steps:Start by reviewing the overview of the registration process. Log in to your AWS Account.Enter in the bank account into which you want us to disburse funds. Once you select \"Continue,\" we will set that bank account as the default disbursement option.In the confirmation screen, choose \"Continue to Console to Start Listing.\"If you exceed $20,000 in sales of RI, or plan to sell 50 or more RIs, you will need to provide tax information before you can list your RIs. Choose \"Continue with Tax Interview.\" During the tax interview pipeline, you will be prompted to enter your company name, contact name, address, and Tax Identification Number using the TIMS workflow.Additionally, if you plan to sell RIs worth more than $50,000 per year you will also need to file a limit increase."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I know when I can start selling on the RI Marketplace?"}, {"role": "assistant", "content": "You can start selling on the RI Marketplace after you have added a bank account through the registration pipeline. Once activation is complete, you will receive a confirmation email. However, it is important to note that you will not be able to receive disbursements until we are able to receive verification from your bank, which may take up to two weeks, depending on the bank you use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I list an RI for sale?"}, {"role": "assistant", "content": "To list an RI, simply complete these steps in the Amazon EC2 console:Select the RIs that you wish to sell, and choose \"Sell Reserved Instances.\" If you have not completed the registration process, you will be prompted to register using the registration pipeline.For each RI type, set the number of instances you\u2019d like to sell, and the price for the one-time fee you would like to set. Note that you can set the one-time price to different amounts depending on the amount of time remaining so that you don\u2019t have to keep adjusting your one-time price if your RI doesn\u2019t sell quickly. By default you just need to set the current price and we will automatically decrease the one-time price by the same increment each month.Once you have configured your listing, a final confirmation screen will appear. Choose \"Sell Reserved Instance.\""}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which RIs can I list for sale?"}, {"role": "assistant", "content": "You can list any RIs that have been active for at least 30 days, and for which we have received payment. Typically, this means that you can list your reservations once they are in the active state. It is important to note that if you are an invoice customer, your RI can be in the active state prior to AWS receiving payment. In this case, your RI will not be listed until we have received your payment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are listed RIs displayed to buyers?"}, {"role": "assistant", "content": "RIs (both third-party and those offered by AWS) that have been listed on the RI Marketplace can be viewed in the \"Reserved Instances\" section of the Amazon EC2 console. You can also use the DescribeReservedInstancesListings API call.The listed RIs are grouped based on the type, term remaining, upfront price, and hourly price. This makes it easier for buyers to find the right RIs to purchase."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much of my RI term can I list?"}, {"role": "assistant", "content": "You can sell an RI for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term RI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I remove my RI after I\u2019ve listed it for sale?"}, {"role": "assistant", "content": "Yes, you can remove your RI listings at any point until a sale is pending (meaning a buyer has bought your RI and confirmation of payment is pending)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which pricing dimensions can I set for the RIs that I want to list?"}, {"role": "assistant", "content": "Using the RI Marketplace, you can set an upfront price you\u2019d be willing to accept. You cannot set the hourly price (which will remain the same as was set on the original RI), and you will not receive any funds collected from payments associated with the hourly prices."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I still use my reservation while it is listed on the RI Marketplace?"}, {"role": "assistant", "content": "Yes, you will continue to receive the capacity and billing benefit of your reservation until it is sold. Once sold, any running instance that was being charged at the discounted rate will be charged at the On-Demand rate until and unless you purchase a new reservation, or terminate the instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I resell an RI that I purchased from the RI Marketplace?"}, {"role": "assistant", "content": "Yes, you can resell RIs purchased from the RI Marketplace just like any other RI.Q. Are there any restrictions when selling RIs"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I sell RIs purchased from the public volume pricing tiers?"}, {"role": "assistant", "content": "No, this capability is not yet available."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there a charge for selling RIs in the RI Marketplace?"}, {"role": "assistant", "content": "Yes, AWS charges a service fee of 12% of the total upfront price of each RI that you sell in the RI Marketplace."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can AWS sell subsets of my listed RIs?"}, {"role": "assistant", "content": "Yes, AWS may potentially sell a subset of the quantity of RIs that you have listed. For example, if you list 100 RIs, we may only have a buyer interested in purchasing 50 of them. We will sell those 50 instances and continue to list your remaining 50 RIs until and unless you decide not to list them any longer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do buyers pay for RIs that they've purchased?"}, {"role": "assistant", "content": "Payment for completed RI sales are done via ACH wire transfers to a US bank account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When will I receive my money?"}, {"role": "assistant", "content": "Once AWS has received funds from the customer that has bought your reservation, we will disburse funds via wire transfer to the bank account you specified when you registered for the RI Marketplace.Then, we will send you an email notification letting you know that we\u2019ve wired you the funds. Typically, funds will appear in your account within 3-5 days of when your RI was sold."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I sell my RI in the RI Marketplace, will I get refunded for the Premium Support I was charged, too?"}, {"role": "assistant", "content": "No, you will not receive a prorated refund for the upfront portion of the AWS Premium Support Fee."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will I be notified about RI Marketplace activities?"}, {"role": "assistant", "content": "Yes, you will receive a single email once a day that details your RI Marketplace activity whenever you create or cancel RI listings, buyers purchase your listings, or AWS disburses funds to your bank account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What information is exchanged between the buyer and seller to help with the transaction tax calculation?"}, {"role": "assistant", "content": "The buyer\u2019s city, state, zip+4, and country information will be provided to the seller via a disbursement report. This information will enable sellers to calculate any necessary transaction taxes they need to remit to the government (e.g., sales tax, value-added tax, etc.). The legal entity name of the seller will also be provided on the purchase invoice."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are there any restrictions on the customers when purchasing third-party RIs?"}, {"role": "assistant", "content": "Yes, you cannot purchase your own listed RIs, including those in any of your linked accounts (via Consolidated Billing)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I have to pay for Premium Support when purchasing RIs from the RI Marketplace?"}, {"role": "assistant", "content": "Yes, if you are a Premium Support customer, you will be charged for Premium Support when you purchase an RI through the RI Marketplace."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Savings Plans?"}, {"role": "assistant", "content": "Savings Plans is a flexible pricing model that offers low prices on EC2, Lambda and Fargate usage, in exchange for a commitment to a consistent amount of usage (measured in $/hour) for a one- or three-year term. When you sign up for Savings Plans, you will be charged the discounted Savings Plans price for your usage up to your commitment. For example, if you commit to $10 of compute usage an hour, you will get the Savings Plans prices on that usage up to $10 and any usage beyond the commitment will be charged On Demand rates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What types of Savings Plans does AWS offer?"}, {"role": "assistant", "content": "AWS offers two types of Savings Plans:Compute Savings Plans provide the most flexibility and help to reduce your costs by up to 66%. These plans automatically apply to EC2 instance usage regardless of instance family, size, AZ, region, OS or tenancy, and also apply to AWS Fargate and Lambda usage. For example, with Compute Savings Plans, you can change from C4 to M5 instances, shift a workload from EU (Ireland) to EU (London), or move a workload from EC2 to Fargate or Lambda at any time and automatically continue to pay the Savings Plans price. EC2 Instance Savings Plans provides the lowest prices, offering savings up to 72% in exchange for commitment to usage of individual instance families in a Region (e.g., M5 usage in N. Virginia). This automatically reduces your cost on the selected instance family in that region regardless of AZ, size, OS or tenancy. EC2 Instance Savings Plans give you the flexibility to change your usage between instances within a family in that region. For example, you can move from c5.xlarge running Windows to c5.2xlarge running Linux and automatically benefit from the Savings Plan prices."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do Savings Plans compare to EC2 RIs?"}, {"role": "assistant", "content": "Savings Plans offers significant savings over On Demand, just like EC2 RIs, but automatically reduce your bills on compute usage across any AWS region, even as usage changes. This provides you the flexibility to use the compute option that best suits your needs and continue to save money, all without having to perform exchanges or modifications.Compute Savings Plans, which provide savings up to 66% (just like Convertible RIs), automatically reduce your cost on any EC2 instance usage regardless of region, instance family, size, OS, tenancy and even on AWS Fargate and Lambda. EC2 Instance Savings Plans, which provide savings up to 72% (just like Standard RIs), automatically save you money on any instance usage within a given EC2 instance family in a chosen region (e.g., M5 in N. Virginia) regardless of size, OS, or tenancy."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Savings Plans provide capacity reservations for EC2 instances?"}, {"role": "assistant", "content": "No, Savings Plans do not provide a capacity reservation. You can however reserve capacity with [On-Demand Capacity Reservations](#On-Demand_Capacity_Reservation) and pay lower prices on them with Savings Plans."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I get started with Savings Plans?"}, {"role": "assistant", "content": "You can get started with Savings Plans from AWS Cost Explorer in the AwS Management Console or by using the API/CLI. You can easily make a commitment to a Savings Plan by using the recommendations provided in [AWS Cost Explorer](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/cost-reports/home"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I continue to purchase EC2 RIs?"}, {"role": "assistant", "content": "Yes. You can continue purchasing RIs to maintain compatibility with your existing cost management processes, and your RIs will work alongside Savings Plans to reduce your overall bill. However as your RIs expire we encourage you to sign up for Savings Plans as they offer the same savings as RIs, but with additional flexibility."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I tell whether I have stopped my Spot Instance or it has been interrupted?"}, {"role": "assistant", "content": "You can tell that the Spot Instance has been stopped by you or interrupted by looking at the Spot Request Status code. This is visible as Spot Request Status on the Spot Requests page of the [AWS Management Console](https://web.archive.org/web/20240727055400/https://console.aws.amazon.com/ec2sp/#spot)\u00a0or in the [DescribeSpotInstanceRequests API](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-spot-instance-requests.html)\u00a0response as \u201cstatus-code\u201d field.  If the Spot request status code is \u201cinstance-stopped-by-user\u201d, it means that you have stopped your spot instance.Q. How will I be charged if my Spot instance is stopped or interrupted"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use stop or Hibernation interruption behaviors with Spot Fleet?"}, {"role": "assistant", "content": "Yes, stop-start and hibernate-resume are supported with Spot Fleet with \u201cmaintain\u201d fleet option enabled."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How isolated are Availability Zones from one another?"}, {"role": "assistant", "content": "Each Availability Zone runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. Common points of failures like generators and cooling equipment are not shared across Availability Zones. Additionally, they are physically separate, such that even extremely uncommon disasters such as fires, tornados or flooding would only affect a single Availability Zone."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is Amazon EC2 running in more than one AWS Region?"}, {"role": "assistant", "content": "Yes. Please refer to [Regional Products and Services](/web/20240727055400/https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/) for more details of our product and service availability by Region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I make sure that I am in the same Availability Zone as another developer?"}, {"role": "assistant", "content": "We do not currently support the ability to coordinate launches into the same Availability Zone across AWS developer accounts. One Availability Zone name (for example, us-east-1a) in two AWS customer accounts may relate to different physical Availability Zones."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: If I transfer data between Availability Zones using public IP addresses, will I be charged twice for Regional Data Transfer (once because it\u2019s across zones, and a second time because I\u2019m using public IP addresses)?"}, {"role": "assistant", "content": "No. Regional Data Transfer rates apply if at least one of the following is true, but you are only charged once for a given instance even if both are true:The other instance is in a different Availability Zone, regardless of which type of address is used.Public or Elastic IP addresses are used, regardless of which Availability Zone the other instance is in."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What CPU options are available on EC2 instances?"}, {"role": "assistant", "content": "EC2 instances offer a variety of CPU options to help customers balance performance and cost requirements.\u00a0 Depending on the instance type, EC2 offers a choice in CPU including AWS Graviton/Graviton2 processors (Arm), AMD processors (x86), and Intel processors (x86)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What kind of hardware will my application stack run on?"}, {"role": "assistant", "content": "Visit [Amazon EC2 Instance Type](/web/20240727055400/https://aws.amazon.com/ec2/instance-types/) for a list of EC2 instances available by region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does EC2 perform maintenance?"}, {"role": "assistant", "content": "AWS regularly performs routine hardware, software, power, and network maintenance with minimal disruption across all EC2 instance types. This is achieved by a combination of technologies and methods across the entire AWS Global infrastructure, such as live update and live migration as well as redundant and concurrently maintainable systems. Non-intrusive maintenance technologies such as live update and live migration do not require instances to be stopped or rebooted. Customers are not required to take any action prior to, during or after live migration or live update. These technologies help improve application uptime and reduce your operational effort. Amazon EC2 uses live update to deploy software to servers quickly with minimal impact to customer instances. Live update ensures that customers\u2019 workloads run on servers with software that is up-to-date with security patches, new instance features and performance improvements. Amazon EC2 uses live migration when running instances need to be moved from one server to another for hardware maintenance or to optimize placement of instances or to dynamically manage CPU resources. Amazon EC2 has been expanding the scope and coverage of non-intrusive maintenance technologies over the years so that scheduled maintenance events are a fallback option rather than the primary means of enabling routine maintenance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I select the right instance type?"}, {"role": "assistant", "content": "Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance or burstable performance; Compute Optimized instances have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerated Computing instances use hardware accelerators, or co-processors, to perform functions such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs; Storage Optimized Instances provide low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, as well as dense HDD-storage instances, which provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an \u201cEC2 Compute Unit\u201d and why did you introduce it?"}, {"role": "assistant", "content": "Transitioning to a utility computing model fundamentally changes how developers have been trained to think about CPU resources. Instead of purchasing or leasing a particular processor to use for several months or years, you are renting capacity by the hour. Because Amazon EC2 is built on commodity hardware, over time there may be several different types of physical hardware underlying EC2 instances. Our goal is to provide a consistent amount of CPU capacity no matter what the actual underlying hardware.Amazon EC2 uses a variety of measures to provide each instance with a consistent and predictable amount of CPU capacity. In order to make it easy for developers to compare CPU capacity between different instance types, we have defined an Amazon EC2 Compute Unit. The amount of CPU that is allocated to a particular instance is expressed in terms of these EC2 Compute Units. We use several benchmarks and tests to manage the consistency and predictability of the performance from an EC2 Compute Unit. The EC2 Compute Unit (ECU) provides the relative measure of the integer processing power of an Amazon EC2 instance. Over time, we may add or substitute measures that go into the definition of an EC2 Compute Unit, if we find metrics that will give you a clearer picture of compute capacity."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does EC2 ensure consistent performance of instance types over time?"}, {"role": "assistant", "content": "AWS conducts performance benchmarking at regular intervals of Linux and Windows compute performance on EC2 instance types to ensure consistent performance over time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the regional availability of Amazon EC2 instance types?"}, {"role": "assistant", "content": "For a list of all instances and regional availability, visit [Amazon EC2 Pricing](/web/20240727055400/https://aws.amazon.com/ec2/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Optimize CPUs?"}, {"role": "assistant", "content": "Optimize CPUs gives you greater control of your EC2 instances on two fronts. First, you can specify a custom number of vCPUs when launching new instances to save on vCPU-based licensing costs. Second, you can disable Intel Hyper-Threading Technology (Intel HT Technology) for workloads that perform well with single-threaded CPUs, such as certain HPC applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use Optimize CPUs feature?"}, {"role": "assistant", "content": "You should use Optimize CPUs if:You are running EC2 workloads that are not compute bound and are incurring vCPU-based licensing costs. By launching instances with a custom number of vCPUs you may be able to optimize your licensing spend.You are running workloads that will benefit from disabling hyper-threading on EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will the CPU optimized instances be priced?"}, {"role": "assistant", "content": "CPU optimized instances will be priced the same as equivalent full-sized instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will my application performance change when using Optimize CPUs on EC2?"}, {"role": "assistant", "content": "Your application performance change with Optimize CPUs will be largely dependent on the workloads you are running on EC2. We encourage you to benchmark your application performance with Optimize CPUs to arrive at the right number of vCPUs and optimal hyper-threading behavior for your application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Optimize CPUs on EC2 Bare Metal instance types (such as i3.metal)?"}, {"role": "assistant", "content": "No. You can use Optimize CPUs with only virtualized EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I get started with using Optimize CPUs for EC2 Instances?"}, {"role": "assistant", "content": "For more information on how to get started with Optimize CPUs and supported instance types, please visit the Optimize CPUs documentation page [here](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How am I billed for my use of Amazon EC2 running IBM?"}, {"role": "assistant", "content": "You pay only for what you use and there is no minimum fee. Pricing is per instance-hour consumed for each instance type. Partial instance-hours consumed are billed as full hours. Data transfer for Amazon EC2 running IBM is billed and tiered separately from Amazon EC2. There is no Data Transfer charge between two Amazon Web Services within the same Region (for example, between Amazon EC2 US West and another AWS service in the US West). Data transferred between AWS services in different regions will be charged as Internet Data Transfer on both sides of the transfer.For Amazon EC2 running IBM pricing information, please visit the pricing section on the [Amazon EC2 running IBM detail page](/web/20240727055400/https://aws.amazon.com/partners/find/partnerdetails/"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Amazon DevPay with Amazon EC2 running IBM?"}, {"role": "assistant", "content": "No, you cannot use DevPay to bundle products on top of Amazon EC2 running IBM at this time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use my existing Windows Server license with EC2?"}, {"role": "assistant", "content": "Yes you can. After you\u2019ve imported your own Windows Server machine images using the ImportImage tool, you can launch instances from these machine images on EC2 Dedicated Hosts and effectively manage instances and report usage. Microsoft typically requires that you track usage of your licenses against physical resources such as sockets and cores and Dedicated Hosts helps you to do this. Visit the Dedicated Hosts detail page for more information on how to use your own Windows Server licenses on Amazon EC2 Dedicated Hosts."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What software licenses can I bring to the Windows environment?"}, {"role": "assistant", "content": "Specific software license terms vary from vendor to vendor. Therefore, we recommend that you check the licensing terms of your software vendor to determine if your existing licenses are authorized for use in Amazon EC2."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EC2 Mac instances?"}, {"role": "assistant", "content": "Amazon EC2 Mac instances allow customers to run on-demand macOS workloads in the cloud for the first time, extending the flexibility, scalability, and cost benefits of AWS to all Apple developers. With EC2 Mac instances, developers creating apps for iPhone, iPad, Mac, Apple Watch, Apple TV, and Safari can provision and access macOS environments within minutes, dynamically scale capacity as needed, and benefit from AWS\u2019s pay-as-you-go pricing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What workloads should you run on EC2 Mac instances?"}, {"role": "assistant", "content": "Amazon EC2 Mac instances are designed to build, test, sign, and publish applications for Apple platforms such as iOS, iPadOS, watchOS, tvOS, macOS, and Safari. Customers such as Pinterest, Intuit, FlipBoard, Twitch, and Goldman Sachs have seen up to 75% better build performance, up to 80% lower build failure rates, and up to 5x the number of parallel builds compared to running macOS on premises."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 x86 Mac instances?"}, {"role": "assistant", "content": "x86-based EC2 Mac instances are built on Apple Mac mini computers featuring Intel Core i7 processors and are powered by the [AWS Nitro System](/web/20240727055400/https://aws.amazon.com/ec2/nitro/). They offer customers a choice of macOS Mojave (10.14), macOS Catalina (10.15), macOS Big Sur (11), and macOS Monterey (12) as Amazon Machine Images (AMIs). x86-based EC2 Instances are available in 12 Regions: US East (Ohio, N. Virginia), US West (Oregon), Europe (Stockholm, Frankfurt, Ireland, London), and Asia Pacific (Mumbai, Seoul, Singapore, Sydney, Tokyo). Learn more and get started with x86-based EC2 Mac instances [here](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 M1 Mac instances?"}, {"role": "assistant", "content": "EC2 M1 Mac instances are built on Apple M1 Mac mini computers and are powered by the [AWS Nitro System.](/web/20240727055400/https://aws.amazon.com/ec2/nitro/) They deliver up to 60 percent better price performance over x86-based EC2 Mac instances for iOS and macOS application build workloads. EC2 M1 Mac instances enable ARM64 macOS environments for the first time in AWS, and support macOS Big Sur (11) and macOS Monterey (12) as Amazon Machine Images (AMIs). EC2 M1 Mac instances are available in 4 Regions: US East (N. Virginia), US West (Oregon), Europe (Ireland), and Asia Pacific (Singapore). Learn more and get started with EC2 M1 Mac instances [here.](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 M1 Ultra Mac instances?"}, {"role": "assistant", "content": "EC2 M1 Ultra Mac instances are built on Apple M1 Ultra Mac Studio computers and are powered by the\u00a0[AWS Nitro System.](/web/20240727055400/https://aws.amazon.com/ec2/nitro/)\u00a0EC2 M1 Ultra Mac instances enable ARM64 macOS environments, and support macOS Ventura (13) or later as Amazon Machine Images (AMIs). EC2 M1 Ultra Mac instances are available in 2 Regions: US East (N. Virginia), US West (Oregon). Learn more and get started with EC2 M1 Ultra Mac instances\u00a0[here.](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 M2 Mac instances?"}, {"role": "assistant", "content": "EC2 M2 Mac instances are built on Apple M2 Mac mini computers and powered by the\u00a0[AWS Nitro System](https://web.archive.org/web/20240727055400/https://aws.amazon.com/ec2/nitro/). They are up to 10% more performant than EC2 M1 Mac instances for iOS and macOS application build workloads. EC2 M2 Mac instances enable ARM64 macOS environments on AWS and support macOS Ventura (version 13.2 and later) as Amazon Machine Images (AMIs).\u00a0EC2 M2 Mac instances are available in 5 Regions: US East (N. Virginia, Ohio), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Sydney). Learn more and get started with EC2 M2 Mac instances\u00a0[here](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are EC2 M2 Pro Mac instances?"}, {"role": "assistant", "content": "EC2 M2 Pro Mac instances are built on Apple M2 Pro Mac mini computers and powered by the AWS Nitro System. They are up to 35% more performant than EC2 M1 Mac instances for iOS and macOS application build workloads. EC2 M2 Pro Mac instances enable ARM64 macOS environments on AWS and support macOS Ventura (version 13.2 and later) as Amazon Machine Images (AMIs).\u00a0EC2 M2 Pro Mac instances are available in 4 Regions: US East (N. Virginia, Ohio), US West (Oregon), and Asia Pacific (Sydney). Learn more and get started with EC2 M2 Pro Mac instances\u00a0[here](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What pricing models are available for EC2 Mac instances?"}, {"role": "assistant", "content": "Amazon EC2 Mac instances are available as Dedicated Hosts through both On-Demand and Savings Plans pricing models. The Dedicated Host is the unit of billing for EC2 Mac instances. Billing is per second, with a 24-hour minimum allocation period for the Dedicated Host to comply with the Apple macOS Software License Agreement. At the end of the 24-hour minimum allocation period, the host can be released at any time with no further commitment. Both Compute and Instance Savings Plans are available for EC2 Mac instances and offer up to 44 percent off On-Demand pricing. Visit the [Dedicated Host pricing page](/web/20240727055400/https://aws.amazon.com/ec2/dedicated-hosts/pricing/) for more information. (Note: Please select \u201cDedicated Host\u201d tenancy and \u201cLinux\u201d operating system to view details.) You can also access EC2 Mac instances pricing on the [AWS Pricing Calculator for Dedicated Hosts.](https://web.archive.org/web/20240727055400/https://calculator.aws/#/)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do you release a Dedicated Host?"}, {"role": "assistant", "content": "The minimum allocation period for an EC2 Mac instance Dedicated Host is 24 hours. After the allocation period has exceeded 24 hours, first stop or terminate the instance running on the host, then release the host using the aws ec2 release-hosts CLI command or the AWS Management Console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you share EC2 Mac Dedicated Hosts with other AWS accounts in your organization?"}, {"role": "assistant", "content": "Yes. You can share EC2 Mac Dedicated Hosts with AWS accounts inside your AWS organization, an organizational unit inside your AWS organization, or your entire AWS organization via AWS Resource Access Manager. For more information, please refer to the [AWS Resource Access Manager](/web/20240727055400/https://aws.amazon.com/ram/) documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many EC2 Mac instances can you run on an EC2 Mac Dedicated Host?"}, {"role": "assistant", "content": "EC2 Mac instances leverage the full power of the underlying Mac mini hardware. You can run 1 EC2 Mac instance on each EC2 Mac Dedicated Host."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you update the EFI NVRAM variables on an EC2 Mac instance?"}, {"role": "assistant", "content": "Yes, you can update certain EFI NVRAM variables on an EC2 Mac instance that will persist across reboots. However, EFI NVRAM variables will be reset if the instance is stopped or terminated. Please see the [EC2 Mac instances documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-stop) for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you use FileVault to encrypt the Amazon Elastic Block Store (Amazon EBS) boot volume on EC2 Mac instances?"}, {"role": "assistant", "content": "FileVault requires a login before booting into macOS and before remote access can be enabled. If FileVault is enabled, you will lose access to your data on the boot volume at instance reboot, stop, or terminate. We strongly recommend you do not enable FileVault. Instead, we recommend using Amazon EBS encryption for both boot and data EBS volumes on EC2 Mac instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you access to the microphone input or audio output on an EC2 Mac instance?"}, {"role": "assistant", "content": "There is no access to the microphone input on an EC2 Mac instance. The built-in Apple Remote Desktop VNC server does not support audio output. Third party remote desktop software, such as [Teradici CAS](https://web.archive.org/web/20240727055400/https://aws.amazon.com/marketplace/pp/prodview-isaghmqny2wr6), supports remote audio on macOS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What macOS-based Amazon Machine Images (AMIs) are available for EC2 Mac instances?"}, {"role": "assistant", "content": "EC2 Mac instances use physical Mac mini hardware to run macOS. Apple hardware only supports the macOS version shipped with the hardware (or later). x86-based EC2 Mac instances use the 2018 Intel Core i7 Mac mini, which means macOS Mojave (10.14.x) is as 'far back' as you can go, since the 2018 Mac mini shipped with Mojave. EC2 M1 Mac instances use 2020 M1 Mac mini, which shipped with macOS Big Sur (11.x).\u00a0EC2 M2 and M2 Pro Mac instances use the 2023 M2 and M2 Pro Mac Minis respectively, which shipped with macOS Ventura (13.2). To see which latest versions of macOS are available as EC2 Mac AMIs, please visit the [documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can you run older versions of macOS on EC2 Mac instances?"}, {"role": "assistant", "content": "EC2 Mac instances are bare metal instances and do not use the Nitro hypervisor. You can install and run a type-2 virtualization layer on x86-based EC2 Mac instances to get access to macOS High Sierra, Sierra, or older macOS versions. On EC2 M1 Mac instances, as macOS Big Sur is the first macOS version to support Apple Silicon, older macOS versions will not run even under virtualization."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I run beta or preview versions of macOS on EC2 Mac instances?"}, {"role": "assistant", "content": "Installation of beta or preview macOS versions is only available on Apple Silicon-based EC2 Mac Instances . Amazon EC2 doesn't qualify beta or preview macOS versions and doesn't ensure instances will remain functional after an update to a pre-production macOS version."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can you use EC2 user data with EC2 Mac instances?"}, {"role": "assistant", "content": "As with EC2 Linux and Windows instances, you can pass custom user data to EC2 Mac instances. Instead of using [cloud-init](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html), EC2 Mac instances use an open-source launch daemon: [ec2-macos-init](https://web.archive.org/web/20240727055400/https://github.com/aws/ec2-macos-init). You can pass this data into the EC2 Launch Wizard as plain-text, as a file, or as base64-encoded-text."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do you install Xcode on an EC2 Mac instance?"}, {"role": "assistant", "content": "AWS provides base macOS AMIs without any prior Xcode IDE installation. You can install Xcode (and accept the EULA) just like you would on any other macOS system. You can install the latest Xcode IDE from the App Store, or earlier Xcode versions from the Apple Developer website. Once you have Xcode installed, we recommend creating a snapshot of your AMI for future use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the release cadence of macOS AMIs?"}, {"role": "assistant", "content": "We make new macOS AMIs available on a best effort basis. You can subscribe to SNS notifications for updates. We are targeting 30-60 days after a macOS minor version update and 90-120 days after a macOS major version update to release official macOS AMIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What agents and packages are included in EC2 macOS AMIs?"}, {"role": "assistant", "content": "The following agents and packages are included by default in EC2 macOS AMIs:ENA Driver for macOSAWS CLIEC2-macos-initAmazon CloudWatch AgentChronyHomebrewAWS Systems Manger Agent"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you update the agents and packages included in macOS AMIs?"}, {"role": "assistant", "content": "There is a [public GitHub repository of the Homebrew tap](https://web.archive.org/web/20240727055400/https://github.com/aws/homebrew-aws) for all agents and packages added to the base macOS image. You can use Homebrew to install the latest versions of agents and packages on macOS instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can you apply OS and software updates to your Mac instances directly from Apple Update Servers?"}, {"role": "assistant", "content": "Automatic macOS software updates are disabled on EC2 Mac instances. We recommend using our officially vended macOS AMIs to launch the version of macOS you need. On x86-based and all Apple Silicon EC2 Mac instances, you can update the version of macOS via the Software Update preferences pane, or via the software update CLI command. On both EC2 Mac instances, you can install and update applications and any other user-space software."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do you connect to an EC2 Mac instance over SSH?"}, {"role": "assistant", "content": "After launching your instance and receiving an instance id, you can use the following command to poll the instance and determine when it is ready for SSH access. Connecting over SSH to EC2 Mac instances follows the same process as connecting to other EC2 instances, such as those running Linux or Windows. To support connecting to your instance using SSH, launch the instance using a key pair and a security group that allows SSH access. Provide the .pem file for the key pair when you connect to the instance. For more information, please see the [documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-ssh)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do you connect to an EC2 Mac instance over VNC?"}, {"role": "assistant", "content": "macOS has built-in Screen Sharing functionality that is disabled by default, but can be enabled and used to connect to a Graphical (Desktop) session of your EC2 Mac instance. For more information on how to enable the built-in Screen Sharing, please see\u00a0the [documentation](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-vnc)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do you connect to an EC2 Mac instance using AWS Systems Manager Session Manager?"}, {"role": "assistant", "content": "You can connect to your EC2 Mac instances with AWS Systems Manager Session Manager (SSM). Session Manager is a fully managed [AWS Systems Manager](/web/20240727055400/https://aws.amazon.com/systems-manager/) feature that provides secure and auditable instance management. It removes the need to keep open inbound ports, maintain bastion hosts, or manage SSH keys. The SSM Agent is pre-installed by default on all EC2 macOS AMIs. For more information, please see [this blog](https://web.archive.org/web/20240727055400/https://aws.amazon.com/blogs/mt/manage-your-amazon-ec2-macos-instances-with-aws-systems-manager/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How many Amazon EBS volumes and Elastic Network Interfaces (ENIs) are supported by EC2 Mac instances?"}, {"role": "assistant", "content": "x86-based EC2 Mac instances support 16 EBS volumes and 8 ENI attachments, and EC2 M1 Mac instances support up to 10 EBS volumes and 8 ENI attachments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do EC2 Mac instances support EBS?"}, {"role": "assistant", "content": "EC2 Mac instances are EBS optimized by default and offer up to 8 Gbps of dedicated EBS bandwidth to both encrypted and unencrypted EBS volumes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do EC2 Mac instances support booting from local storage?"}, {"role": "assistant", "content": "EC2 Mac instances can only boot from EBS-backed macOS AMIs. The internal SSD of the Mac mini is present in Disk Utility, but is not bootable."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do EC2 Mac instances support Amazon FSx?"}, {"role": "assistant", "content": "Yes. EC2 Mac instances support FSx using the SMB protocol. You will need to enroll the EC2 Mac instance into a supported directory service (such as Active Directory or the AWS Directory Service) to enable FSx on EC2 Mac instances. For more information on FSx, visit the [product page](/web/20240727055400/https://aws.amazon.com/fsx/windows/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do EC2 Mac instances support Amazon Elastic File System (Amazon EFS)?"}, {"role": "assistant", "content": "Yes, EC2 Mac instances support EFS over the NFSv4 protocol. For more information on EFS, visit the [product page](/web/20240727055400/https://aws.amazon.com/efs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Nitro System support for Older Generation instances?"}, {"role": "assistant", "content": "The AWS Nitro System now will provide its modern hardware and software components for previous generation EC2 instances to extend the length of service beyond the typical lifetime of the underlying hardware. With the Nitro System support, customers can continue running their workloads and applications on the instance families they were built on."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which previous-generation instances will receive Nitro System support and within what time frame?"}, {"role": "assistant", "content": "We have enabled Nitro system support for Amazon EC2 C1, M1, M2, T1, T2, C3, M3, R3, C4, and M4 instances. Customers of these instances may receive a maintenance notification of\u00a0 migration to Nitro System. We will add support for additional instance types in 2024."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What actions do I need to take to migrate my existing previous generation instances?"}, {"role": "assistant", "content": "Customers do not need to take any action for migrating active previous generation instances running on older generation hardware. For instances that are on older generation hardware, each customer account ID mapped to instance(s) will receive an email notification 2 weeks prior to the scheduled maintenance.Similar to our typical maintenance events, customers will have the option to reschedule their maintenance as many times as needed within 2 additional weeks from the original scheduled maintenance time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What will happen if instance is stopped and started before or during the scheduled maintenance window?"}, {"role": "assistant", "content": "Stop/Start of an instance during the scheduled maintenance window will migrate the instance to a new host and the instance will not have to undergo the scheduled maintenance. The stop/start may result in migration of the customer instance to be supported by the AWS Nitro System. Please note that the data on any local instance-store volumes will not be preserved when you stop and start your instance. Click here for more information about [stop/start](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What will happen to my instance during this maintenance event?"}, {"role": "assistant", "content": "We will work in conjunction with the customer as a part of our [standard AWS maintenance process](https://web.archive.org/web/20240727055400/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instances-status-check_sched.html). Several AWS teams have already migrated and are running previous generation instances on Nitro hardware. During maintenance, the instance will be rebooted which can take up to 30 minutes depending upon the instance size and attributes. For example: Instances with local disk take longer to migrate than instances without local disk. After the reboot, your instance retains its IP address, DNS name, and any data on local instance-store volumes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to rebuild/recertify workloads to run on previous generation instances migrated to AWS Nitro System?"}, {"role": "assistant", "content": "No, customers don\u2019t need to rebuild/recertify workloads on previous generation instances migrated to AWS Nitro System."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will there be any changes to my instance specifications once migrated to AWS Nitro System?"}, {"role": "assistant", "content": "There will be no change to instance specification of previous generation instances when instances are migrated to AWS Nitro System."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will all features and AMIs on my previous generation instances be supported as a part of this migration?"}, {"role": "assistant", "content": "Yes, all existing features and AMIs supported on previous generation instances will be supported as we migrate these instances to AWS Nitro System."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will there be changes to pricing and billing when previous generation instances are migrated to AWS Nitro System?"}, {"role": "assistant", "content": "There will be no change to billing and pricing. We will continue to support the same pricing models we support today for the previous generation instances (On-Demand, 1yr/3yr Reserved Instance, Savings Plan, Spot)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is Amazon Elastic Container Service (ECS)?"}, {"role": "assistant", "content": "Amazon ECS\u00a0is a fully managed opinionated container orchestration service that delivers the easiest way for organizations to build, deploy, and manage containerized applications at any scale on AWS, in traditional\u00a0[Amazon Elastic Cloud Compute](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ec2/) (EC2)\u00a0instances or on a serverless compute plane with\u00a0[AWS Fargate](https://web.archive.org/web/20240727074557/https://aws.amazon.com/fargate/). Amazon ECS is fully managed and versionless, providing tooling and built-in support that makes it simple to build and run containerized applications on AWS. For example, Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability while\u00a0[Amazon CloudWatch Container Insights](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch-container-insights.html)\u00a0collects, aggregates, and summarizes metrics and logs. With Amazon ECS, you do not have to provision or scale servers or clusters or choose the types of severs you want your containers to run on or optimize cluster packing. You retain control of the operating properties of containers with the ability to specify CPU and memory requirements, networking and IAM policies, and launch type and data volumes. With simple API calls, you can launch and stop container-enabled applications, query the complete state of your cluster, and access many familiar features like security groups,\u00a0[Elastic Load Balancing](https://web.archive.org/web/20240727074557/https://aws.amazon.com/elasticloadbalancing/)\u00a0(ELB),\u00a0[Amazon Elastic Block Store](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ebs/)\u00a0(EBS) volumes, and Identity Access Management (IAM) roles. You can use Amazon ECS to schedule container placement across your cluster based on your resource needs and availability requirements."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use Amazon ECS?"}, {"role": "assistant", "content": "Amazon ECS is a fully managed container orchestration service makes it easy to use containers to deploy and manage long-running applications, services, and batch processes without needing to install, operate, and scale your own cluster management infrastructure. Amazon ECS maintains application availability and allows you to scale your containers up or down to meet your application's capacity requirements. When used with AWS Fargate, Amazon ECS allows you to deploy applications without needing to provision, manage, or scale compute infrastructure, reducing the time it takes for you to build, deploy, or migrate your containerized applications successfully. Furthermore, Amazon ECS is integrated with familiar features like ELB, [Amazon Virtual Private Cloud ](https://web.archive.org/web/20240727074557/https://aws.amazon.com/vpc/)(VPC), IAM, Application AutoScaling, [Amazon CloudWatch](https://web.archive.org/web/20240727074557/https://aws.amazon.com/cloudwatch/), and [Amazon Elastic File System](https://web.archive.org/web/20240727074557/https://aws.amazon.com/efs/) (EFS), meaning that you don\u2019t need to build or maintain generalized abstractions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What role does Amazon ECS play within AWS?"}, {"role": "assistant", "content": "Amazon ECS\u00a0is a fully managed opinionated container orchestration service that delivers\u00a0the easiest way for organizations to build, deploy, and manage containerized applications at any scale. Amazon ECS is fully managed and versionless, providing tooling and built-in support that makes it simple to build and run containerized applications on AWS. For example, with Amazon ECS, you do not need to provision or scale servers or clusters or choose the types of severs you want your containers to run on or optimize cluster packing. You retain control of the operating properties of containers with the ability to specify CPU and memory requirements, networking and IAM policies, compute platform (AWS Fargate or Amazon EC2), and data volumes.\u00a0With AWS Fargate, Amazon ECS supports serverless container orchestration so you can leverage more of AWS\u2019s operational excellence when it comes to scaling, maintaining availability, and securing your containerized workloads. If you want to modernize your container-based applications with little to no re-factoring, but still enjoy the many advantages of scale, agility, and cost that serverless compute provides, Amazon ECS with AWS Fargate is an ideal compute choice.Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability while Amazon ECS CloudWatch Container Insights collects, aggregates, and summarizes metrics and logs. When you desire more control over the characteristics of how your applications run, Amazon ECS on Amazon EC2 is available, as well as Amazon ECS Anywhere, for when you want to run container workloads on your infrastructure. Collectively, Amazon ECS on AWS Fargate, Amazon ECS on Amazon EC2, and Amazon ECS Anywhere give you the ability to run a wide variety of applications all with the same experience and tooling. Given this, over 65% of all new AWS container customers use Amazon ECS.With AWS you have a comprehensive choice of serverless compute options including Amazon ECS with AWS Fargate and\u00a0[AWS Lambda](https://web.archive.org/web/20240727074557/https://aws.amazon.com/lambda/), a serverless compute service that runs your code in response to events with\u00a0[Event-Driven Architecture](https://web.archive.org/web/20240727074557/https://aws.amazon.com/event-driven-architecture/) (EDA)\u00a0and automatically manages the underlying compute resources for you. You can use one or more of these compute choices depending on your use case. Whether it\u2019s Amazon ECS with AWS Fargate or AWS Lambda, AWS serverless choices deliver the advantages of scale, agility, and cost that serverless compute provides."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the pricing for Amazon ECS?"}, {"role": "assistant", "content": "There is no additional charge for Amazon ECS. You pay for AWS resources (for example, Amazon EC2 instances, AWS Fargate resources or Amazon EBS volumes) you create to store and run your application. You only pay for what you use, as you use it; there are no minimum fees and no upfront commitments. There are two different charge models for Amazon ECS. Amazon ECS on AWS Outposts follows the same model as Amazon EC2 Launch Type.\u00a0Amazon EC2 Launch Type Model:\u00a0There is no additional charge for Amazon EC2 launch type. You pay for AWS resources (such as Amazon EC2 instances or Amazon EBS volumes) you create to store and run your application. You only pay for what you use, as you use it; there are no minimum fees and no upfront commitments. See detailed pricing information on the\u00a0[Amazon EC2 pricing page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ec2/pricing/).AWS Fargate Launch Type Model:\u00a0With AWS Fargate, you pay for the amount of vCPU and memory resources that your containerized application requests. vCPU and memory resources are calculated from the time your container images are pulled until the Amazon ECS Task terminates, rounded up to the nearest second. A minimum charge of one minute applies. See detailed pricing information on the\u00a0[AWS Fargate pricing page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/fargate/pricing/?nc=sn&loc=2)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How is Amazon ECS different from AWS Lambda?"}, {"role": "assistant", "content": "Amazon ECS is a highly scalable container orchestration service that allows you to run and manage distributed applications that run in containers. AWS Lambda is an event-driven task compute service that runs your code in response to \u201cevents\u201d such as changes in data, website clicks, or messages from other AWS services without you having to manage any compute infrastructure.\u00a0Many applications use both of these constructs in production, and customers often use both to take advantage of their respective benefits."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I get started using Amazon ECS?"}, {"role": "assistant", "content": "Visit our\u00a0[Getting Started page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ecs/getting-started/)\u00a0for more information on how to start using Amazon ECS.\u00a0Whether you are new to Amazon ECS or you already have a use case in mind, you can choose your own path and follow the curated learning steps to get started."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is an Amazon ECS task?"}, {"role": "assistant", "content": "Modern application (say Microservices) architecture recommends to split your applications into the individual units, and Amazon ECS is optimized for this pattern.\u00a0Tasks\u00a0are the smallest unit of compute in Amazon ECS and\u00a0allow you to define a set of containers you would like to place together, their properties, and how they may be linked. Tasks include all the information Amazon ECS needs to make the placement decision. To launch a single container, your task definition should only include one container definition."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I run applications and services on Amazon ECS?"}, {"role": "assistant", "content": "Yes. The Amazon ECS service scheduler can manage long-running applications and services. The service scheduler helps you maintain application availability and allows you to scale your containers up or down to meet your application's capacity requirements. The service scheduler allows you to distribute traffic across your containers using ELB. Amazon ECS will automatically register and deregister your containers from the associated load balancer. The service scheduler will also automatically recover containers that become unhealthy (i.e., fail ELB health checks) or stop running to ensure you have the desired number of healthy containers supporting your application.You can scale your application up and down by changing the number of containers you want the service to run. You can update your application by changing its definition or using a new image. The scheduler will automatically start new containers using the new definition and stop containers running the previous version (waiting for the ELB connections to drain if ELB is used)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Amazon ECS support autoscaling of applications?"}, {"role": "assistant", "content": "Applications and microservices deployed to Amazon ECS leverage the\u00a0[Application Auto Scaling](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)\u00a0service to automatically scale based on observed metrics data. Amazon ECS\u00a0[measures service utilization](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch-metrics.html#service_utilization)\u00a0based on CPU and memory resources consumed by the tasks that belong to a service and publishes CloudWatch metrics, namely, ECSServiceAverageCPUUtilization and ECSServiceAverageMemoryUtilization, with this data. Application Auto Scaling can then use these\u00a0[predefined metrics\u00a0](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/autoscaling/application/APIReference/API_PredefinedMetricSpecification.html)in conjunction with scaling policies to proportionally scale the number of tasks in a service. Additionally, there are use cases where a service\u2019s average CPU and memory usage alone are not reliable indicators of when and to what degree to execute a scaling action. For this, Application Auto Scaling also supports scaling a service based on a\u00a0[custom metric specification](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/autoscaling/application/APIReference/API_CustomizedMetricSpecification.html)\u00a0that represents a CloudWatch metric of our choosing, which may be better suited. This includes metrics that track other application aspects such as number of HTTP requests received, number of messages retrieved from a queue/topic, and number of database transactions. You can now use CloudWatch metrics or\u00a0[Prometheus metrics](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus.html)\u00a0of your choosing.To learn more, please visit:\u00a0[Autoscaling Amazon ECS services based on custom CloudWatch and Prometheus metrics](https://web.archive.org/web/20240727074557/https://aws.amazon.com/blogs/containers/autoscaling-amazon-ecs-services-based-on-custom-cloudwatch-and-prometheus-metrics/)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What compute options are available with Amazon ECS?"}, {"role": "assistant", "content": "Amazon ECS enables you to run a wide variety of applications with the same experience and tooling across a diverse set of compute options:[AWS Fargate](https://web.archive.org/web/20240727074557/https://aws.amazon.com/fargate/): AWS Fargate is a serverless, pay-as-you-go compute engine. It removes the burden of server provisioning, cluster management, and orchestration. Amazon ECS uses containers provisioned by AWS Fargate to automatically scale, load balance, and manage scheduling of your containers for availability, providing an easier way to build and operate containerized applications.[Amazon EC2](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ec2/): With Amazon on ECS on EC2, you own the EC2 instances and have complete control over all aspects of infrastructure management. For instance, you can select specific EC2 instance types or customize the underlying operating system. You can use Auto Scaling Group Capacity Providers to manage the scaling of EC2 instances.On-premises virtual machines (VM) or servers:                  Amazon ECS Anywhere provides support for registering an external instance such as an on-premises server or virtual machine (VM), to your Amazon ECS cluster.\u00a0The capacity can be located in any of the following AWS resources:\u00a0\u00a0\u00a0\u00a0                    Availability ZonesLocal ZonesWavelength ZonesAWS RegionsAWS Outposts"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Amazon ECS support the autoscaling of compute infrastructure?"}, {"role": "assistant", "content": "Yes. Amazon ECS supports autoscaling compute infrastructure for both AWS Fargate and Amazon EC2, so that you can focus on building and scaling your applications rather than the underlying infrastructure.Amazon ECS with AWS Fargate provides you a serverless experience, as AWS Fargate automatically provisions, scales, and updates the compute infrastructure needed for your applications.For your applications that require Amazon EC2 capacity, Amazon ECS provides\u00a0Auto Scaling Group Capacity Providers\u00a0which automatically scale Amazon EC2 instances in response to the capacity requirement of your applications. You can create an Amazon EC2 Auto Scaling Group (ASG) with your desired configuration for Amazon EC2 instance types, Amazon Machine Image (AMI), network settings, etc. and create a Capacity Provider to automatically scale Amazon EC2 instances in that ASG based on the scheduling needs and load for your applications. manages the scale-in and scale-out actions of the ASG based on the load your tasks."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are Amazon ECS Capacity Providers?"}, {"role": "assistant", "content": "Amazon ECS\u00a0[capacity providers](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-capacity-providers.html)\u00a0are the interface through which you can define the capacity needs for your applications. Capacity providers allow you to define flexible rules for how your applications run on different types of compute capacity, and manage the scaling of the capacity. Capacity Providers work with both Amazon EC2 and AWS Fargate. Amazon ECS provides predefined capacity providers for\u00a0[AWS Fargate and Fargate-Spot](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-capacity-providers.html)\u00a0capacities for every cluster. For Amazon EC2, you can create your own\u00a0[ASG capacity providers](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/asg-capacity-providers.html)\u00a0to manage scaling of an Amazon EC2 Auto Scaling Group. When running Amazon ECS tasks and services, you can split them across multiple capacity providers, for instance to run a service in a predefined split percentage across AWS Fargate and Fargate Spot capacities."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Amazon ECS support batch jobs?"}, {"role": "assistant", "content": "Yes. You can use Amazon ECS Run task to run one or more tasks once. Run task starts the task on an instance that meets the task\u2019s requirements including CPU, memory, and ports.\u00a0You can also use\u00a0[AWS Batch](https://web.archive.org/web/20240727074557/https://aws.amazon.com/batch/)\u00a0to plan, schedule, and execute your batch computing workloads using on Amazon ECS, so you can focus on analyzing results and solving problems."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use my own Amazon Machine Image (AMI)?"}, {"role": "assistant", "content": "Yes. You can use any AMI that meets the Amazon ECS AMI specification. We recommend starting from the Amazon ECS-enabled Amazon Linux AMI. Partner AMIs compatible with Amazon ECS are also available. You can review the Amazon ECS AMI specification in the\u00a0[documentation](https://web.archive.org/web/20240727074557/https://aws.amazon.com/documentation/ecs/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I configure my container instances to pull from Amazon Elastic Container Registry (ECR)?"}, {"role": "assistant", "content": "Amazon ECR is integrated with Amazon ECS allowing you to easily store, run, and manage container images for applications running on Amazon ECS. All you need to do is specify the Amazon ECR repository in your task Definition and attach the\u00a0[AmazonEC2ContainerServiceforEC2Role](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html)\u00a0to your instances. Then Amazon ECS will retrieve the appropriate images for your applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "When should I use Amazon ECS with AWS Fargate?"}, {"role": "assistant", "content": "[AWS Fargate](https://web.archive.org/web/20240727074557/https://aws.amazon.com/fargate/)\u00a0offers serverless compute to run containers with Amazon ECS. AWS Fargate allows customers to launch their containers without having to provision or manage Amazon EC2 instances. AWS Fargate is the easiest way to launch and run containers on AWS. Customers requiring greater control of their EC2 instances (to support compliance and governance requirements or broader customization options) can choose to use Amazon ECS with Amazon EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What networking options does Amazon ECS support?"}, {"role": "assistant", "content": "Amazon ECS supports Docker networking and integrates with Amazon VPC to provide isolation for containers. This gives you control over how containers connect with other services and external traffic. With Amazon ECS, you can choose between four networking modes for your containers that cater towards different use cases:VPC Mode: This mode assigns each running Amazon ECS task a dedicated elastic networking interface, allowing containers full networking features in a VPC, just like Amazon EC2 instances.Bridge Mode: This mode creates a Linux bridge that connects all containers running on the host in a local virtual network, which can be accessed through the host's default network connection.Host Mode: This mode adds containers directly to the host\u2019s network stack, exposing containers on the host's network with no isolation.None: This mode disables external networking for containers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Amazon ECS support service-to-service communication?"}, {"role": "assistant", "content": "Service Connect:\u00a0Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability for Amazon ECS. It helps you build applications faster by letting you focus on the application code and not on your networking infrastructure. You can use Amazon ECS Service Connect to define logical names for your service endpoints and use them in your client applications to connect to dependencies. Amazon ECS Service Connect helps send your traffic to healthy endpoints and provides rich traffic telemetry in the Amazon ECS console and in Amazon CloudWatch. Native Amazon ECS deployments are more robust with Amazon ECS Service Connect, as it supports automatic connection draining that helps your client applications switch to a new version of the service endpoint without encountering traffic errors. With Amazon ECS Service Connect, you can:                  Set the way client applications connect to their dependencies in just one stepWrite and operate resilient distributed applications with logical namingMonitor and distribute traffic between Amazon ECS tasks without deploying and configuring load balancersDeploy services faster and deliver seamless integration of Amazon ECS microservices comprising an application Service Discovery:\u00a0Amazon ECS is integrated with\u00a0[AWS Cloud Map](https://web.archive.org/web/20240727074557/https://aws.amazon.com/cloud-map/)\u00a0to make it easy for your containerized services to discover and connect with each other. AWS Cloud Map is a cloud resource discovery service that lets you define custom names for your application resources. It increases your application availability because your web service will always discover the most up-to-date locations of these dynamically changing resources."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Amazon ECS provide observability for applications?"}, {"role": "assistant", "content": "MonitoringYou can monitor your Amazon ECS resources using Amazon CloudWatch, which collects and processes raw data from Amazon ECS into readable, near real-time metrics. These statistics are recorded for a period of two weeks so that you can access historical information and gain a better perspective on how your clusters or services are performing. There is no additional charge for this. To learn more, please visit,\u00a0[Amazon ECS CloudWatch metrics](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch-metrics.html).For enhanced metrics, use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices, available for your Amazon ECS clusters running on Amazon EC2 and AWS Fargate. CloudWatch automatically collects metrics for many resources, such as CPU, memory, disk, and network. Container Insights also provides diagnostic information, such as container restart failures, to help you isolate issues and resolve them quickly. For Amazon ECS, Container Insights collects metrics at the cluster, task and service levels on both Linux and Windows Server instances. It can collect metrics at the instance-level only on Linux instances.Network metrics are available only for containers in\u00a0bridge\u00a0network mode and\u00a0awsvpc\u00a0network mode. They are not available for containers in\u00a0host\u00a0network mode. To learn more, please visit,\u00a0[Using Container Insights](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html). LoggingAmazon ECS allows you to record all your Amazon ECS API calls and have the log files delivered to you through\u00a0[AWS CloudTrail](https://web.archive.org/web/20240727074557/https://aws.amazon.com/cloudtrail/). The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by Amazon ECS. CloudTrail provides you a history of API calls made from the AWS Management Console, AWS SDKs, and AWS CLI. It enables security analysis, resource change tracking, and compliance auditing. AWS Config[AWS Config](https://web.archive.org/web/20240727074557/https://aws.amazon.com/config/)\u00a0integrates with Amazon ECS to provide you visibility into your configuration of AWS resources in your AWS account. AWS Config allows users to monitor and track how resources were configured, how they relate to one another, and how the configurations and relationships change over time. AWS Config enables you to simplify compliance and security, operational troubleshooting, and resource administration. Third PartyAmazon ECS supports an entire ecosystem of third-party observability vendors by embracing open container standards. For more information view the\u00a0[Amazon ECS Partners page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ecs/partners/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What storage options are available with Amazon ECS?"}, {"role": "assistant", "content": "Amazon ECS offers the following storage options:Amazon Elastic File System (EFS): Amazon EFS provides serverless, fully elastic, scalable file storage for use with your Amazon ECS tasks. You can mount a shared Amazon EFS file system to your ECS tasks for persistent storage.Amazon Elastic Block Store (EBS): Amazon EBS provides scalable, high-performance storage for your Amazon ECS tasks. You can configure ECS to provision and attach EBS volumes with desired characteristics (size, performance, encryption, etc) to your Amazon ECS tasks."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I monitor cost information for my Amazon ECS tasks running on AWS Fargate?"}, {"role": "assistant", "content": "Costs for Amazon ECS tasks running on AWS Fargate are available in AWS Cost and Usage Reports (CUR) and AWS Cost Explorer automatically. You can use managed as well as user-added tags to aggregate and allocate costs to new and existing business units, teams, or applications for your Amazon ECS tasks.[Learn more about Amazon ECS usage reports](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/usage-reports.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I monitor cost information for my Amazon ECS tasks running on Amazon EC2 instances?"}, {"role": "assistant", "content": "You can access cost and usage information for Amazon ECS tasks running on Amazon EC2 instances in AWS Cost and Usage Reports (CUR) by opting into Split Cost Allocation Data for Amazon ECS. Split Cost Allocation Data generates task-level costs for Amazon ECS tasks running on Amazon EC2 instances by analyzing each task\u2019s resource consumption based on the price of the instance, and the percentage of CPU and memory resources consumed by the containers running on the instance. Split Cost Allocation Data automatically ingests managed and user-added tags for your Amazon ECS tasks, allowing you to aggregate and allocate costs to new and existing business units, teams, or applications. You can opt into Split Cost Allocation Data for Amazon ECS from the AWS Cost Management console preferences. Then you can opt into Split Cost Allocation Data for your individual CUR reports from the CUR reporting preferences in AWS Billing console.\u00a0  [Learn more about enabling split cost allocation data.](https://web.archive.org/web/20240727074557/https://docs.aws.amazon.com/cur/latest/userguide/enabling-split-cost-allocation-data.html)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Amazon ECS isolate containers belonging to different customers?"}, {"role": "assistant", "content": "Amazon ECS schedules containers for execution on customer-controlled Amazon EC2 instances or with AWS Fargate and builds on the same isolation controls and compliance settings available for Amazon EC2 customers. Your compute instances are located in a Virtual Private Cloud (VPC) with an IP range that you specify. You decide which instances are exposed to the Internet and which remain private.Your Amazon EC2 instances use an IAM role to access the Amazon ECS service.Your Amazon ECS tasks use an IAM role to access services and resources.Your Amazon ECS tasks running on AWS Fargate run in isolated virtual machines.Security Groups and networks ACLs allow you to control inbound and outbound network access to and from your instances.You can connect your existing IT infrastructure to resources in your VPC using industry-standard encrypted IPsec VPN connections.You can provision your Amazon EC2 resources as Dedicated Instances. Dedicated Instances are Amazon EC2 Instances that run on hardware dedicated to a single customer for additional isolation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I apply additional security configuration and isolation frameworks to my container instances?"}, {"role": "assistant", "content": "Yes. As an Amazon EC2 customer, you have root access to the operating system (OS) of your container instances. You can take ownership of the OS security settings, as well as configure additional software components for security capabilities such as monitoring, patch management, log management, and host intrusion detection.\u00a0Using Amazon ECS with AWS Fargate drives high levels of security with the ability to assign granular permissions to each task, giving you a higher degree isolation, network access control, and IAM control when building applications. With AWS Fargate, every task runs in a separate virtual machine (VM), providing more isolation than two tasks sharing the same host. Each task also has its own network interface allowing the security group to be applied to each task, with control over the incoming and outgoing traffic."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Amazon ECS support retrieving container images from a private or internal source?"}, {"role": "assistant", "content": "Yes. Customers can configure their container instances to access a private container image registry within a VPC or a registry that\u2019s accessible outside a VPC such as\u00a0[Amazon ECR](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ecr/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I configure IAM roles for Amazon ECS tasks?"}, {"role": "assistant", "content": "You first need to create an IAM role for your task, using the 'Amazon EC2 Container Service Task Role\u2019 service role and attaching a policy with the required permissions. When you create a new task definition or a task definition revision, you can then specify a role by selecting it from the \u2019Task Role\u2019 drop-down or using the \u2018taskRoleArn\u2019 filed in the JSON format."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "With which compliance programs does Amazon ECS conform?"}, {"role": "assistant", "content": "Amazon ECS meets the standards for PCI DSS Level 1, ISO 9001, ISO 27001, ISO 27017, ISO 27018, SOC 1, SOC 2, SOC 3, and HIPAA eligibility.  For more information, visit our\u00a0[compliance pages](https://web.archive.org/web/20240727074557/https://aws.amazon.com/compliance/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use Amazon ECS for Protected Health Information (PHI) and other HIPAA-regulated workloads?"}, {"role": "assistant", "content": "Yes. Amazon ECS is HIPAA-eligible. If you have an executed\u00a0[Business Associate Addendum (BAA)](https://web.archive.org/web/20240727074557/https://aws.amazon.com/compliance/hipaa-compliance/)\u00a0with AWS, you can use Amazon ECS to process encrypted Protected Health Information (PHI) using containers deployed onto the\u00a0[AWS Fargate](https://web.archive.org/web/20240727074557/https://aws.amazon.com/fargate/)\u00a0launch-type or Amazon EC2 compute instances. For more information, please visit our page on\u00a0[HIPAA compliance](https://web.archive.org/web/20240727074557/https://aws.amazon.com/compliance/hipaa-compliance/). If you plan to process, store, or transmit PHI and do not have an executed BAA from AWS, please\u00a0[contact us](https://web.archive.org/web/20240727074557/https://aws.amazon.com/contact-us/)\u00a0for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use Amazon ECS for US Government-regulated workloads or processing sensitive Controlled Unclassified Information (CUI)?"}, {"role": "assistant", "content": "Yes. By using the AWS GovCloud (US) region, containers and clusters managed by Amazon ECS can meet the requirements to sensitive data and regulated workloads with your containers. For more information, visit our page on\u00a0[AWS GovCloud](https://web.archive.org/web/20240727074557/https://aws.amazon.com/govcloud-us/).Customers can also deploy their workloads on Amazon ECS using AWS Fargate in a manner compliant with Federal Information Processing Standard (FIPS) 140-2. FIPS is a U.S. and Canadian government standard that specifies the security requirements for cryptographic modules that protect sensitive information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What other security assurances does AWS offer for my Amazon ECS workloads?"}, {"role": "assistant", "content": "Amazon ECS is architected to be secure by design, and also integrates with AWS native security services for security, identity, and compliance. For example, you can use [Amazon GuardDuty](https://web.archive.org/web/20240727074557/https://aws.amazon.com/guardduty) to monitor your Amazon ECS workloads running on AWS Fargate or Amazon EC2 to detect potentially malicious or suspicious behavior."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does the Amazon ECS SLA guarantee?"}, {"role": "assistant", "content": "Our Compute\u00a0SLA guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon ECS.\u00a0AWS makes two SLA commitments for Amazon ECS and AWS Fargate: (1) a Multi-AZ Included Container Service SLA that governs Included Container Services deployed across multiple AZs; and (2) a Single Task/Pod SLA that governs Included Container Service tasks and pods individually. Please see the\u00a0[AWS Fargate and Amazon Elastic Container Service SLA\u00a0page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/ecs/sla/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I know if I qualify for a SLA Service Credit?"}, {"role": "assistant", "content": "You are eligible for an SLA credit for Amazon ECS under the Compute SLA if more than one Availability Zone in which you are running a task, within the same region has a Monthly Uptime Percentage of less than 99.99% during any monthly billing cycle.For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, please see the\u00a0[Compute SLA details page](https://web.archive.org/web/20240727074557/https://aws.amazon.com/compute/sla/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon Elastic Container Registry (Amazon ECR)?"}, {"role": "assistant", "content": "Amazon ECR is a fully managed container registry that makes it easy for developers to share and deploy container images and artifacts. Amazon ECR is integrated with          [Amazon Elastic Container Service (Amazon ECS)](/web/20240727090456/https://aws.amazon.com/ecs/),\u00a0          [Amazon Elastic Kubernetes Service (Amazon EKS)](/web/20240727090456/https://aws.amazon.com/eks/),\u00a0and          [AWS Lambda](/web/20240727090456/https://aws.amazon.com/lambda/), simplifying your development to production workflow. Amazon ECR eliminates the need to operate your own container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts your images in a highly available and scalable architecture, allowing you to deploy containers for your applications reliably. Integration with AWS Identity and Access Management (IAM) provides resource-level control of each repository that lets you share images across your organization or with anyone in the world."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use Amazon ECR?"}, {"role": "assistant", "content": "Amazon ECR eliminates the need to operate and scale the infrastructure required to power your container registry. Amazon ECR uses Amazon\u00a0Simple Storage Service (S3) for storage to make your container images highly available and accessible, allowing you to deploy new containers for your applications reliably. Amazon ECR transfers your container images over HTTPS and automatically encrypts your images at rest. You can configure policies to manage permissions for each repository and restrict access to IAM users, roles, or other AWS accounts. Amazon ECR integrates with Amazon ECS, Amazon EKS, AWS Fargate, AWS Lambda, and the Docker CLI, allowing you to simplify your development and production workflows. You can easily push your container images to Amazon ECR using the Docker CLI from your development machine, and Amazon container orchestrators or compute can pull them directly for production deployments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the pricing for Amazon ECR?"}, {"role": "assistant", "content": "With Amazon ECR, there are no upfront fees or commitments.\u00a0You pay only for the amount of data you store in your public or private repositories, and data transferred to the internet. Please see our          [Pricing](/web/20240727090456/https://aws.amazon.com/ecr/pricing/) page for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is Amazon ECR a global service?"}, {"role": "assistant", "content": "Amazon ECR is a Regional service and is designed to give you flexibility in how images are deployed. You have the ability to push/pull images to the same AWS Region where your Docker cluster runs for the best performance. You can also access Amazon ECR anywhere that Docker runs, such as desktops and on-premises environments. Pulling images between Regions or out to the internet will have additional latency and data transfer costs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can Amazon ECR host public container images?"}, {"role": "assistant", "content": "Yes. Amazon ECR has a highly available container registry and website that makes it easy for you to share or search for public container software. Anyone with or without an AWS account can use the Amazon ECR          [public gallery](https://web.archive.org/web/20240727090456/https://gallery.ecr.aws/) to search for and download commonly used container images such as operating systems, AWS published images, and files, such as Helm charts, for Kubernetes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the difference between Amazon ECR public and private repositories?"}, {"role": "assistant", "content": "A private repository does not offer content search capabilities and requires Amazon IAM-based authentication using AWS account credentials before allowing images to be pulled. A public repository has descriptive content and allows anyone anywhere to pull images without needing an AWS account or using IAM credentials. Public repository images are also available in the Amazon ECR public gallery."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What compliance capabilities can I enable on Amazon ECR?"}, {"role": "assistant", "content": "You can use AWS CloudTrail on Amazon ECR to provide a history of all API actions such as who pulled an image and when tags were moved between images. Administrators can also find which EC2 instances pulled which images."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I get started using Amazon ECR?"}, {"role": "assistant", "content": "The best way to get started with Amazon ECR is to use the Docker CLI to push and pull your first image. Visit our [Getting Started](/web/20240727090456/https://aws.amazon.com/ecr/getting-started/) page for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I access Amazon ECR inside a VPC?"}, {"role": "assistant", "content": "Yes. You can set up [AWS PrivateLink endpoints](https://web.archive.org/web/20240727090456/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/vpc-endpoints.html) to allow your instances to pull images from your private repositories without traversing through the public internet."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What\u2019s the best way to manage my repositories and images?"}, {"role": "assistant", "content": "Amazon ECR provides a [command line interface and APIs](https://web.archive.org/web/20240727090456/http://aws.amazon.com/documentation/ecr/) to create, monitor, and delete repositories and set repository permissions. You can perform the same actions in the Amazon ECR console, which can be accessed via the \u201cRepositories\u201d section of the Amazon ECR console. Amazon ECR also integrates with the Docker CLI, allowing you to push, pull, and tag images on your development machine."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I publicly share an image using Amazon ECR?"}, {"role": "assistant", "content": "You publish an image to the Amazon ECR public gallery by signing into your AWS account and pushing to a public repository you create. You are assigned a unique alias per account to use in image URLs that identifies all public images that you publish."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use a custom alias for my public images?"}, {"role": "assistant", "content": "Yes. You can request a custom alias such as your organization or project name, unless it\u2019s a reserved alias. Names that identify AWS services are reserved. Names that identify AWS Marketplace sellers may also be reserved. We will review and approve your custom alias request within a few days unless your alias request violates the AWS Acceptable Use Policy or other AWS policies."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I pull a public image from Amazon ECR?"}, {"role": "assistant", "content": "You pull using the familiar \u2018docker pull\u2019 command with the URL of the image. You can easily search for this URL by finding images using a publisher alias, image name, or image description using the Amazon ECR public gallery. Image URLs are in the format public.ecr.aws/<alias>/<image>:<tag>, for example public.ecr.aws/eks/aws-alb-ingress-controller:v1.1.5"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR replicate images across AWS Regions?"}, {"role": "assistant", "content": "Yes. Amazon ECR is designed to give you flexibility in where you store and how you deploy your images. You can create deployment pipelines that build images, push them to Amazon ECR in one Region, and Amazon ECR can automatically replicate them to other Regions and accounts for deployment to multi-Region clusters."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Amazon ECR within local and on-premises environments?"}, {"role": "assistant", "content": "Yes. You can access Amazon ECR anywhere that Docker runs such as desktops and on-premises environments."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does the Amazon ECR public gallery provide AWS-published images?"}, {"role": "assistant", "content": "Yes. Services such as Amazon EKS, Amazon SageMaker and AWS Lambda publish their official public use container images and artifacts to Amazon ECR."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR work with Amazon ECS?"}, {"role": "assistant", "content": "Yes. Amazon ECR is integrated with Amazon ECS, allowing you to easily store, run, and manage container images for applications running on Amazon ECS. All you need to do is specify the Amazon ECR repository in your task definition and Amazon ECS will retrieve the appropriate images for your applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR work with AWS Elastic Beanstalk?"}, {"role": "assistant", "content": "Yes. AWS Elastic Beanstalk supports Amazon ECR for both [single and multi-container Docker environments](https://web.archive.org/web/20240727090456/http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.container.console.html), allowing you to easily deploy container images stored in Amazon ECR with AWS Elastic Beanstalk. All you need to do is specify the Amazon ECR repository in your Dockerrun.aws.json configuration and attach the AmazonEC2ContainerRegistryReadOnly policy to your container instance role."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What version of Docker Engine does Amazon ECR support?"}, {"role": "assistant", "content": "Amazon ECR currently supports Docker Engine 1.7.0 and up."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What version of the Docker Registry API does Amazon ECR support?"}, {"role": "assistant", "content": "Amazon ECR supports the Docker Registry V2 API specification."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will Amazon ECR automatically build images from a Dockerfile?"}, {"role": "assistant", "content": "No. However, Amazon ECR integrates with a number of popular CI/CD solutions to provide this capability. See the [Amazon ECR Partners page](/web/20240727090456/https://aws.amazon.com/what-are-containers/partners/) for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR support federated access?"}, {"role": "assistant", "content": "Yes. Amazon ECR is integrated with AWS Identity and Access Management (IAM), which supports [identity federation for delegated access](/web/20240727090456/https://aws.amazon.com/identity/federation/) to the AWS Management Console or AWS APIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What version of the Docker Image Manifest specification does Amazon ECR support?"}, {"role": "assistant", "content": "Amazon ECR supports the Docker Image Manifest V2, Schema 2 format. In order to maintain backwards compatibility with Schema 1 images, Amazon ECR will continue to accept images uploaded in the Schema 1 format. Additionally, Amazon ECR can down-translate from a Schema 2 to a Schema 1 image when pulling with an older version of Docker Engine (1.9 and below)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR support the Open Container Initiative (OCI) format?"}, {"role": "assistant", "content": "Yes. Amazon ECR is compatible with the Open Container Initiative (OCI) image specification, letting you push and pull OCI images and artifacts. Amazon ECR can also translate between Docker Image Manifest V2, Schema 2 images and OCI images on pull."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does Amazon ECR help ensure that container images are secure?"}, {"role": "assistant", "content": "Amazon ECR automatically encrypts images at rest using Amazon S3 server-side encryption or AWS KMS encryption and transfers your container images over HTTPS. You can configure policies to manage permissions and control access to your images using AWS Identity and Access Management (IAM) users and roles without having to manage credentials directly on your EC2 instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I use AWS Identity and Access Management (IAM) for permissions?"}, {"role": "assistant", "content": "You can use IAM resource-based policies to control and monitor who and what (e.g., EC2 instances) can access your container images, as well as how, when, and where they can access them. To get started, use the AWS Management Console to create resource-based policies for your repositories. Alternatively, you can use sample policies and attach them to your repositories via the Amazon ECR CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I share my images across AWS accounts?"}, {"role": "assistant", "content": "Yes. [Here is an example](https://web.archive.org/web/20240727090456/http://docs.aws.amazon.com/AmazonECR/latest/userguide/RepositoryPolicyExamples.html) of how to create and set a policy for cross-account image sharing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon ECR scan container images for vulnerabilities?"}, {"role": "assistant", "content": "You can enable Amazon ECR to automatically scan your container images for a broad range of operating system vulnerabilities. You can also scan images using an API command, and Amazon ECR will notify you over API and in the console when a scan completes. For enhanced image scanning, you can turn on [Amazon Inspector](/web/20240727090456/https://aws.amazon.com/inspector/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is\u00a0Amazon Elastic Kubernetes Service (Amazon EKS)?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS is a managed service that makes it easy for you to run Kubernetes on AWS without installing and operating your own Kubernetes control plane or worker nodes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Kubernetes?"}, {"role": "assistant", "content": "A:\u00a0Kubernetes is an open-source container orchestration system allowing you to deploy and manage containerized applications at scale. Kubernetes arranges containers into logical groupings for management and discoverability, then launches them onto clusters of Amazon Elastic Compute Cloud (Amazon EC2) instances. Using Kubernetes, you can run containerized applications including microservices, batch processing workers, and platforms as a service (PaaS) using the same toolset on premises and in the cloud."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use Amazon EKS?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS provisions and scales the Kubernetes control plane, including the application programming interface (API) servers and backend persistence layer, across multiple AWS Availability Zones (AZs) for high availability and fault tolerance. Amazon EKS automatically detects and replaces unhealthy control plane nodes and patches the control plane. You can run EKS using AWS Fargate, which provides serverless compute for containers. Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design.Amazon EKS is integrated with many AWS services to provide scalability and security for your applications. These services include Elastic Load Balancing for load distribution, AWS Identity and Access Management (IAM) for authentication, Amazon Virtual Private Cloud (VPC) for isolation, and AWS CloudTrail for logging."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does Amazon EKS work?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS works by provisioning (starting) and managing the Kubernetes control plane and worker nodes for you. At a high level, Kubernetes consists of two major components: a cluster of 'worker nodes' running your containers, and the control plane managing when and where containers are started on your cluster while monitoring their status.Without Amazon EKS, you have to run both the Kubernetes control plane and the cluster of worker nodes yourself. With Amazon EKS, you provision your worker nodes using a single command in the EKS console, command-line interface (CLI), or API. AWS handles provisioning, scaling, and managing the Kubernetes control plane in a highly available and secure configuration. This removes a significant operational burden and allows you to focus on building applications instead of managing AWS infrastructure."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which operating systems does Amazon EKS support?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS supports Kubernetes-compatible Linux x86, ARM, and Windows Server operating system distributions. Amazon EKS provides optimized AMIs for Amazon Linux 2, Bottlerocket, and Windows Server 2019. At this time, there is no Amazon EKS optimized AMI for AL2023. EKS- optimized AMIs for other Linux distributions, such as Ubuntu, are available from their respective vendors."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: I have a feature request, who do I tell?"}, {"role": "assistant", "content": "A: Please let us know what we can add or do better by opening a feature request on the [AWS Container Services Public Roadmap](https://web.archive.org/web/20240727090537/https://github.com/aws/containers-roadmap)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon EKS work with my existing Kubernetes applications and tools?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS runs the open-source Kubernetes software, so you can use all the existing plug-ins and tooling from the Kubernetes community. Applications running on Amazon EKS are fully compatible with applications running on any standard Kubernetes environment, whether running in on-premises data centers or public clouds. This means that you can easily migrate any standard Kubernetes application to Amazon EKS without any code modifications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does Amazon EKS work with AWS Fargate?"}, {"role": "assistant", "content": "A:\u00a0Yes. You can run Kubernetes applications as serverless containers using AWS Fargate and Amazon EKS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are Amazon EKS add-ons?"}, {"role": "assistant", "content": "A:\u00a0EKS Add-Ons let you enable and manage Kubernetes operational software, which provides capabilities like observability, scaling, networking, and AWS cloud resource integrations for your EKS clusters. At launch, EKS add-ons supports controlling the launch and version of the AWS VPC CNI plugin through the EKS API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use Amazon EKS add-ons?"}, {"role": "assistant", "content": "A: [Amazon EKS add-ons](https://web.archive.org/web/20240727090537/https://aws.amazon.com/blogs/containers/introducing-amazon-eks-add-ons/)\u00a0provides one-click installation and management of Kubernetes operational software. Go from cluster creation to running applications in a single command, while easily keeping the operational software required for your cluster up to date. This ensures your Kubernetes clusters are secure and stable and reduces the amount of work needed to start and manage production-ready Kubernetes clusters on AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which Kubernetes versions does Amazon EKS support?"}, {"role": "assistant", "content": "A: See the [Amazon EKS documentation](https://web.archive.org/web/20240727090537/https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html) for currently supported Kubernetes versions. Amazon EKS will continue to add support for additional Kubernetes versions in the future."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I update my Kubernetes cluster to a new version?"}, {"role": "assistant", "content": "A:\u00a0Yes. Amazon EKS performs managed, in-place cluster upgrades for both Kubernetes and Amazon EKS platform versions. This simplifies cluster operations and lets you take advantage of the latest Kubernetes features, as well as the updates to Amazon EKS configuration and security patches.There are two types of updates you can apply to your Amazon EKS cluster: Kubernetes version updates and Amazon EKS platform version updates. As new Kubernetes versions are released and validated for use with Amazon EKS, we will support three stable Kubernetes versions as part of the update process at any given time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an EKS platform version?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS platform versions represent the capabilities of the cluster control plane, such as which Kubernetes API server flags are enabled, as well as the current Kubernetes patch version. Each Kubernetes minor version has one or more associated Amazon EKS platform versions. The platform versions for different Kubernetes minor versions are independent.When a new Kubernetes minor version is available in Amazon EKS (for example, 1.13), the initial Amazon EKS platform version for that Kubernetes minor version starts at eks.1. However, Amazon EKS releases new platform versions periodically to enable new Kubernetes control plane settings and to provide security fixes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why would I want manual control over Kubernetes version updates?"}, {"role": "assistant", "content": "A:\u00a0New versions of Kubernetes introduce significant change to the Kubernetes API, which can change application behavior. Manual control over Kubernetes cluster versioning lets you test applications against new versions of Kubernetes before upgrading production clusters. Amazon EKS offers the ability to choose when you introduce changes to your EKS cluster."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I update my worker nodes?"}, {"role": "assistant", "content": "A: AWS publishes EKS-optimized Amazon Machine Images (AMIs) that include the necessary worker node binaries (Docker and Kubelet).\u00a0This AMI is updated regularly and includes the most up-to-date version of these components. You can update your EKS managed nodes to the latest versions of the EKS-optimized AMIs with a single command in the EKS console, API, or CLI.If you are building your own custom AMIs to use for EKS worker nodes, AWS also publishes [Packer scripts](https://web.archive.org/web/20240727090537/https://github.com/awslabs/amazon-eks-ami) that document our build steps, allowing you to identify the binaries included in each version of the AMI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EKS extended support?"}, {"role": "assistant", "content": "A:\u00a0Amazon EKS extended support for Kubernetes versions lets you use a Kubernetes minor version for up to 26 months from the time the version is generally available from Amazon EKS. Amazon EKS versions in extended support receive ongoing security patches for the Kubernetes control plane managed by Amazon EKS. Additionally, Amazon EKS will release critical patches for the Amazon VPC CNI, kube-proxy, and CoreDNS add-ons, AWS-published EKS Optimized Amazon Machine Images (AMIs) for Amazon Linux, Bottlerocket, Windows, and EKS Fargate nodes. AWS backs all Amazon EKS versions in both standard and extended support with full technical support. Extended support for Kubernetes versions is available in all AWS Regions where Amazon EKS is available, including AWS GovCloud (US) Regions. Learn more about the Amazon EKS version support policy in the [Amazon EKS documentation](https://web.archive.org/web/20240727090537/https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How much does Amazon EKS cost?"}, {"role": "assistant", "content": "A: You pay $0.10 per hour for each Amazon EKS cluster you create and for the AWS resources you create to run your Kubernetes worker nodes. You only pay for what you use, as you use it; there are no minimum fees and no upfront commitments. Find more information in the \u00a0[EKS pricing page](/web/20240727090537/https://aws.amazon.com/eks/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Where is Amazon EKS available?"}, {"role": "assistant", "content": "A: Please visit the [AWS global infrastructure region table](/web/20240727090537/https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/) for the most up-to-date information on Amazon EKS Regional availability."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EKS Service Level Agreement (SLA)?"}, {"role": "assistant", "content": "A: The Amazon EKS SLA can be found [here](https://web.archive.org/web/20240727090537/https://aws.amazon.com/eks/sla/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is AWS Fargate?"}, {"role": "assistant", "content": "AWS Fargate is a serverless compute engine for containers that works with both\u00a0[Amazon Elastic Container Service](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ecs/) (ECS) and [Amazon Elastic Kubernetes Service](https://web.archive.org/web/20240727090700/https://aws.amazon.com/eks/) (EKS). AWS Fargate makes it easy to focus on building your applications by eliminating the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use AWS Fargate?"}, {"role": "assistant", "content": "AWS Fargate is a serverless, pay-as-you-go compute engine that lets you focus on building applications without managing servers. AWS Fargate is compatible with both\u00a0Amazon ECS and Amazon EKS. AWS Fargate makes it easy to scale and manage cloud applications by shifting as much management of the underlying infrastructure resources to AWS so development teams can focus on writing code that solve business problems. Shifting tasks such as server management, resource allocation, and scaling to AWS does not only improve your operational posture, but also accelerates the process of going from idea to production on the cloud and lowers the total cost of ownership (TCO). With multiple CPU architectures and operating systems supported, you can enjoy the serverless benefits of cost, agility and scale across a wide variety of applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What use cases does AWS Fargate support?"}, {"role": "assistant", "content": "AWS Fargate is useful for a broad range of workloads, including support for common container use cases such as\u00a0web applications, APIs, microservices architectures,\u00a0data processing, artificial intelligence and machine learning applications. Also, application modernization when\u00a0customers are building new applications in the cloud, or migrating a traditional application to the cloud."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does AWS Fargate work with Amazon ECS and Amazon EKS?"}, {"role": "assistant", "content": "Amazon ECS is a highly scalable, high performance container management service and Amazon EKS is a fully managed Kubernetes service. Both services can schedule containers onto AWS Fargate to automatically scale, load balance, and optimize container availability through managed scheduling, providing an easier way to build and operate containerized applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Where does my workload run on AWS Fargate?"}, {"role": "assistant", "content": "With AWS Fargate each workload runs on its own single use, single tenant compute instance. Each workload is isolated by a virtualization boundary,\u00a0with each Amazon ECS Task or Kubernetes pod running on a newly provisioned instance.\u00a0Please see the\u00a0[AWS Fargate Security Whitepaper](https://web.archive.org/web/20240727090700/https://d1.awsstatic.com/whitepapers/AWS_Fargate_Security_Overview_Whitepaper.pdf)\u00a0for more detail on the AWS Fargate architecture."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How should I choose when to use AWS Fargate?"}, {"role": "assistant", "content": "Choose AWS Fargate for its isolation model and security. You should also select Fargate if you want to launch containers without having to provision or manage [Amazon Elastic Compute Cloud](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ec2/) (EC2) instances. AWS Fargate has built-in integrations with AWS services and third-party tools that allows you to monitor your applications and gather metrics and logs. And, with AWS Fargate, you pay only for compute resources used, with no upfront expenses. If you require greater control of your Amazon EC2 instances or broader customization options, then use Amazon ECS or Amazon EKS without AWS Fargate. Use Amazon EC2 for GPU workloads, which are not supported on AWS Fargate today."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I run my Arm-based applications on AWS Fargate?"}, {"role": "assistant", "content": "Yes. When using Amazon ECS,\u00a0AWS Fargate allows you to run your Arm-based applications by using Arm-compatible container images or multi-architecture container images in\u00a0[Amazon Elastic Container Registry](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ecr/)\u00a0(Amazon ECR). You can simply specify the CPU Architecture as Arm64\u00a0in your Amazon ECS Task Definition to target AWS Fargate powered by Arm-based\u00a0[AWS Graviton Processors](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ec2/graviton/).\u00a0Use Amazon EC2 to run Arm workloads on Amazon EKS, which are not supported on AWS Fargate today."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I run my Amazon ECS Windows containers on AWS Fargate?"}, {"role": "assistant", "content": "Yes. AWS Fargate offers a serverless approach for running your Windows containers. It removes the need to provision and manage servers and lets you specify and pay for resources per application. AWS Fargate provides task-level isolation and handles the necessary patching and updating to help provide a secure compute environment. Please see the\u00a0[Windows platform versions\u00a0](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform-windows-fargate.html)documentation page for supported versions of Windows Server."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use my existing Microsoft Windows License with AWS Fargate?"}, {"role": "assistant", "content": "Since AWS Fargate is a serverless compute engine, customers do not need to manage the underlying compute instances running in AWS Fargate. Therefore, AWS Fargate will manage the Windows OS licenses for you and the cost of doing so is built into the AWS Fargate pricing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the service quotas for AWS Fargate?"}, {"role": "assistant", "content": "[Service quotas in AWS Fargate\u00a0](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-quotas.html#service-quotas-fargate)are based on the number of vCPU cores used in a given region in a given account. New AWS accounts might have initial lower quotas that can increase over time, and request to raise these soft limits through the\u00a0[standard AWS service quota increase process](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html). For workloads that will require significant scale (10,000s of cores) AWS recommends a multi-account strategy."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does the AWS Fargate SLA guarantee?"}, {"role": "assistant", "content": "Our Compute SLA guarantees a Monthly Uptime Percentage of at least 99.99% for AWS Fargate. AWS makes two SLA commitments for the Included Containers Services: (1) a Multi-AZ Included Container Service SLA that governs Included Container Services deployed across multiple AZs; and (2) a Single Task/Pod SLA that governs Included Container Service tasks and pods individually. Please see the\u00a0[AWS Fargate and Amazon Elastic Container Service SLA](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ecs/sla/)\u00a0page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I know if I qualify for an SLA Service Credit?"}, {"role": "assistant", "content": "You are eligible for an AWS Fargate SLA credit under the Compute SLA if more than one Availability Zone in which you are running a task, within the same region, has a Monthly Uptime Percentage of less than 99.99% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, please see the\u00a0[Compute SLA details page](https://web.archive.org/web/20240727090700/https://aws.amazon.com/compute/sla/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I improve the startup time of my container tasks running on AWS Fargate?"}, {"role": "assistant", "content": "Seekable OCI (SOCI) can help reduce the launch time of Amazon ECS tasks on AWS Fargate. SOCI is a technology open sourced by AWS that enables containers to launch faster by lazily loading the container image. To learn how to get started with SOCI, please visit the\u00a0[documentation](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/userguide/container-considerations.html#fargate-tasks-soci-images)\u00a0and the\u00a0[blog post](https://web.archive.org/web/20240727090700/https://aws.amazon.com/blogs/aws/aws-fargate-enables-faster-container-startup-using-seekable-oci/).Reducing AWS Fargate startup times with zstd compressed container images. The layers of a container image are compressed for efficiency, by default using the\u00a0[gzip](https://web.archive.org/web/20240727090700/https://en.wikipedia.org/wiki/Gzip)\u00a0format. However, containerd supports an alternative format known as \u201c[zstd](https://web.archive.org/web/20240727090700/https://en.wikipedia.org/wiki/Zstd)\u201d that has been shown to decompress more quickly, resulting in faster task launch times when using AWS Fargate.\u00a0[Please see this blogpost](https://web.archive.org/web/20240727090700/https://aws.amazon.com/blogs/containers/reducing-aws-fargate-startup-times-with-zstd-compressed-container-images/)\u00a0for more details on how to build container images with zstd."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I size workloads for AWS Fargate?"}, {"role": "assistant", "content": "It is recommended to load test applications locally, or in development environments, to understand the requirements of the application to size the request appropriately.\u00a0[AWS Compute Optimizer](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/compute-optimizer/latest/ug/view-ecs-recommendations.html)\u00a0can be used to provide recommendations if a workload is under or over sized."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I get network traffic in and out of my workload on AWS Fargate?"}, {"role": "assistant", "content": "On AWS Fargate, each ECS Task or Kubernetes Pod is given a dedicated\u00a0[elastic network interface (ENI)](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html)\u00a0attached into your\u00a0[virtual private cloud (VPC)](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html). All traffic in and out of the containerized workload goes through this ENI. Therefore\u00a0[VPC Security Groups](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-groups.html)\u00a0and\u00a0[VPC network ACLs](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html)\u00a0can be used to secure the ENI, and\u00a0[VPC Flow Logs](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html)\u00a0can be used to monitor traffic flows."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I run stateful workloads on AWS Fargate?"}, {"role": "assistant", "content": "Each workload that runs on AWS Fargate is given full access to\u00a0[20 GiB of ephemeral storage](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-task-storage.html)\u00a0to use as temporary storage while the workload is running. Once the workload has stopped, any data stored in this 20 GiB volume is erased. This ephemeral storage volume can be expanded up to 200GiB on Amazon ECS and 175 GiB on Amazon EKS.\u00a0[Amazon Elastic File System](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/efs-volumes.html)\u00a0(EFS) an be used to provide persistent storage to workloads running on AWS Fargate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I build container images within AWS Fargate?"}, {"role": "assistant", "content": "Common approaches to building containers from within containers often require privileged mode (such as with Docker in Docker), which is unavailable in AWS Fargate's security model, or mounting of the docker socket into a container, which is unavailable due to AWS Fargate utilizing containerd as of\u00a0[Platform Version 1.4](https://web.archive.org/web/20240727090700/https://aws.amazon.com/blogs/containers/aws-fargate-launches-platform-version-1-4/). Alternatively, rootless image build project such as\u00a0[Kaniko](https://web.archive.org/web/20240727090700/https://github.com/GoogleContainerTools/kaniko)\u00a0can be deployed within AWS Fargate's security model and are a viable option for building container images."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can AWS Fargate be used in solutions that must conform to a specific compliance programs?"}, {"role": "assistant", "content": "AWS Fargate meets the standards for a wide array of compliance programs, including PCI DSS, SOC, FIPS 140-2, FedRAMP, and HIPAA. For more information and a complete list of programs, please see the\u00a0[AWS Cloud Security Services in Scope\u00a0documentation](https://web.archive.org/web/20240727090700/https://aws.amazon.com/compliance/services-in-scope/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use AWS Fargate for Protected Health Information (PHI) and other HIPAA regulated workloads?"}, {"role": "assistant", "content": "Yes. AWS Fargate is HIPAA-eligible. If you have an executed\u00a0Business Associate Addendum (BAA)\u00a0with AWS, you can process encrypted Protected Health Information (PHI) using containers deployed onto AWS Fargate. For more information, please visit\u00a0[our page on HIPAA compliance](https://web.archive.org/web/20240727090700/https://aws.amazon.com/compliance/hipaa-compliance/).\u00a0If you plan to process, store, or transmit PHI and do not have an executed BAA from AWS, please\u00a0contact us\u00a0for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use AWS Fargate for US Government-regulated workloads or for processing sensitive Controlled Unclassified Information (CUI)?"}, {"role": "assistant", "content": "Yes. AWS Fargate is available in\u00a0[AWS GovCloud (US)](https://web.archive.org/web/20240727090700/https://aws.amazon.com/govcloud-us/)\u00a0Regions.\u00a0AWS GovCloud (US)\u00a0is Amazon's isolated cloud infrastructure and services designed to address specific regulatory and compliance requirements of US Government agencies, as well as contractors, educational institutions, and other US customers that run sensitive workloads in the cloud. For a full list of AWS Regions where AWS Fargate is available, please visit our\u00a0[Region table](https://web.archive.org/web/20240727090700/https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)\u00a0or\u00a0[documentation](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate-Regions.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can AWS Fargate be extended through integrations with other systems?"}, {"role": "assistant", "content": "AWS Fargate offers a flexible integration model inclusive of both first party AWS services and third party [Amazon Partner Network](https://web.archive.org/web/20240727090700/https://aws.amazon.com/ecs/partners/) (APN) solutions. The common integration mechanism is to run a sidecar container within a AWS Fargate task that can interact with the primary application container, for example a runtime security agent or log router that interacts with the primary application and then ships data to a centralized system for analysis and review."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What options do I have for monitoring AWS Fargate workloads?"}, {"role": "assistant", "content": "AWS provides several tools for monitoring and responding to various facets of your AWS Fargate resources, including [Amazon CloudWatch](https://web.archive.org/web/20240727090700/https://aws.amazon.com/cloudwatch/) Alarms, Amazon CloudWatch Logs, Amazon CloudWatch Events, [AWS CloudTrail](https://web.archive.org/web/20240727090700/https://aws.amazon.com/cloudtrail/) Logs, [AWS Trusted Advisor](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/awssupport/latest/user/trusted-advisor.html), and [AWS Compute Optimizer](https://web.archive.org/web/20240727090700/https://aws.amazon.com/compute-optimizer/). A popular approach is to utilize\u00a0[CloudWatch Container Insights](https://web.archive.org/web/20240727090700/https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html)\u00a0to collect and analyze logs and view operational dashboards. Application logging has built-in log drivers for CloudWatch and Splunk, but FireLens for Amazon ECS can be used via task definition parameters to route logs to an AWS service or AWS Partner Network (APN) destination."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the pricing of AWS Fargate?"}, {"role": "assistant", "content": "With AWS Fargate, you pay only for the amount of vCPU, memory, and storage resources provisioned by your containerized applications. vCPU and memory resources are calculated from the time your container images are pulled until the Amazon ECS task or EKS pod terminates, rounded up to the nearest second. A minimum charge of 1 minute applies. 20 GB of ephemeral storage is available for all AWS Fargate Tasks and Pods by default\u2014you only pay for any additional storage that you configure.\u00a0AWS Fargate supports Spot and Compute Savings Plan pricing options just like with Amazon EC2 instances. You can find additional details on the\u00a0[pricing page](https://web.archive.org/web/20240727090700/https://aws.amazon.com/fargate/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I optimize my spend on AWS Fargate?"}, {"role": "assistant", "content": "AWS offers Spot instances for AWS Fargate tasks, which utilizes spare compute capacity that is available at a lower price than on-demand instances. By using spot instances you can run interruption tolerant Amazon ECS Tasks at up to a 70 percent discount off the AWS Fargate price.\u00a0AWS introduced AWS Fargate Savings Plans, a discount model that provides you with the same discounts as Reserved Instances, in exchange for a commitment to use a specific amount (measured in dollars per hour) of compute power over a one- or three-year period.\u00a0AWS Graviton processors are designed by AWS to deliver the best price performance for your cloud workloads running in Amazon EC2, AWS managed containers, and other managed services. AWS Graviton provides up to 40 percent better price performance over comparable x86-based instances. AWS Graviton processors are more energy efficient and use up to 60 percent less energy for the same performance than comparable EC2 instances.\u00a0AWS Fargate is included in the AWS Compute Optimizer, which allows you to easily identify and remediate inefficient configurations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why should I use AWS Fargate powered by Graviton processors?"}, {"role": "assistant", "content": "AWS Graviton processors are custom built by Amazon Web Services cores\u00a0to deliver the best price performance for your cloud workloads. AWS Fargate powered by AWS Graviton processors delivers up to 40% improved price/performance at 20% lower cost over comparable Intel x86-based Fargate for a variety of workloads such as application servers, web services, high-performance computing, and media processing. You get the same serverless benefits of AWS Fargate while optimizing performance and cost for running your containerized workloads."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is AWS Lambda?"}, {"role": "assistant", "content": "AWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume - there is no charge when your code is not running. With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. Just upload your code, and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is serverless computing?"}, {"role": "assistant", "content": "[Serverless computing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/serverless/) allows you to build and run applications and services without thinking about servers. With serverless computing, your application still runs on servers, but all the server management is done by AWS. At the core of serverless computing is AWS Lambda, which lets you run your code without provisioning or managing servers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What events can trigger an AWS Lambda function?"}, {"role": "assistant", "content": "Please see our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/intro-core-components.html#intro-core-components-event-sources) for a complete list of event sources."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use AWS Lambda versus Amazon EC2?"}, {"role": "assistant", "content": "Amazon Web Services offers a set of compute services to meet a range of needs.[Amazon EC2](https://web.archive.org/web/20240727065740/https://aws.amazon.com/ec2/) offers flexibility, with a wide range of instance types and the option to customize the operating system, network and security settings, and the entire software stack, allowing you to easily move existing applications to the cloud. With Amazon EC2 you are responsible for provisioning capacity, monitoring fleet health and performance, and designing for fault tolerance and scalability. [AWS Elastic Beanstalk](https://web.archive.org/web/20240727065740/https://aws.amazon.com/elasticbeanstalk/) offers an easy-to-use service for deploying and scaling web applications in which you retain ownership and full control over the underlying EC2 instances. [Amazon EC2 Container Service](https://web.archive.org/web/20240727065740/https://aws.amazon.com/ecs/) is a scalable management service that supports Docker containers and allows you to easily run distributed applications on a managed cluster of Amazon EC2 instances.AWS Lambda makes it easy to execute code in response to events, such as changes to Amazon S3 buckets, updates to an Amazon DynamoDB table, or custom events generated by your applications or devices. With Lambda, you do not have to provision your own instances; Lambda performs all the operational and administrative activities on your behalf, including capacity provisioning, monitoring fleet health, applying security patches to the underlying compute resources, deploying your code, running a web service front end, and monitoring and logging your code. AWS Lambda provides easy scaling and high availability to your code without additional effort on your part."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What kind of code can run on AWS Lambda?"}, {"role": "assistant", "content": "AWS Lambda offers an easy way to accomplish many activities in the cloud. For example, you can use AWS Lambda to build mobile back-ends that retrieve and transform data from Amazon DynamoDB, handlers that compress or transform objects as they are uploaded to Amazon S3, auditing and reporting of API calls made to any Amazon Web Service, and server-less processing of streaming data using Amazon Kinesis."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What languages does AWS Lambda support?"}, {"role": "assistant", "content": "AWS Lambda natively supports Java, Go, PowerShell, Node.js, C#, Python, and Ruby code, and provides a Runtime API which allows you to use any additional programming languages to author your functions. Please read our documentation on using [Node.js](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/authoring-function-in-nodejs.html), [Python](https://web.archive.org/web/20240727065740/http://docs.aws.amazon.com/lambda/latest/dg/python-lambda.html), [Java](https://web.archive.org/web/20240727065740/http://docs.aws.amazon.com/lambda/latest/dg/java-lambda.html), [Ruby](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html), [C#](https://web.archive.org/web/20240727065740/http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html), [Go](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/go-programming-model.html), and [PowerShell](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/powershell-programming-model.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I access the infrastructure that AWS Lambda runs on?"}, {"role": "assistant", "content": "No. AWS Lambda operates the compute infrastructure on your behalf, allowing it to perform health checks, apply security patches, and do other routine maintenance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does AWS Lambda isolate my code?"}, {"role": "assistant", "content": "Each AWS Lambda function runs in its own isolated environment, with its own resources and file system view. AWS Lambda uses the same techniques as Amazon EC2 to provide security and separation at the infrastructure and execution levels."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does AWS Lambda secure my code?"}, {"role": "assistant", "content": "AWS Lambda stores code in Amazon S3 and encrypts it at rest. AWS Lambda performs additional integrity checks while your code is in use."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What AWS regions are available for AWS Lambda?"}, {"role": "assistant", "content": "Please refer to the [AWS Global Infrastructure Region Table](https://web.archive.org/web/20240727065740/https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an AWS Lambda function?"}, {"role": "assistant", "content": "The code you run on AWS Lambda is uploaded as a \u201cLambda function\u201d. Each function has associated configuration information, such as its name, description, entry point, and resource requirements. The code must be written in a \u201cstateless\u201d style i.e. it should assume there is no affinity to the underlying compute infrastructure. Local file system access, child processes, and similar artifacts may not extend beyond the lifetime of the request, and any persistent state should be stored in Amazon S3, Amazon DynamoDB, Amazon EFS, or another Internet-available storage service. Lambda functions can include libraries, even native ones."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will AWS Lambda reuse function instances?"}, {"role": "assistant", "content": "To improve performance, AWS Lambda may choose to retain an instance of your function and reuse it to serve a subsequent request, rather than creating a new copy. To learn more about how Lambda reuses function instances, visit our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-introduction.html). Your code should not assume that this will always happen."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What if I need scratch space on disk for my AWS Lambda function?"}, {"role": "assistant", "content": "You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments. The ephemeral storage is available in each function\u2019s /tmp directory.Each function has access to 512MB of storage at no additional cost. When configuring your functions with more than 512MB of ephemeral storage, you will be charged based on the amount of storage you configure, and how long your function runs, metered in 1ms increments. For comparison, in the US East (Ohio) region, the AWS Fargate ephemeral storage price is $0.000111 per GB-hour, or $0.08 per GB-month. Amazon EBS gp3 storage volume pricing in US East (Ohio) is $0.08 per GB-month. AWS Lambda ephemeral storage pricing is $0.0000000309 per GB-second, or $0.000111 per GB-hour and $0.08 per GB-month. To learn more, see [AWS Lambda Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I configure my application to use AWS Lambda ephemeral storage?"}, {"role": "assistant", "content": "You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is AWS Lambda ephemeral storage encrypted?"}, {"role": "assistant", "content": "Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What metrics can I use to monitor my AWS Lambda ephemeral storage usage?"}, {"role": "assistant", "content": "You can use AWS CloudWatch Lambda Insight metrics to monitor your ephemeral storage usage. To learn more, see the AWS CloudWatch Lambda Insights [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Lambda-Insights-metrics.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Amazon S3, Amazon EFS, or AWS Lambda ephemeral storage for my serverless applications?"}, {"role": "assistant", "content": "If your application needs durable, persistent storage, consider using Amazon S3 or Amazon EFS. If your application requires storing data needed by code in a single function invocation, consider using AWS Lambda ephemeral storage as a transient cache. To learn more, please see [Choosing between AWS Lambda data storage options in web apps](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/choosing-between-aws-lambda-data-storage-options-in-web-apps/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use ephemeral storage while Provisioned Concurrency is enabled for my function?"}, {"role": "assistant", "content": "Yes. However, if you application needs persistent storage, consider using Amazon EFS or Amazon S3. When you enable Provisioned Concurrency for your function, your function's [initialization code](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/foundation-progmodel.html) runs during allocation and every few hours, as running instances of your function are recycled. You can see the initialization time in logs and [traces](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/services-xray.html) after an instance processes a request. However, initialization is billed even if the instance never processes a request. This Provisioned Concurrency initialization behavior may affect how your function interacts with data you store in ephemeral storage, even when your function isn\u2019t processing requests. To learn more about Provisioned Concurrency, please see the relevant [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I configure my application to use AWS Lambda ephemeral storage?"}, {"role": "assistant", "content": "You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is AWS Lambda ephemeral storage encrypted?"}, {"role": "assistant", "content": "Yes. All data stored in ephemeral storage is encrypted at rest with a key managed by AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What metrics can I use to monitor my AWS Lambda ephemeral storage usage?"}, {"role": "assistant", "content": "You can use AWS CloudWatch Lambda Insight metrics to monitor your ephemeral storage usage. To learn more, see the AWS CloudWatch Lambda Insights [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Lambda-Insights-metrics.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why must AWS Lambda functions be stateless?"}, {"role": "assistant", "content": "Keeping functions stateless enables AWS Lambda to rapidly launch as many copies of the function as needed to scale to the rate of incoming events. While AWS Lambda\u2019s programming model is stateless, your code can access stateful data by calling other web services, such as Amazon S3 or Amazon DynamoDB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use threads and processes in my AWS Lambda function code?"}, {"role": "assistant", "content": "Yes. AWS Lambda allows you to use normal language and operating system features, such as creating additional threads and processes. Resources allocated to the Lambda function, including memory, execution time, disk, and network use, must be shared among all the threads/processes it uses. You can launch processes using any language supported by Amazon Linux."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What restrictions apply to AWS Lambda function code?"}, {"role": "assistant", "content": "Lambda attempts to impose as few restrictions as possible on normal language and operating system activities, but there are a few activities that are disabled: Inbound network connections are blocked by AWS Lambda, and for outbound connections, only TCP/IP and UDP/IP sockets are supported, and ptrace (debugging) system calls are blocked. TCP port 25 traffic is also blocked as an anti-spam measure."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create an AWS Lambda function using the Lambda console?"}, {"role": "assistant", "content": "If you are using Node.js or Python, you can author the code for your function using code editor in the AWS Lambda console, which lets you author and test your functions, and view the results of function executions in a robust, IDE-like environment. [Go to the console to get started](https://web.archive.org/web/20240727065740/https://console.aws.amazon.com/lambda/home?region=us-east-1).You can also package the code (and any dependent libraries) as a ZIP and upload it using the AWS Lambda console from your local environment or specify an Amazon S3 location where the ZIP file is located. Uploads must be no larger than 50MB (compressed). You can use the AWS Eclipse plugin to author and deploy Lambda functions in Java. You can use the Visual Studio plugin to author and deploy Lambda functions in C#, and Node.js."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create an AWS Lambda function using the Lambda CLI?"}, {"role": "assistant", "content": "You can package the code (and any dependent libraries) as a ZIP and upload it using the AWS CLI from your local environment, or specify an Amazon S3 location where the ZIP file is located. Uploads must be no larger than 50MB (compressed). Visit the [Lambda Getting Started guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html) to get started."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Lambda support environment variables?"}, {"role": "assistant", "content": "Yes. You can easily create and modify environment variables from the AWS Lambda Console, CLI, or SDKs. To learn more about environment variables, see the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/env_variables.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I store sensitive information in environment variables?"}, {"role": "assistant", "content": "For sensitive information, such as database passwords, we recommend you use client-side encryption using [AWS Key Management Service](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/kms/latest/developerguide/overview.html) and store the resulting values as ciphertext in your environment variable. You will need to include logic in your AWS Lambda function code to decrypt these values."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I manage my AWS Lambda functions?"}, {"role": "assistant", "content": "You can adjust and secure the resources associated with your Lambda function using the Lambda API or console. To learn more about it, see the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-managing.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I share code across functions?"}, {"role": "assistant", "content": "Yes, you can package any code (frameworks, SDKs, libraries, and more) as a [Lambda Layer](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html) and manage and share them easily across multiple functions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I monitor an AWS Lambda function?"}, {"role": "assistant", "content": "AWS Lambda automatically monitors Lambda functions on your behalf, reporting real-time metrics through Amazon CloudWatch, including total requests, account-level and function-level concurrency usage, latency, error rates, and throttled requests. You can view statistics for each of your Lambda functions via the Amazon CloudWatch console or through the AWS Lambda console. You can also call third-party monitoring APIs in your Lambda function.\u00a0Visit [Troubleshooting CloudWatch metrics](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions.html) to learn more. Standard charges for AWS Lambda apply to use Lambda\u2019s built-in metrics."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I troubleshoot failures in an AWS Lambda function?"}, {"role": "assistant", "content": "AWS Lambda automatically integrates with Amazon CloudWatch logs, creating a log group for each Lambda function and providing basic application lifecycle event log entries, including logging the resources consumed for each use of that function. You can easily insert additional logging statements into your code. You can also call third-party logging APIs in your Lambda function. Visit [Troubleshooting Lambda functions](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions.html) to learn more. Amazon CloudWatch Logs rates will apply."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I scale an AWS Lambda function?"}, {"role": "assistant", "content": "You do not have to scale your Lambda functions \u2013 AWS Lambda scales them automatically on your behalf. Every time an event notification is received for your function, AWS Lambda quickly locates free capacity within its compute fleet and runs your code. Since your code is stateless, AWS Lambda can start as many copies of your function as needed without lengthy deployment and configuration delays. There are no fundamental limits to scaling a function. AWS Lambda will dynamically allocate capacity to match the rate of incoming events."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are compute resources assigned to an AWS Lambda function?"}, {"role": "assistant", "content": "In the AWS Lambda resource model, you choose the amount of memory you want for your function, and are allocated proportional CPU power and other resources. For example, choosing 256MB of memory allocates approximately twice as much CPU power to your Lambda function as requesting 128MB of memory and half as much CPU power as choosing 512MB of memory. To learn more, see our [Function Configuration documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html).You can set your memory from 128MB to 10,240MB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q:\u00a0When should I use AWS Lambda functions with more than 3008 MB of memory?"}, {"role": "assistant", "content": "Customers running memory or compute-intensive workloads can now use more memory for their functions. Larger memory functions help multithreaded applications run faster, making them ideal for data and computationally intensive applications like machine learning, batch and ETL jobs, financial modeling, genomics, HPC, and media processing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long can an AWS Lambda function execute?"}, {"role": "assistant", "content": "AWS Lambda functions can be configured to run up to 15 minutes per execution. You can set the timeout to any value between 1 second and 15 minutes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be charged for using AWS Lambda functions?"}, {"role": "assistant", "content": "AWS Lambda is priced on a pay-per-use basis. Please see the [AWS Lambda pricing page](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/) for details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I save money on AWS Lambda with a Compute Savings Plan?"}, {"role": "assistant", "content": "Yes. In addition to saving money on Amazon EC2 and AWS Fargate, you can also use Compute Savings Plans to save money on AWS Lambda. Compute Savings Plans offer up to 17% discount on Duration, Provisioned Concurrency, and Duration (Provisioned Concurrency). Compute Savings Plans do not offer a discount on Requests in your Lambda bill. However, your Compute Savings Plans commitment can apply to Requests at regular rates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Lambda support versioning?"}, {"role": "assistant", "content": "Yes. By default, each AWS Lambda function has a single, current version of the code. Clients of your Lambda function can call a specific version or get the latest implementation. Please read our documentation on [versioning Lambda functions](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How long after uploading my code will my AWS Lambda function be ready to call?"}, {"role": "assistant", "content": "Deployment times may vary with the size of your code, but AWS Lambda functions are typically ready to call within seconds of upload."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use my own version of a supported library?"}, {"role": "assistant", "content": "Yes. You can include your own copy of a library (including the AWS SDK) in order to use a different version than the default one provided by AWS Lambda."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does tiered pricing work?"}, {"role": "assistant", "content": "AWS Lambda offers discounted pricing tiers for monthly on-demand function duration above certain thresholds. Tiered pricing is available for functions running on both x86 and Arm architectures. Lambda pricing tiers are applied to aggregate monthly on-demand duration of your functions running on the same architecture (x86 or Arm, respectively), in the same region, within the account. If you\u2019re using consolidated billing in AWS Organizations, pricing tiers are applied to the aggregate monthly duration of your functions running on the same architecture, in the same region, across the accounts in the organization. For example, if you are running x86 Lambda functions in the US East (Ohio) region, you will pay $0.0000166667 for every GB-second for the first 6 billion GB-seconds per month, $0.0000150000 for every GB-second for the next 9 billion GB-seconds per month, and $0.0000133334 for every GB-second over 15 billion GB-seconds per month, in that region. Pricing for Requests, Provisioned Concurrency, and Provisioned Concurrency Duration remains unchanged. For more information, please see [AWS Lambda Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I take advantage of both tiered pricing, and Compute Savings Plans?"}, {"role": "assistant", "content": "Yes. Lambda usage that is covered by your hourly savings plan commitment is billed at the [applicable CSP rate and discount](https://web.archive.org/web/20240727065740/https://aws.amazon.com/savingsplans/compute-pricing/). The remaining usage that is not covered by this commitment will be billed at the rate corresponding to the tier your monthly aggregate function duration falls in."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is an event source?"}, {"role": "assistant", "content": "An event source is an AWS service or developer-created application that produces events that trigger an AWS Lambda function to run. Some services publish these events to Lambda by invoking the cloud function directly (for example, Amazon S3). Lambda can also poll resources in other services that do not publish events to Lambda. For example, Lambda can pull records from an Amazon Kinesis stream or an Amazon SQS queue and execute a Lambda function for each fetched message.Many other services, such as AWS CloudTrail, can act as event sources simply by logging to Amazon S3 and using S3 bucket notifications to trigger AWS Lambda functions"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What event sources can be used with AWS Lambda?"}, {"role": "assistant", "content": "Please see our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/intro-core-components.html#intro-core-components-event-sources) for a complete list of event sources."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How are events represented in AWS Lambda?"}, {"role": "assistant", "content": "Events are passed to a Lambda function as an event input parameter. For event sources where events arrive in batches, such as Amazon SQS, Amazon Kinesis, and Amazon DynamoDB Streams, the event parameter may contain multiple events in a single call, based on the batch size you request. To learn more about Amazon S3 event notifications, visit [Configuring Notifications for Amazon S3 Events](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html). To learn more about Amazon DynamoDB Streams, visit the [DynamoDB Stream Developers Guide](https://web.archive.org/web/20240727065740/http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html). To learn more about invoking Lambda functions using Amazon SNS, visit the [Amazon SNS Developers Guide](https://web.archive.org/web/20240727065740/http://docs.aws.amazon.com/sns/latest/dg/sns-lambda.html). For more information on Amazon Cognito events, visit [Amazon Cognito](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cognito/). For more information on AWS CloudTrail logs and auditing API calls across AWS services, see [AWS CloudTrail](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cloudtrail/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I make an AWS Lambda function respond to changes in an Amazon S3 bucket?"}, {"role": "assistant", "content": "From the AWS Lambda console, you can select a function and associate it with notifications from an Amazon S3 bucket. Alternatively, you can use the Amazon S3 console and configure the bucket\u2019s notifications to send to your AWS Lambda function. This same functionality is also available through the AWS SDK and CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I make an AWS Lambda function respond to updates in an Amazon DynamoDB table?"}, {"role": "assistant", "content": "You can trigger a Lambda function on DynamoDB table updates by subscribing your Lambda function to the DynamoDB Stream associated with the table. You can associate a DynamoDB Stream with a Lambda function using the Amazon DynamoDB console, the AWS Lambda console, or Lambda\u2019s registerEventSource API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use an AWS Lambda function to process records in an Amazon Kinesis stream?"}, {"role": "assistant", "content": "From the AWS Lambda console, you can select a Lambda function and associate it with an Amazon Kinesis stream owned by the same account. This same functionality is also available through the AWS SDK and CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does AWS Lambda process data from Amazon Kinesis streams and Amazon DynamoDB Streams?"}, {"role": "assistant", "content": "The Amazon Kinesis and DynamoDB Streams records sent to your AWS Lambda function are strictly serialized, per shard. This means that if you put two records in the same shard, Lambda guarantees that your Lambda function will be successfully invoked with the first record before it is invoked with the second record. If the invocation for one record times out, is throttled, or encounters any other error, Lambda will retry until it succeeds (or the record reaches its 24-hour expiration) before moving on to the next record. The ordering of records across different shards is not guaranteed, and processing of each shard happens in parallel."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How should I choose between AWS Lambda and Amazon Kinesis Data Analytics for my analytics needs?"}, {"role": "assistant", "content": "AWS Lambda allows you to perform time-based aggregations (such as count, max, sum, average, etc.) over a short window of up to 15 minutes for your data in Amazon Kinesis or Amazon DynamoDB Streams over a single logical partition such as a shard. This gives you the option to easily set up simple analytics for your event-based application without adding architectural complexity, as your business and analytics logic can be located in the same function. Lambda allows aggregations over a maximum of a 15-minute tumbling window, based on the event timestamp. [Amazon Kinesis Data Analytics](https://web.archive.org/web/20240727065740/https://aws.amazon.com/kinesis/data-analytics/)\u00a0allows you to build more complex analytics applications that support flexible processing choices and robust fault-tolerance with exactly-once processing without duplicates, and analytics that can be performed over an entire data stream across multiple logical partitions. With KDA, you can analyze data over multiple types of aggregation windows (tumbling window, stagger window, sliding window, session window) using either the event time or the processing time.\u00a0\u00a0AWS LambdaAmazon KDATumbling WindowYesYesStagger WindowNoYesSliding WindowNoYesSession WindowNoYesEnrichmentNoYesJoint input and reference tablesNoYesSplit input streamNoYesExactly-once processingNoYesMaximum time window15 minsNo limitAggregation scopePartition/shardStreamTime semanticsEvent timeEvent time, Processing time"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use an AWS Lambda function to respond to notifications sent by Amazon Simple Notification Service (SNS)?"}, {"role": "assistant", "content": "From the AWS Lambda console, you can select a Lambda function and associate it with an Amazon SNS topic. This same functionality is also available through the AWS SDK and CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use an AWS Lambda function to respond to emails sent by Amazon Simple Email Service (SES)?"}, {"role": "assistant", "content": "From the Amazon SES Console, you can set up your receipt rule to have Amazon SES deliver your messages to an AWS Lambda function. The same functionality is available through the AWS SDK and CLI."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use an AWS Lambda function to respond to Amazon CloudWatch alarms?"}, {"role": "assistant", "content": "First, configure the alarm to send Amazon SNS notifications. Then from the AWS Lambda console, select a Lambda function and associate it with that Amazon SNS topic. See the [Amazon CloudWatch Developer Guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatch.html) for more on setting up Amazon CloudWatch alarms."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use an AWS Lambda function to respond to changes in user or device data managed by Amazon Cognito?"}, {"role": "assistant", "content": "From the AWS Lambda console, you can select a function to trigger when any datasets associated with an [Amazon Cognito](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cognito/) identity pool are synchronized. This same functionality is also available through the AWS SDK and CLI. Visit Amazon Cognito for more information on using Amazon Cognito to share and synchronize data across a user\u2019s devices."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can my application trigger an AWS Lambda function directly?"}, {"role": "assistant", "content": "You can invoke a Lambda function using a custom event through AWS Lambda\u2019s invoke API. Only the function owner or another AWS account that the owner has granted permission can invoke the function. Visit the [Lambda Developers Guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the latency of invoking an AWS Lambda function in response to an event?"}, {"role": "assistant", "content": "AWS Lambda is designed to process events within milliseconds. Latency will be higher immediately after a Lambda function is created, updated, or if it has not been used recently."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create a mobile backend using AWS Lambda?"}, {"role": "assistant", "content": "You upload the code you want AWS Lambda to execute and then invoke it from your mobile app using the AWS Lambda SDK included in the AWS Mobile SDK. You can make both direct (synchronous) calls to retrieve or check data in real time, as well as asynchronous calls. You can also define a custom API using Amazon API Gateway and invoke your Lambda functions through any REST compatible client. To learn more about the AWS Mobile SDK, visit the [AWS Mobile SDK](https://web.archive.org/web/20240727065740/https://aws.amazon.com/mobile/sdk/) page. To learn more about Amazon API Gateway, visit the [Amazon API Gateway](https://web.archive.org/web/20240727065740/https://aws.amazon.com/api-gateway/) page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I invoke an AWS Lambda function over HTTPS?"}, {"role": "assistant", "content": "You can invoke a Lambda function over HTTPS by defining a custom RESTful API using Amazon API Gateway. This gives you an endpoint for your function which can respond to REST calls like GET, PUT, and POST. Read more about using AWS Lambda with Amazon API Gateway."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can my AWS Lambda function customize its behavior to the device and app making the request?"}, {"role": "assistant", "content": "When called through the AWS Mobile SDK, AWS Lambda functions automatically gain insight into the device and application that made the call through the \u2018context\u2019 object."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can my AWS Lambda function personalize its behavior based on the identity of the end-user of an application?"}, {"role": "assistant", "content": "When your app uses the Amazon Cognito identity, end users can authenticate themselves using a variety of public login providers such as Amazon, Facebook, Google, and other OpenID Connect-compatible services. User identity is then automatically and secured presented to your Lambda function in the form of an Amazon Cognito id, allowing it to access user data from Amazon Cognito, or as a key to store and retrieve data in Amazon DynamoDB or other web services."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create an Alexa skill using AWS Lambda?"}, {"role": "assistant", "content": "AWS Lambda is integrated with the Alexa Skills Kit, a collection of self-service APIs, tools, documentation, and code samples that make it easy for you to create voice-driven capabilities (or \u201cskills\u201d) for Alexa. You simply upload the Lambda function code for the new Alexa skill you are creating, and AWS Lambda does the rest, executing the code in response to Alexa voice interactions and automatically managing the compute resources on your behalf. Read the Alexa Skills Kit documentation for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if my function fails while processing an event?"}, {"role": "assistant", "content": "For Amazon S3 bucket notifications and custom events, AWS Lambda will attempt execution of your function three times in the event of an error condition in your code or if you exceed a service or resource limit. For ordered event sources that AWS Lambda polls on your behalf, such as Amazon DynamoDB Streams and Amazon Kinesis streams, Lambda will continue attempting execution in the event of a developer code error until the data expires. You can monitor progress through the Amazon Kinesis and Amazon DynamoDB consoles and through the Amazon CloudWatch metrics that AWS Lambda generates for your function. You can also set Amazon CloudWatch alarms based on error or execution throttling rates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is a serverless application?"}, {"role": "assistant", "content": "Lambda-based applications (also referred to as serverless applications) are composed of functions triggered by events. A typical serverless application consists of one or more functions triggered by events such as object uploads to Amazon S3, Amazon SNS notifications, or API actions. These functions can stand alone or leverage other resources such as DynamoDB tables or Amazon S3 buckets. The most basic serverless application is simply a function."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I deploy and manage a serverless application?"}, {"role": "assistant", "content": "You can deploy and manage your serverless applications using the AWS Serverless Application Model (AWS SAM). AWS SAM is a specification that prescribes the rules for expressing serverless applications on AWS. This specification aligns with the syntax used by AWS CloudFormation today and is supported natively within AWS CloudFormation as a set of resource types (referred to as \"serverless resources\"). These resources make it easier for AWS customers to use CloudFormation to configure and deploy serverless applications using existing CloudFormation APIs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I discover existing serverless applications developed by the AWS community?"}, {"role": "assistant", "content": "You can choose from a collection of serverless applications published by developers, companies, and partners in the AWS community with the [AWS Serverless Application Repository](https://web.archive.org/web/20240727065740/https://aws.amazon.com/serverless/serverlessrepo/). After finding an application, you can configure and deploy it straight from the [Lambda console](https://web.archive.org/web/20240727065740/https://console.aws.amazon.com/lambda/home?region=us-east-1)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I automate deployment for a serverless application?"}, {"role": "assistant", "content": "You can automate your serverless application release process using AWS CodePipeline and AWS CodeDeploy. CodePipeline is a continuous delivery service that enables you to model, visualize and automate the steps required to release your serverless application. CodeDeploy provides a deployment automation engine for your Lambda-based applications. CodeDeploy lets you orchestrate deployments according to established best-practice methodologies such as canary and linear deployments, and helps you establish the necessary guardrails to verify that newly-deployed code is safe, stable, and ready to be fully released to production.\u00a0To learn more about serverless CI/CD, visit our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/automating-deployment.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I get started on building a serverless application?"}, {"role": "assistant", "content": "To get started, visit the AWS Lambda console and download one of our blueprints. The file you download will contain an AWS SAM file (which defines the AWS resources in your application) and a .ZIP file (which includes your function code). You can then use AWS CloudFormation commands to package and deploy the serverless application that you just downloaded. For more details, visit our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/deploying-lambda-apps.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I coordinate calls between multiple AWS Lambda functions?"}, {"role": "assistant", "content": "You can use [AWS Step Functions](https://web.archive.org/web/20240727065740/https://aws.amazon.com/step-functions/) to coordinate a series of AWS Lambda functions in a specific order. You can invoke multiple Lambda functions sequentially, passing the output of one to the other, and/or in parallel, and Step Functions will maintain state during executions for you."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I troubleshoot a serverless application?"}, {"role": "assistant", "content": "You can enable your Lambda function for tracing with [AWS X-Ray](https://web.archive.org/web/20240727065740/https://aws.amazon.com/xray/) by adding X-Ray permissions to your Lambda function execution role and changing your function \u201ctracing mode\u201d to \u201cactive. \u201d When X-Ray is enabled for your Lambda function, AWS Lambda will emit tracing information to X-Ray regarding the Lambda service overhead incurred when invoking your function. This will provide you with insights such as Lambda service overhead, function init time, and function execution time. In addition, you can include the X-Ray SDK in your Lambda deployment package to create your own trace segments, annotate your traces, or view trace segments for downstream calls made from your Lambda function. X-Ray SDKs are currently available for Node.js and Java. Visit [Troubleshooting Lambda-based applications](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html) to learn more. AWS X-Ray rates will apply."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I build serverless applications that connect to relational databases?"}, {"role": "assistant", "content": "Yes. You can build highly scalable, secure, Lambda-based serverless applications that connect to relational databases using [Amazon RDS Proxy](https://web.archive.org/web/20240727065740/https://aws.amazon.com/rds/proxy/), a highly available database proxy that manages thousands of concurrent connections to relational databases. Currently, RDS Proxy supports MySQL and Aurora databases. You can begin using RDS Proxy through the Amazon RDS console or the AWS Lambda console. Serverless applications that use fully managed connection pools from RDS Proxy will be billed according to [RDS Proxy Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/rds/proxy/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is AWS SAM licensed?"}, {"role": "assistant", "content": "The specification is open sourced under Apache 2.0, which allows you and others to adopt and incorporate AWS SAM into build, deployment, monitoring, and management tools with a commercial-friendly license. You can access the AWS SAM repository on GitHub [here](https://web.archive.org/web/20240727065740/https://github.com/awslabs/serverless-application-specification)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Container Image Support for AWS Lambda?"}, {"role": "assistant", "content": "AWS Lambda now enables you to package and deploy functions as container images. Customers can leverage the flexibility and familiarity of container tooling, and the agility and operational simplicity of AWS Lambda to build applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I use Container Image Support for AWS Lambda?"}, {"role": "assistant", "content": "You can start with either an AWS provided base images for Lambda or by using one of your preferred community or private enterprise images. Then, simply use Docker CLI to build the image, upload it to Amazon ECR, and then create the function by using all familiar Lambda interfaces and tools, such as the AWS Management Console, the AWS CLI, the AWS SDK, AWS SAM, and AWS CloudFormation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which container image types are supported?"}, {"role": "assistant", "content": "You can deploy third-party Linux base images (e.g. Alpine or Debian) to Lambda in addition to the Lambda provided images. AWS Lambda will support all images based on the following image manifest formats: Docker Image Manifest V2 Schema 2 (used with Docker version 1.10 and newer) or Open Container Initiative (OCI) Spec (v1.0 and up). Lambda supports images with a size of up to 10GB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What base images can I use?"}, {"role": "assistant", "content": "AWS Lambda provides a variety of base images customers can extend, and customers can also use their preferred Linux-based images with a size of up to 10GB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What container tools can I use to package and deploy functions as container images?"}, {"role": "assistant", "content": "You can use any container tooling as long as it supports one of the following container image manifest formats: Docker Image Manifest V2 Schema 2 (used with Docker version 1.10 and newer) or Open Container Initiative (OCI) Specifications (v1.0 and up). For example, you can use native container tools (i.e. docker run, docker compose, Buildah and Packer) to define your functions as a container image and deploy to Lambda."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What AWS Lambda features are available to functions deployed as container images?"}, {"role": "assistant", "content": "All existing AWS Lambda features, with the exception of Lambda layers and Code Signing, can be used with functions deployed as container images. Once deployed, AWS Lambda will treat an image as immutable. Customers can use container layers during their build process to include dependencies."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will AWS Lambda patch and update my deployed container image?"}, {"role": "assistant", "content": "Not at this time. Your image, once deployed to AWS Lambda, will be immutable. The service will not patch or update the image. However, AWS Lambda will publish curated base images for all supported runtimes that are based on the Lambda managed environment. These published images will be patched and updated along with updates to the AWS Lambda managed runtimes. You can pull and use the latest base image from DockerHub or Amazon ECR Public, re-build your container image and deploy to AWS Lambda via Amazon ECR. This allows you to build and test the updated images and runtimes, prior to deploying the image to production"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are the differences between functions created using ZIP archives vs. container images?"}, {"role": "assistant", "content": "There are three main differences between functions created using ZIP archives vs. container images:Functions created using ZIP archives have a maximum code package size of 250 MB unzipped, and those created using container images have a maximum image size of 10 GB.\u00a0Lambda uses Amazon ECR as the underlying code storage for functions defined as container images, so a function may not be invocable when the underlying image is deleted from ECR.\u00a0ZIP functions are automatically patched for the latest runtime security and bug fixes. Functions defined as container images are immutable, and customers are responsible for the components packaged in their function. Customers can leverage the AWS provided base images which are regularly updated by AWS for security and bug fixes, using the most recent patches available."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there a performance difference between functions defined as zip and container images?"}, {"role": "assistant", "content": "No - AWS Lambda ensures that the performance profiles for functions packaged as container images are the same as for those packaged as ZIP archives, including typically sub-second start up times."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be charged for deploying Lambda functions as container images?"}, {"role": "assistant", "content": "There is no additional charge for packaging and deploying functions as container images to AWS Lambda. When you invoke your function deployed as a container image, you pay the regular price for requests and execution duration. To learn more, visit [AWS Lambda pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/).\u00a0You will be charged for storing your container images in Amazon ECR at the standard ECR prices. To learn more, visit [Amazon ECR pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/ecr/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the Lambda Runtime Interface Emulator (RIE)?"}, {"role": "assistant", "content": "The Lambda Runtime Interface Emulator is a proxy for the Lambda [Runtime API](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html),which allows customers to locally test their Lambda function packaged as a container image. It is a lightweight web server that converts HTTP requests to JSON events and emulates the Lambda Runtime API. It allows you to locally test your functions using familiar tools such as cURL and the Docker CLI (when testing functions packaged as container images). It also simplifies running your application on additional compute services. You can include the Lambda Runtime Interface Emulator in your container image to have it accept HTTP requests natively instead of the JSON events required for deployment to Lambda. This component does not emulate the Lambda orchestrator, or security and authentication configurations. The Runtime Interface Emulator is open sourced on GitHub. You can get started by downloading and installing it on your local machine."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why do I need the Lambda Runtime Interface Emulator (RIE) during local testing?"}, {"role": "assistant", "content": "The Lambda Runtime API in the running Lambda service accepts JSON events and returns responses. The Lambda Runtime Interface Emulator allows the function packaged as a container image to accept HTTP requests during local testing with tools like cURL, and surface them via the same interface locally to the function. It allows you to use the docker run or docker-compose up command to locally test your lambda application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What function behaviors can I test locally with the emulator?"}, {"role": "assistant", "content": "You can use the emulator to test if your function code is compatible with the Lambda environment, runs successfully, and provides the expected output. For example, you can mock test events from different event sources. You can also use it to test extensions and agents built into the container image against the Lambda Extensions API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How does the Runtime Interface Emulator (RIE) help me run my Lambda compatible image on additional compute services?"}, {"role": "assistant", "content": "Customers can add the Runtime Interface Emulator as the entry point to the container image or package it as a sidecar to ensure the container image now accepts HTTP requests instead of JSON events. This simplifies the changes required to run their container image on additional compute services. Customers will be responsible for ensuring they follow all security, performance, and concurrency best practices for their chosen environment. RIE is pre-packaged into the AWS Lambda provided images, and is available by default in AWS SAM CLI. Base image providers can use the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) to provide the same experience for their base images."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I deploy my existing containerized application to AWS Lambda?"}, {"role": "assistant", "content": "You can deploy a containerized application to AWS Lambda if it meets the below requirements:The container image must implement the Lambda Runtime API. We have open-sourced a set of software packages, Runtime Interface Clients (RIC), that implement the Lambda Runtime API, allowing you to seamlessly extend your preferred base images to be Lambda compatible.The container image must be able to run on a read-only filesystem. Your function code can access a writable /tmp directory storage of 512 MB. If you are using an image that requires a writable root directory, configure it to write to the /tmp directory.The files required for the execution of function code can be read by the default Lambda user. Lambda defines a default Linux user with least-privileged permissions that follows security best practices. You need to verify that your application code does not rely on files that are restricted by other Linux users for execution.It is a Linux based container image."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q.\u00a0What is AWS Lambda SnapStart?"}, {"role": "assistant", "content": "AWS Lambda SnapStart for Java delivers up to 10x faster function startup performance. For on-demand functions, the initialization phase (where AWS Lambda loads the function\u2019s code and initializes external dependencies) is the largest contributor to start-up latency, and happens on the first invoke. With Lambda SnapStart, Lambda initializes the one-time initialization function code ahead of time when you publish a function version, instead of when you first invoke the function. Then, Lambda takes a snapshot and caches the memory and disk state of the initialized\u00a0 [execution environment](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html). When you invoke the function\u2014and as it scales up\u2014Lambda resumes the function from the cached snapshot instead of initializing the function from scratch."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How do I configure my Lambda function to use Lambda SnapStart?"}, {"role": "assistant", "content": "Lambda SnapStart is a simple function level configuration that can be configured for new and existing Java functions by using Lambda API, the AWS Management Console, AWS Command Line Interface (CLI), AWS SDK, AWS Cloud Development Kit (CDK), AWS CloudFormation, and the AWS Serverless Application Model (SAM). When you configure Lambda SnapStart, every function version that is published thereafter benefits from the improved startup performance offered by Lambda SnapStart. To learn more about Lambda SnapStart, see the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/snapstart.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How do I choose between Lambda SnapStart and Provisioned Concurrency (PC)?"}, {"role": "assistant", "content": "Lambda SnapStart is a performance optimization that helps your Java functions to achieve up to 10x faster start-up times by reducing the variable latency incurred during execution of one-time initialization code. Lambda SnapStart works broadly across all functions in your application or account at no additional cost. When a customer publishes a function version with Lambda SnapStart, the function\u2019s code is initialized ahead of time, instead of being initialized on the first invoke. Lambda then takes a snapshot of the initialized execution environment and persists it in a tiered cache for low-latency access. When the function is first invoked and then scaled, Lambda resumes the function from the cached snapshot instead of initializing from scratch, driving a lower startup latency. While Lambda SnapStart reduces startup latency, it works as a best-effort optimization, and does not guarantee elimination of cold starts. If your application has strict latency requirements and requires double-digit millisecond startup times, we recommend you use PC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Which runtimes does Lambda SnapStart support?"}, {"role": "assistant", "content": "Lambda SnapStart supports the Java 11 runtime. Future versions of Java will be supported after they are released. For all runtimes supported by Lambda, see the [Lambda runtimes documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I enable both Lambda SnapStart and PC on the same function?"}, {"role": "assistant", "content": "No. Lambda SnapStart and PC cannot be enabled at the same time, on the same function."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I configure a Lambda SnapStart function with a virtual private cloud (VPC)?"}, {"role": "assistant", "content": "Yes. You can configure a Lambda SnapStart function to access resources in a virtual private cloud (VPC). For more information on how to configure your function with a VPC, see the [Lambda documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I configure Lambda SnapStart on both x86 and Arm architectures?"}, {"role": "assistant", "content": "No. You can configure Lambda SnapStart only for functions running on x86 architecture at this time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I enable Lambda SnapStart with Amazon Elastic File System (EFS)?"}, {"role": "assistant", "content": "No. You cannot enable Lambda SnapStart with Amazon EFS at this time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I enable Lambda SnapStart with larger ephemeral storage (/tmp) beyond 512 MB?"}, {"role": "assistant", "content": "No. You cannot enable Lambda SnapStart with larger ephemeral storage (/tmp) beyond 512 MB at this time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Does the process of caching and resuming from snapshots introduce software compatibility considerations?"}, {"role": "assistant", "content": "Yes. If your code assumes uniqueness of state, you need to evaluate your code\u2019s resilience to snapshot operations (such as being cloned and resumed). To learn more on uniqueness considerations with Lambda SnapStart, see the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/snapstart-uniqueness.html#snapstart-scanning) and [blog](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/starting-up-faster-with-aws-lambda-snapstart/) on understanding uniqueness in VM snapshots with Lambda SnapStart."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I execute my own code before a snapshot is created or when the function is resumed from snapshot?"}, {"role": "assistant", "content": "Yes. You can implement your own software logic before creating (checkpointing) a snapshot and after restoring a snapshot using runtime hooks. To learn more, see the [Lambda SnapStart documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/snapstart-runtime-hooks.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Will I be charged for Lambda SnapStart?"}, {"role": "assistant", "content": "No. There's no additional cost for enabling Lambda SnapStart. You are charged based on the number of requests for your functions and the duration your code executes based on current [Lambda Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/). Duration charges apply to code that runs in the handler of a function and runtime hooks, as well as initialization code that is declared outside of the handler. Please note that AWS Lambda may periodically recycle execution environments with security patches and rerun your initialization code. For more details, see the [Lambda Programming Model documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/foundation-progmodel.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How long do the snapshots for the published function version stay cached with Lambda SnapStart?"}, {"role": "assistant", "content": "With Lambda SnapStart, Lambda keeps a snapshot of the initialized execution environment for the last three published function versions, as long as the published versions continue to receive invokes. The snapshot associated with a published function version expires if it remains inactive for more than 14 days."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How can I encrypt the snapshots of initialized execution environment created by Lambda SnapStart?"}, {"role": "assistant", "content": "Snapshots are encrypted be default with customer-unique AWS Key Management Service (KMS) keys owned and managed by the Lambda service. Customers can also encrypt snapshots using a [KMS key](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#customer-cmk) owned and managed by the customer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Is there a time limit for how long my code initialization can run with Lambda SnapStart?"}, {"role": "assistant", "content": "The maximum allowed initialization duration for Lambda SnapStart will match the execution timeout duration you have configured for your function. The maximum configurable execution timeout limit for a function is 15 minutes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is AWS Lambda Provisioned Concurrency?"}, {"role": "assistant", "content": "Provisioned Concurrency gives you greater control over the performance of your serverless applications. When enabled, Provisioned Concurrency keeps functions initialized and hyper-ready to respond in double-digit milliseconds."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I set up and manage Provisioned Concurrency?"}, {"role": "assistant", "content": "You can configure concurrency on your function through the AWS Management Console, the Lambda API, the AWS CLI, and AWS CloudFormation. The simplest way to benefit from Provisioned Concurrency is by using AWS Auto Scaling. You can use Application Auto Scaling to configure schedules, or have Auto Scaling automatically adjust the level of Provisioned Concurrency in real time as demand changes. To learn more about Provisioned Concurrency, [see the documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to change my code if I want to use Provisioned Concurrency?"}, {"role": "assistant", "content": "You don\u2019t need to make any changes to your code to use Provisioned Concurrency. It works seamlessly with all existing functions and runtimes. There is no change to the invocation and execution model of Lambda when using Provisioned Concurrency."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be charged for Provisioned Concurrency?"}, {"role": "assistant", "content": "Provisioned Concurrency adds a pricing dimension, of \u2018Provisioned Concurrency\u2019, for keeping functions initialized. When enabled, you pay for the amount of concurrency that you configure and for the period of time that you configure it. When your function executes while Provisioned Concurrency is configured on it, you also pay for Requests and execution Duration. To learn more about the pricing of Provisioned Concurrency,\u00a0see [AWS Lambda Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Provisioned Concurrency?"}, {"role": "assistant", "content": "Provisioned Concurrency is ideal for building latency-sensitive applications, such as web or mobile backends, synchronously invoked APIs, and interactive microservices. You can easily configure the appropriate amount of concurrency based on your application's unique demand. You can increase the amount of concurrency during times of high demand and lower it, or turn it off completely, when demand decreases."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if a function receives invocations above the configured level of Provisioned Concurrency?"}, {"role": "assistant", "content": "If the concurrency of a function reaches the configured level, subsequent invocations of the function have the latency and scale characteristics of regular Lambda functions. You can restrict your function to only scale up to the configured level. Doing so prevents the function from exceeding the configured level of Provisioned Concurrency. This is a mechanism to prevent undesired variability in your application when demand exceeds the anticipated amount."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What are AWS Lambda functions powered by Graviton2 processors?"}, {"role": "assistant", "content": "AWS Lambda allows you to run your functions on either x86-based or Arm-based processors. AWS Graviton2 processors are custom built by Amazon Web Services using 64-bit Arm Neoverse cores to deliver increased price performance for your cloud workloads. Customers get the same advantages of AWS Lambda, running code without provisioning or managing servers, automatic scaling, high availability, and only paying for the resources you consume."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Why should I use AWS Lambda functions powered by Graviton2 processors?"}, {"role": "assistant", "content": "AWS Lambda functions powered by Graviton2, using an Arm-based processor architecture designed by AWS, are designed to deliver up to 34% better price performance compared to functions running on x86 processors, for a variety of serverless workloads, such as web and mobile backends, data, and stream processing. With lower latency, up to 19% better performance, a 20% lower cost, and the highest power-efficiency currently available at AWS, Graviton2 functions can power mission critical serverless applications. Customers can configure both existing and new functions to target the Graviton2 processor. They can deploy functions running on Graviton2 as either zip files or container images."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I configure my functions to run on Graviton2 processors?"}, {"role": "assistant", "content": "You can configure functions to run on Graviton2 through the AWS Management Console, the AWS Lambda API, the AWS CLI, and AWS CloudFormation by setting the architecture flag to \u2018arm64\u2019 for your function."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I deploy my application built using functions powered by Graviton2 processors?"}, {"role": "assistant", "content": "There is no change between x86-based and Arm-based functions. Simply upload your code via the AWS Management Console, zip file, or container image, and AWS Lambda automatically runs your code when triggered, without requiring you to provision or manage infrastructure."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need an Arm-based development machine to create, build, and test functions powered by Graviton2 processors locally?"}, {"role": "assistant", "content": "Interpreted languages like Python, Java, and Node generally do not require recompilation unless your code references libraries that use architecture specific components. In those cases, you would need to provide the libraries targeted to arm64. For more details, please see the [Getting started with AWS Graviton](https://web.archive.org/web/20240727065740/https://github.com/aws/aws-graviton-getting-started) page. Non-interpreted languages will require compiling your code to target arm64. While more modern compilers will produce compiled code for arm64, you will need to deploy it into an arm-based environment to test. To learn more about using Lambda functions with Graviton2, please see the [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/foundation-arch.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can an application use both functions powered by Graviton2 processors and x86 processors?"}, {"role": "assistant", "content": "An application can contain functions running on both architectures. AWS Lambda allows you to change the architecture (\u2018x86_64\u2019 or \u2018arm64\u2019) of your function\u2019s current version. Once you create a specific version of your function, the architecture cannot be changed."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Lambda support multi-architecture container images?"}, {"role": "assistant", "content": "No. Each function version can only use a single container image."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I create AWS Lambda Layers that target functions powered by AWS Graviton2 processors?"}, {"role": "assistant", "content": "Yes. Layers and extensions can be targeted to \u2018x86_64\u2019 or \u2018arm64\u2019 compatible architectures. The default architecture for functions and layers is \u2018x86_64\u2019."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What languages and runtimes are supported by Lambda functions running on Graviton2 processors?"}, {"role": "assistant", "content": "At launch, customers can use Python, Node.js, Java, Ruby, .Net Core, Custom Runtime (provided.al2), and OCI Base images. To learn more, please see the [AWS Lambda Runtimes](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the pricing of AWS Lambda functions powered by AWS Graviton2 processors? Does the AWS Lambda free tier apply to functions powered by Graviton2?"}, {"role": "assistant", "content": "AWS Lambda functions powered by AWS Graviton2 processors are 20% cheaper compared to x86-based Lambda functions. The Lambda free tier applies to AWS Lambda functions powered by x86 and Arm-based architectures."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I choose between running my functions on Graviton2 processors or x86 processors?"}, {"role": "assistant", "content": "Each workload is unique and we recommend customers test their functions to determine the price performance improvement they might see. To do that, we recommend using the [AWS Lambda Power Tuning](https://web.archive.org/web/20240727065740/https://github.com/alexcasalboni/aws-lambda-power-tuning) tool. We recommend starting with web and mobile backends, data, and stream processing when testing your workloads for potential price performance improvements."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Amazon EFS for AWS Lambda?"}, {"role": "assistant", "content": "With Amazon Elastic File System (Amazon EFS) for AWS Lambda, customers can securely read, write and persist large volumes of data at virtually any scale using a fully managed elastic NFS file system that can scale on demand without the need for provisioning or capacity management. Previously, developers added code to their functions to download data from S3 or databases to local temporary storage, limited to 512MB. With EFS for Lambda, developers don't need to write code to download data to temporary storage in order to process it."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I set up Amazon EFS for Lambda?"}, {"role": "assistant", "content": "Developers can easily connect an existing EFS file system to a Lambda function via an [EFS Access Point](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html) by using the console, CLI, or SDK. When the function is first invoked, the file system is automatically mounted and made available to function code. You can learn more in the documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do I need to configure my function with VPC settings before I can use my Amazon EFS file system?"}, {"role": "assistant", "content": "Yes. Mount targets for Amazon EFS are associated with a subnet in a VPC. The AWS Lambda function needs to be configured to access that VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Who should use Amazon EFS for Lambda?"}, {"role": "assistant", "content": "Using EFS for Lambda is ideal for building machine learning applications or loading large reference files or models, processing or backing up large amounts of data, hosting web content, or developing internal build systems. Customers can also use EFS for Lambda to keep state between invocations within a stateful microservice architecture, in a Step Functions workflow, or sharing files between serverless applications and instance or container-based applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Will my data be encrypted in transit?"}, {"role": "assistant", "content": "Yes. Data encryption in transit uses industry-standard Transport Layer Security (TLS) 1.2 to encrypt data sent between AWS Lambda functions and the Amazon EFS file systems."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is my data encrypted at rest?"}, {"role": "assistant", "content": "Customers can provision Amazon EFS to encrypt data at rest. Data encrypted at rest is transparently encrypted while being written, and transparently decrypted while being read, so you don\u2019t have to modify your applications. Encryption keys are managed by the AWS Key Management Service (KMS), eliminating the need to build and maintain a secure key management infrastructure."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How will I be charged for Amazon EFS for AWS Lambda?"}, {"role": "assistant", "content": "There is no additional charge for using Amazon EFS for AWS Lambda. Customers pay the standard price for AWS Lambda and for Amazon EFS. When using Lambda and EFS in the same availability zone, customers are not charged for data transfer. However, if they use VPC peering for Cross-Account access, they will incur data transfer charges. To learn more, please see [Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I associate more than one Amazon EFS file system with my AWS Lambda function?"}, {"role": "assistant", "content": "No. Each Lambda function will be able to access one EFS file system."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use the same Amazon EFS file system across multiple functions, containers, and instances?"}, {"role": "assistant", "content": "Yes. Amazon EFS supports Lambda functions, ECS and Fargate containers, and EC2 instances. You can share the same file system and use IAM policy and Access Points to control what each function, container, or instance has access to."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do AWS Lambda functions support HTTP(S) endpoints?"}, {"role": "assistant", "content": "Yes. Lambda functions can be configured with a function URL, a built-in HTTPS endpoint that can be invoked using the browser, curl, and any HTTP client. Function URLs are an easy way to get started building HTTPS accessible functions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I configure a Lambda function URL for my function?"}, {"role": "assistant", "content": "You can configure a function URL for your function through the AWS Management Console, the AWS Lambda API, the AWS CLI, AWS CloudFormation, and the AWS Serverless Application Model. Function URLs can be enabled on the $LATEST unqualified version of your function, or on any function alias. To learn more about configuring a function URL, [see the documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I secure my Lambda function URL?"}, {"role": "assistant", "content": "Lambda function URLs are secured with IAM authorization by default. You can choose to disable IAM authorization to create a public endpoint or if you plan to implement custom authorization as part of the function\u2019s business logic."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I invoke my function with a Lambda function URL?"}, {"role": "assistant", "content": "You can easily invoke your function from your web browser by navigating to the Lambda URL, from your client application\u2019s code using an HTTP library, or from the command line using curl."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do Lambda function URLs work with function versions and aliases?"}, {"role": "assistant", "content": "Yes. Lambda function URLs can be enabled on a function or function alias. If no alias is specified, the URL will point to $LATEST by default. Function URLs cannot target an individual function version."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I enable custom domains for my Lambda function URL?"}, {"role": "assistant", "content": "Custom domain names are not currently supported with function URLs. You can use a custom domain with your function URL by creating an Amazon CloudFront distribution and a CNAME to map your custom domain to your CloudFront distribution name. Then, map your CloudFront distribution domain name to be routed to your function URL as an origin."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can Lambda function URLs be used to invoke a function in a VPC?"}, {"role": "assistant", "content": "Yes, function URLs can be used to invoke a Lambda function in a VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the pricing for using Lambda function URLs?"}, {"role": "assistant", "content": "There is no additional charge for using function URLs. You pay the standard price for AWS Lambda. To learn more, please see [AWS Lambda Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Lambda@Edge?"}, {"role": "assistant", "content": "[Lambda@Edge](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/edge/) allows you to run code across AWS locations globally without provisioning or managing servers, responding to end-users at the lowest network latency. You just upload your Node.js or Python code to AWS Lambda and configure your function to be triggered in response to [Amazon CloudFront](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cloudfront/) requests (i.e., when a viewer request lands, when a request is forwarded to or received back from the origin, and right before responding back to the end-user). The code is then ready to execute across AWS locations globally when a request for content is received, and scales with the volume of CloudFront requests globally. Learn more in our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I use Lambda@Edge?"}, {"role": "assistant", "content": "To use Lambda@Edge, you just upload your code to AWS Lambda and associate a function version to be triggered in response to Amazon CloudFront requests. Your code must satisfy the Lambda@Edge service limits. Lambda@Edge supports Node.js and Python for global invocation by CloudFront events at this time. Learn more in our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: When should I use Lambda@Edge?"}, {"role": "assistant", "content": "Lambda@Edge is optimized for latency-sensitive use cases where your end viewers are distributed globally. All the information you need to make a decision should be available at the CloudFront edge, within the function and the request. This means that use cases where you are looking to make decisions on how to serve content based on user characteristics (e.g., location, client device, etc.) can now be executed and served close to your users without having to be routed back to a centralized server."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I deploy my existing Lambda functions for global invocation?"}, {"role": "assistant", "content": "You can associate existing Lambda functions with CloudFront events for global invocation if the function satisfies the Lambda@Edge service requirements and limits. Read more [here](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/API_UpdateFunctionConfiguration.html) on how to update your function properties."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What Amazon CloudFront events can be used to trigger my functions?"}, {"role": "assistant", "content": "Your functions will automatically trigger in response to the following Amazon CloudFront events:Viewer Request - This event occurs when an end-user or a device on the Internet makes an HTTP(S) request to CloudFront, and the request arrives at the edge location closest to that user.Viewer Response - This event occurs when the CloudFront server at the edge is ready to respond to the end user or the device that made the request.Origin Request - This event occurs when the CloudFront edge server does not already have the requested object in its cache, and the viewer request is ready to be sent to your backend origin web server (e.g. Amazon EC2, or Application Load Balancer, or Amazon S3).Origin Response - This event occurs when the CloudFront server at the edge receives a response from your backend origin web server."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How is AWS Lambda@Edge different from using AWS Lambda behind Amazon API Gateway?"}, {"role": "assistant", "content": "The difference is that API Gateway and Lambda are regional services. Using [Lambda@Edge](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/edge/) and [Amazon CloudFront](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cloudfront/) allows you to execute logic across multiple AWS locations based on where your end viewers are located."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How available are AWS Lambda functions?"}, {"role": "assistant", "content": "AWS Lambda is designed to use replication and redundancy to provide high availability for both the service itself and for the Lambda functions it operates. There are no maintenance windows or scheduled downtimes for either."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Do my AWS Lambda functions remain available when I change my code or its configuration?"}, {"role": "assistant", "content": "Yes. When you update a Lambda function, there will be a brief window of time, typically less than a minute, when requests could be served by either the old or the new version of your function."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there a limit to the number of AWS Lambda functions I can execute at once?"}, {"role": "assistant", "content": "No. AWS Lambda is designed to run many instances of your functions in parallel. However, AWS Lambda has a default safety throttle, for the number of concurrent executions per account per region (visit [here](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html#concurrent-execution-safety-limit) for info on default safety throttle limits). You can also control the maximum concurrent executions for individual AWS Lambda functions, which you can use to reserve a subset of your account concurrency limit for critical functions, or cap traffic rates to downstream resources.  If you wish to submit a request to increase the concurrent execution limit, you can use [Service Quotas](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/servicequotas/latest/userguide/request-quota-increase.html) to request a limit increase request."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if my account exceeds the default throttle limit on concurrent executions?"}, {"role": "assistant", "content": "On exceeding the maximum concurrent executions limit, AWS Lambda functions being invoked synchronously will return a throttling error (429 error code). Lambda functions being invoked asynchronously can absorb reasonable bursts of traffic for approximately 15-30 minutes, after which incoming events will be rejected as throttled. In case the Lambda function is being invoked in response to Amazon S3 events, events rejected by AWS Lambda may be retained and retried by S3 for 24 hours. Events from Amazon Kinesis streams and Amazon DynamoDB streams are retried until the Lambda function succeeds or the data expires. Amazon Kinesis and Amazon DynamoDB Streams retain data for 24 hours."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Are default maximum concurrent execution limits applied on a per function level?"}, {"role": "assistant", "content": "The default maximum concurrent execution limit is applied at the account level. However, you can also set limits on individually functions as well (visit [here](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html) for info on Reserved Concurrency)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How quickly do my AWS Lambda functions scale?"}, {"role": "assistant", "content": "Each synchronously invoked Lambda function can scale at a rate of up to 1000 concurrent executions every 10 seconds. While Lambda's scaling rate is suitable for most use cases, it is particularly ideal for those with predictable or unpredictable bursts of traffic. For example, SLA-bound data processing would require predictable yet rapid scaling to meet processing demand. Similarly, serving breaking news articles, or flash sales could drive unpredictable levels of traffic in a short period of time. Lambda's scaling rate can facilitate such use cases without additional configurations or tooling. Additionally, the concurrency scaling limit is a function-level limit, which means each function in your account scales independently of other functions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if my Lambda function fails while processing an event?"}, {"role": "assistant", "content": "On failure, Lambda functions being invoked synchronously will respond with an exception. Lambda functions being invoked asynchronously are retried at least 3 times. Events from Amazon Kinesis streams and Amazon DynamoDB streams are retried until the Lambda function succeeds or the data expires. Kinesis and DynamoDB Streams retain data for a minimum of 24 hours."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What happens if my Lambda function invocations exhaust the available policy?"}, {"role": "assistant", "content": "On exceeding the retry policy for asynchronous invocations, you can configure a \u201cdead letter queue\u201d (DLQ) into which the event will be placed; in the absence of a configured DLQ the event may be rejected. On exceeding the retry policy for stream-based invocations, the data would have already expired and therefore rejected."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What resources can I configure as a dead letter queue for a Lambda function?"}, {"role": "assistant", "content": "You can configure an Amazon SQS queue or an Amazon SNS topic as your dead letter queue."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I allow my AWS Lambda function access to other AWS resources?"}, {"role": "assistant", "content": "You grant permissions to your Lambda function to access other resources using an IAM role. AWS Lambda assumes the role while executing your Lambda function, so you always retain full, secure control of exactly which AWS resources it can use. Visit [Setting up AWS Lambda](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/setting-up.html) to learn more about roles."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I control which Amazon S3 buckets can call which AWS Lambda functions?"}, {"role": "assistant", "content": "When you configure an Amazon S3 bucket to send messages to an AWS Lambda function, a resource policy rule will be created that grants access. Visit the [Lambda Developer Guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) to learn more about resource policies and access controls for Lambda functions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I control which Amazon DynamoDB table or Amazon Kinesis stream an AWS Lambda function can poll?"}, {"role": "assistant", "content": "Access controls are managed through the Lambda function role. The role you assign to your Lambda function also determines which resource(s) AWS Lambda can poll on its behalf. Visit the [Lambda Developer Guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q:\u00a0How do I control which Amazon SQS queue an AWS Lambda function can poll?"}, {"role": "assistant", "content": "Access controls can be managed by the Lambda function role or a resource policy setting on the queue itself.\u00a0If both policies are present, the more restrictive of the two permissions will be applied."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I access resources in Amazon VPC from my AWS Lambda function?"}, {"role": "assistant", "content": "You can enable Lambda functions to access resources in your VPC by specifying the subnet and security group as part of your function configuration. Lambda functions configured to access resources in a particular VPC will not have access to the internet as a default configuration. To grant internet to these functions, use [internet gateways](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/vpc/latest/userguide/extend-intro.html). By default, Lambda functions communicate with resources in a dual-stack VPC over IPv4. You can configure your functions to access resources in a dual-stack VPC over IPv6. For more details on Lambda functions configured with VPC, see [Lambda Private Networking with VPC](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/foundation-networking.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is Code Signing for AWS Lambda?"}, {"role": "assistant", "content": "Code Signing for AWS Lambda offers trust and integrity controls that enable you to verify that only unaltered code from approved developers is deployed in your Lambda functions. You can use [AWS Signer](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/signer/latest/developerguide/Welcome.html), a fully-managed code signing service, to digitally sign code artifacts and configure your Lambda functions to verify the signatures at deployment. Code Signing for AWS Lambda is currently only available for functions packaged as ZIP archives."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I create digitally signed code artifacts?"}, {"role": "assistant", "content": "You can create digitally signed code artifacts using a [Signing Profile](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/signer/latest/api/API_SigningProfile.html) through the AWS Signer console, the Signer API, SAM CLI or AWS CLI. To learn more, please see the [documentation for AWS Signer](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/signer/latest/api/Welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I configure my Lambda functions to enable code signing?"}, {"role": "assistant", "content": "You can enable code signing by creating a Code Signing Configuration through the AWS Management Console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM. Code Signing Configuration helps you specify the approved signing profiles and configure whether to warn or reject deployments if signature checks fail. Code Signing Configurations can be attached to individual Lambda functions to enable the code signing feature. Such functions now start verifying signatures at deployment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What signature checks does AWS Lambda perform on deployment?"}, {"role": "assistant", "content": "AWS Lambda can perform the following signature checks at deployment:\u2022 Corrupt signature - This occurs if the code artifact has been altered since signing.\u2022 Mismatched signature - This occurs if the code artifact is signed by a signing profile that is not approved.\u2022 Expired signature - This occurs if the signature is past the configured expiry date.\u2022 Revoked signature - This occurs if the signing profile owner revokes the signing jobs.To learn more, please see the [AWS Lambda documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I enable code signing for existing functions?"}, {"role": "assistant", "content": "Yes, you can enable code signing for existing functions by attaching a code signing configuration to the function. You can do this using the AWS Lambda console, the Lambda API, the AWS CLI, AWS CloudFormation, and AWS SAM."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is there any additional cost for using Code Signing for AWS Lambda?"}, {"role": "assistant", "content": "There is no additional cost when using Code Signing for AWS Lambda. You pay the standard price for AWS Lambda. To learn more, please see [Pricing](https://web.archive.org/web/20240727065740/https://aws.amazon.com/lambda/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What advanced logging controls are supported on Lambda?"}, {"role": "assistant", "content": "To provide you a simplified and enhanced logging experience by default, AWS Lambda offers advanced logging controls such as the ability to natively capture Lambda function logs in JSON structured format, control the log level filtering of Lambda function logs without making any code changes, and customize the Amazon CloudWatch log group Lambda sends logs to."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What can I use advanced logging controls for?"}, {"role": "assistant", "content": "You can capture Lambda function logs in JSON structured format without having to use your own logging libraries. JSON structured logs make it easier to search, filter, and analyze large volumes of log entries. You can control the log level filtering of Lambda function logs without making any code changes, which enables you to choose the required logging granularity level for Lambda functions without sifting through large volumes of logs when debugging and troubleshooting errors. You can also set which\u00a0[Amazon CloudWatch](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cloudwatch/)\u00a0log group Lambda sends logs to, making it easier to aggregate logs from multiple functions within an application in one place. You can then apply security, governance, and retention policies to logs at the application level rather than individually to every function."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How do I use advanced logging controls?"}, {"role": "assistant", "content": "You can specify advanced logging controls for your Lambda functions using AWS Lambda API, AWS Lambda console, AWS CLI, AWS Serverless Application Model (SAM), and AWS CloudFormation. To learn more, visit the\u00a0[launch blog post](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/)\u00a0for advanced logging controls or the\u00a0[Lambda Developer Guide](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html#monitoring-cloudwatchlogs-advanced)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. Can I use my own logging libraries to generate JSON structured logs for my Lambda function?"}, {"role": "assistant", "content": "Yes, you can use your own logging libraries to generate Lambda logs in JSON structured format. To ensure your logging libraries work seamlessly with Lambda\u2019s native JSON structured logging capability, Lambda will not double-encode any logs generated by your function that are already JSON encoded. You can also use\u00a0[Powertools for AWS Lambda](https://web.archive.org/web/20240727065740/https://github.com/aws-powertools/)\u00a0library to capture Lambda logs in JSON structured format."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q. How will I be charged for using the advanced logging controls?"}, {"role": "assistant", "content": "There is no additional charge for using advanced logging controls on Lambda. You will continue to be charged for ingestion and storage of your Lambda logs by Amazon CloudWatch Logs. See\u00a0[CloudWatch pricing page](https://web.archive.org/web/20240727065740/https://aws.amazon.com/cloudwatch/pricing/)\u00a0for log pricing details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I compile my AWS Lambda function Java code?"}, {"role": "assistant", "content": "You can use standard tools like Maven or Gradle to compile your Lambda function. Your build process should mimic the same build process you would use to compile any Java code that depends on the AWS SDK. Run your Java compiler tool on your source files and include the AWS SDK 1.9 or later with transitive dependencies on your classpath. For more details, see our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/java-lambda.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: What is the JVM environment that Lambda uses for executing my function?"}, {"role": "assistant", "content": "Lambda provides the Amazon Linux build of openjdk 1.8."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use packages with AWS Lambda?"}, {"role": "assistant", "content": "Yes. You can use NPM packages as well as custom packages. Learn more [here](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/nodejs-packages-in-lambda/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I execute other programs from within my AWS Lambda function written in Node.js?"}, {"role": "assistant", "content": "Yes. Lambda\u2019s built-in sandbox lets you run batch (\u201cshell\u201d) scripts, other language runtimes, utility routines, and executables. Learn more [here](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/running-executables-in-aws-lambda/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Is it possible to use native modules with AWS Lambda functions written in Node.js?"}, {"role": "assistant", "content": "Yes. Any statically linked native module can be included in the ZIP file you upload, as well as dynamically linked modules compiled with an rpath pointing to your Lambda function root directory. Learn more [here](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/nodejs-packages-in-lambda/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I execute binaries with AWS Lambda written in Node.js?"}, {"role": "assistant", "content": "Yes. You can use Node.js' child_process command to execute a binary that you included in your function or any executable from Amazon Linux that is visible to your function. Alternatively several NPM packages exist that wrap command line binaries such as node-ffmpeg. Learn more [here](https://web.archive.org/web/20240727065740/https://aws.amazon.com/blogs/compute/running-executables-in-aws-lambda/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I deploy AWS Lambda function code written in Node.js?"}, {"role": "assistant", "content": "To deploy a Lambda function written in Node.js, simply package your Javascript code and dependent libraries as a ZIP. You can upload the ZIP from your local environment, or specify an Amazon S3 location where the ZIP file is located. For more details, see our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/authoring-function-in-nodejs.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I use Python packages with AWS Lambda?"}, {"role": "assistant", "content": "Yes. You can use pip to install any Python packages needed."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I package and deploy an AWS Lambda function in C#?"}, {"role": "assistant", "content": "You can create a C# Lambda function using the Visual Studio IDE by selecting \"Publish to AWS Lambda\" in the Solution Explorer. Alternatively, you can directly run the \"dotnet lambda publish\" command from the dotnet CLI, which has the [# Lambda CLI tools patch] installed, which creates a ZIP of your C# source code along with all NuGet dependencies as well as your own published DLL assemblies, and automatically uploads it to AWS Lambda using the runtime parameter \u201cdotnetcore1.0\u201d"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I deploy AWS Lambda function code written in PowerShell?"}, {"role": "assistant", "content": "A PowerShell Lambda deployment package is a ZIP file that contains your PowerShell script, PowerShell modules that are required for your PowerShell script, and the assemblies needed to host PowerShell Core. You then use the AWSLambdaPSCore PowerShell module that you can install from the [PowerShell Gallery](https://web.archive.org/web/20240727065740/https://www.powershellgallery.com/packages/AWSLambdaPSCore/1.1.0.0) to create your PowerShell Lambda deployment package."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I package and deploy an AWS Lambda function in Go?"}, {"role": "assistant", "content": "Upload your Go executable artifact as a ZIP file through the AWS CLI or Lambda console and select the go1.x runtime. With Lambda, you can use Go's native tools to build and package your code. For more details, read our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/go-programming-model.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I deploy AWS Lambda function code written in Ruby?"}, {"role": "assistant", "content": "To deploy a Lambda function written in Ruby, package your Ruby code and gems as a ZIP. You can upload the ZIP from your local environment, or specify an Amazon S3 location where the ZIP file is located."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Which versions of Amazon Linux, Node.js, Python, JDK, .NET Core, SDKs, and additional libraries does AWS Lambda support?"}, {"role": "assistant", "content": "You can view the list of supported versions [here](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Can I change the version of Amazon Linux or any language runtime?"}, {"role": "assistant", "content": "No. AWS Lambda offers a single version of the operating system and managed language runtime to all users of the service. You can [bring your own language runtime](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/lambda/latest/dg/runtimes-custom.html) to use in Lambda."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How can I record and audit calls made to the AWS Lambda API?"}, {"role": "assistant", "content": "AWS Lambda is integrated with AWS CloudTrail. AWS CloudTrail can record and deliver log files to your Amazon S3 bucket describing the API usage of your account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: How do I coordinate calls between multiple Lambda functions?"}, {"role": "assistant", "content": "You can use Amazon Step Functions to coordinate multiple invoking Lambda functions. You can invoke multiple Lambda functions serially, passing the output of one to the other, or in parallel. See our [documentation](https://web.archive.org/web/20240727065740/https://docs.aws.amazon.com/step-functions/latest/dg/hello-lambda.html) for more details."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Q: Does AWS Lambda support Advanced Vector Extensions 2 (AVX2)?"}, {"role": "assistant", "content": "Yes, AWS Lambda supports the Advanced Vector Extensions 2 (AVX2) instruction set. To learn more about how to compile your application code to target this instruction set for improved performance, visit the\u00a0AWS Lambda developer documentation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is Amazon Lightsail?"}, {"role": "assistant", "content": "Amazon Lightsail is a virtual private server (VPS) provider and is the easiest way to get started with AWS for developers, small businesses, students, and other users who need a solution to build and host their applications on cloud. Lightsail provides developers compute, storage, and networking capacity and capabilities to deploy and manage websites and web applications in the cloud. Lightsail includes everything you need to launch your project quickly \u2013 virtual machines, containers, databases, CDN, load balancers, DNS management etc. \u2013 for a low, predictable monthly price."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Virtual Private Server?"}, {"role": "assistant", "content": "A virtual private server, also known as an \"instance\", allows users to run websites and web applications in a highly secure and available environment, while being cost effective."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the benefits of a VPS?"}, {"role": "assistant", "content": "There are many benefits to using a virtual private server, including affordability, scalability, security, and customizable resources."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail?"}, {"role": "assistant", "content": "You can choose among several preconfigured VPS plans that include everything you need to easily deploy and manage your application. Lightsail is best suited for projects that require a few virtual private servers and users who prefer a simple management interface. Common use cases for Lightsail include running websites, web applications, blogs, e-commerce sites, simple software, and more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Lightsail instance plan?"}, {"role": "assistant", "content": "Also referred to as a bundle, a Lightsail plan includes a virtual private server with a fixed amount of memory (RAM) and compute (vCPUs), SSD-based storage (disks), and a data transfer allowance. Lightsail plans also offer static IP addresses (5 per account) and DNS management (6 domain zones per account). Lightsail plans are charged on an hourly, on-demand basis, so you only pay for a plan when you're using it."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Are Lightsail plans the same across AWS Regions?"}, {"role": "assistant", "content": "As Lightsail expands its availability across more Regions, we\u2019re evolving our infrastructure to provide a better overall customer experience. As a result, plans in certain Regions will have different specifications, such as an additional vCPU, compared to plans in other Regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a Lightsail instance?"}, {"role": "assistant", "content": "A Lightsail instance is a virtual private server (VPS) that lives in the AWS Cloud. Use your Lightsail instances to store your data, run your code, and build web-based applications or websites. Your instances can connect to each other and to other AWS resources through both public (Internet) and private (VPC) networking. You can create, manage, and connect easily to instances right from the Lightsail console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What software can I run on my instance?"}, {"role": "assistant", "content": "Lightsail offers a range of operating system and application templates that are automatically installed when you create a new Lightsail instance. Application templates include WordPress, Drupal, Joomla!, Ghost, Magento, Redmine, LAMP, Nginx (LEMP), MEAN, Node.js, Django, and more.You can install additional software on your instances by using the in-browser SSH or your own SSH client."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I create a Lightsail instance?"}, {"role": "assistant", "content": "After logging in to Lightsail, you can use the Lightsail [console](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/webapp?fid=3BE5EA8FA64943AD-0284EED1954F5F15), command line interface (CLI), or API to create and manage instances.The first time you log in to the console, choose Create Instance. The create instance page is where you can choose the software, location, and name for your instance. Once you choose Create, your new instance will spin up automatically within minutes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Lightsail offer an API?"}, {"role": "assistant", "content": "Yes. Everything you do in the Lightsail console is backed by a publicly available API. Learn how to install and use the Lightsail [CLI](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/cli/latest/reference/lightsail/index.html?fid=3BE5EA8FA64943AD-0284EED1954F5F15) and [API](https://web.archive.org/web/20240727061427/http://docs.aws.amazon.com/lightsail/2016-11-28/api-reference/Welcome.html?fid=3BE5EA8FA64943AD-0284EED1954F5F15)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I sign up for Lightsail?"}, {"role": "assistant", "content": "To start using Lightsail, choose [Get Started](https://web.archive.org/web/20240727061427/https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?client=lightsail&fid=3BE5EA8FA64943AD-0284EED1954F5F15) and log in. You use your Amazon Web Services account to access Lightsail; if you don't already have one, you'll be prompted to create one."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do Lightsail instances perform?"}, {"role": "assistant", "content": "Lightsail instances are specifically engineered by AWS for web servers, developer environments, and small database use cases. Such workloads don't use the full CPU often or consistently, but occasionally need a performance burst. Lightsail uses burstable performance instances that provide a baseline level of CPU performance with the additional ability to burst above the baseline. This design enables you to get the performance you need, when you need it, while protecting you from the variable performance or other common side effects that you might typically experience from over-subscription in other environments. For more information on burstable performance, go [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-frequently-asked-questions-faq).If you need highly configurable environments and instances with consistently high CPU performance for applications such as video encoding or HPC applications, we recommend you use [Amazon EC2](https://web.archive.org/web/20240727061427/https://aws.amazon.com/ec2/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I connect to a Lightsail instance?"}, {"role": "assistant", "content": "Lightsail offers a 1-click secure connection to your instance's terminal right from your browser, supporting SSH access for Linux/Unix-based instances and RDP access for Windows-based instances. To use 1-click connections, launch your instance management screens, click\u00a0Connect using SSH\u00a0or\u00a0Connect using RDP, and a new browser window opens and automatically connects to your instance.If you prefer to connect to your Linux/Unix-based instance using your own client, Lightsail will do the SSH key storing and management work for you, and provide you with a secure key to use in your SSH client."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I use IPs in Lightsail?"}, {"role": "assistant", "content": "Each Lightsail instance automatically gets a private IP address and a public IP address. You can use the private IP to transmit data between Lightsail instances and AWS resources privately, for free. You can use the public IP to connect to your instance from the Internet, such as through a registered domain name or through an SSH or RDP connection from your local computer. You can also attach a static IP to the instance, which substitutes the public IP with an IP address that doesn't change even if the instance is stopped and started."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a static IP?"}, {"role": "assistant", "content": "A [static IP](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-static-ip-addresses-in-amazon-lightsail?fid=3BE5EA8FA64943AD-0284EED1954F5F15) is a fixed, public IP that is dedicated to your Lightsail account. You can assign a static IP to an instance, replacing its public IP. If you decide to replace your instance with another one, you can reassign the static IP to the new instance. In this way, you don't have to reconfigure any external systems (like DNS records) to point to a new IP every time you want to replace your instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are DNS records?"}, {"role": "assistant", "content": "DNS is a globally distributed service that translates human readable names like www.example.com into numeric IP addresses, like 192.0.2.1 that computers use to connect to each other. With Lightsail, you can easily map your registered domain names such as photos.example.com to the public IPs of your Lightsail instances. In this way, when users type human readable names like example.com into their browsers, Lightsail automatically translates the address into the IP of the instance you want to direct your users to. Each of these translations is referred to as a DNS query.It's important to know that in order to use a domain in Lightsail, you must first register it. You can register new domains using [domain support features on Lightsail](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-domain-registration), [Amazon Route 53](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-register.html?fid=3BE5EA8FA64943AD-0284EED1954F5F15), or your preferred DNS registrar."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I manage firewall settings for my instance?"}, {"role": "assistant", "content": "Yes. You can control the data traffic for your instances by using the Lightsail firewall. From the Lightsail console, you can set rules about which ports of your instance are publicly accessible for different types of traffic."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are snapshots?"}, {"role": "assistant", "content": "Snapshots are point-in-time backups of instances, databases, or block storage disks. You can create a snapshot of your resources at any time, or you can enable automatic snapshots on instances and disks to have Lightsail create snapshots for you. You can use snapshots as baselines to create new resources or to back up your data. A snapshot contains all of the data that is needed to restore your resource (from the moment when the snapshot was taken). When you restore a resource by creating it from a snapshot, the new resource begins as an exact replica of the original resource that was used to create the snapshot.You can manually take snapshots of your Lightsail instances, disks, and databases, or you can use [automatic snapshots](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-configuring-automatic-snapshots)\u00a0to instruct Lightsail to take daily snapshots of your instances and disks automatically. For more information, see [Snapshots in Amazon Lightsail](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/understanding-instance-snapshots-in-amazon-lightsail)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are automatic snapshots?"}, {"role": "assistant", "content": "Automatic snapshots are a way to schedule daily snapshots of your Linux/Unix instances in Amazon Lightsail. You can pick a time of the day, and Lightsail will automatically take a snapshot for you each day at the time you chose and always keep your seven most recent automatic snapshots. Enabling snapshots is free \u2013 you only pay for the actual storage used by your snapshots."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the differences between manual snapshots and automatic snapshots?"}, {"role": "assistant", "content": "Automatic snapshots cannot be tagged or exported directly to Amazon EC2. However, automatic snapshots can be copied and converted into manual snapshots. To copy an automatic snapshot into a manual one, choose Keep from the automatic snapshot\u2019s context menu to copy it as a manual snapshot."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I back up my instances?"}, {"role": "assistant", "content": "If you want to back up your data, you can use the Lightsail console or API to take a [snapshot](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/overview/article/understanding-instance-snapshots-in-amazon-lightsail?fid=3BE5EA8FA64943AD-0284EED1954F5F15) of your instance. If there is a failure or bad code deployment, you can later use your instance snapshot to create a brand new instance. We recommend stopping your instance temporarily when taking a snapshot, to ensure your data is complete and not corrupted in any way."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the difference between stopping and deleting my instance?"}, {"role": "assistant", "content": "When you stop your instance, it is powered down at its current state and is available for you to start again at any time. Stopping your instance will release its public IP, so it is recommended that you use static IPs for instances that must retain the same IP after they stop.When you delete your instance, you are performing a destructive action. Unless you have taken an instance snapshot, all of your instance data will be lost and you cannot recover it again. The instance's public and private IPs will also be released. If you were using a static IP with that instance, the static IP is detached, but remains in your account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I upgrade my plan?"}, {"role": "assistant", "content": "Yes. You can take a snapshot of your instance, and use the API to launch a new, larger size instance. You can launch new instances from snapshot using the Lightsail console or the CLI. Find instructions on how to use the CLI [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/how-to/article/lightsail-how-to-create-larger-instance-from-snapshot-using-aws-cli?fid=3BE5EA8FA64943AD-0284EED1954F5F15)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I connect Lightsail instances to other resources in my AWS account?"}, {"role": "assistant", "content": "You can connect your Lightsail instances to VPC resources in your AWS account privately, by using VPC peering. Just choose Enable VPC peering on your Lightsail account page, and Lightsail does the work for you. Once VPC peering is enabled, you can address other AWS resources in your default AWS VPC by using their private IPs. Find instructions [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/how-to/article/lightsail-how-to-set-up-vpc-peering-with-aws-resources?fid=3BE5EA8FA64943AD-0284EED1954F5F15).Note that you need to have a default VPC set up in your AWS account in order for VPC peering with Lightsail to work. AWS accounts created before December 2013 do not have a default VPC, and you will need to set one up. Find out more about setting up your default VPC [here](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/default-vpc.html?fid=3BE5EA8FA64943AD-0284EED1954F5F15)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "In which regions is Lightsail available?"}, {"role": "assistant", "content": "Lightsail is currently available in all the Availability Zones in the following AWS Regions:US East (N. Virginia)US East (Ohio)US West (Oregon)Canada (Central)Europe (Frankfurt)Europe (Ireland)Europe (London)Europe (Paris)Europe (Stockholm)Asia Pacific (Mumbai)Asia Pacific (Singapore)Asia Pacific (Sydney)Asia Pacific (Tokyo)Asia Pacific (Seoul)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are Availability Zones?"}, {"role": "assistant", "content": "Availability Zones are collections of data centers that run on physically distinct, independent infrastructure and are engineered to be highly reliable. Common points of failure such as generators and cooling equipment are not shared between Availability Zones. Additionally, Availability Zones are physically separate, so that even extremely uncommon disasters such as fires, tornados, or flooding can affect only a single Availability Zone."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the Lightsail service quotas?"}, {"role": "assistant", "content": "For the latest Lightsail service quotas, including which quotas can be increased, see the [Lightsail service quotas](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/general/latest/gr/lightsail.html) in the AWS General Reference. If you need to increase a quota, please open a case with [customer service](https://web.archive.org/web/20240727061427/https://console.aws.amazon.com/support/home?region=us-east-1)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I get more help?"}, {"role": "assistant", "content": "We're here for you. Quick Assist in Lightsail offers immediate helpful tips about your actions in the console. From the Lightsail console, you can also access a library of getting started guides, overviews, and how-to topics. And if you want to use the API or CLI, Lightsail has a full API reference for all supported programming languages. You can also use Lightsail support resources:If you have an issue with your account or billing, contact\u00a0[customer service](https://web.archive.org/web/20240727061427/https://console.aws.amazon.com/support/home?region=us-east-1#/&fid=3BE5EA8FA64943AD-0284EED1954F5F15)\u00a0online. You get free 24x7 access with your Lightsail account.If you have a general question about how to use Lightsail, search the\u00a0[Lightsail documentation](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/all?fid=3BE5EA8FA64943AD-0284EED1954F5F15)\u00a0and\u00a0[support forums](https://web.archive.org/web/20240727061427/https://forums.aws.amazon.com/forum.jspa?forumID=231&start=0&fid=3BE5EA8FA64943AD-0284EED1954F5F15).Additionally, AWS Support offers an array of paid plans to cover your individual needs."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What operating systems can I use with Amazon Lightsail?"}, {"role": "assistant", "content": "Lightsail currently supports 6 Linux or Unix-like distributions \u2013 Amazon Linux, Debian, FreeBSD, OpenSUSE, and Ubuntu \u2013 and 3 Windows Server versions \u2013 2012 R2, 2016, and 2019."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are tags?"}, {"role": "assistant", "content": "A tag is a label that you assign to a Lightsail resource. Each tag consists of a key and a value, both of which you define. A tag value is optional, so you can choose to create \u201ckey-only\u201d tags for filtering resources in the Lightsail console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I use tags to do in Lightsail?"}, {"role": "assistant", "content": "Tags have multiple use cases - they enable you to group and filter your resources in the Lightsail console and API, track and organize your costs in your bill, and regulate who can see or modify your resources through access management rules. By tagging your resources you can:Organize - use the Lightsail console and API filters to view and manage resources based on their tags you have assigned them. This is useful when you have many resources of the same type\u2014you can quickly identify a specific resource based on the tags you've assigned to it.Cost-allocate - track and allocate costs across different projects or users by tagging your resources and creating \u201ccost allocation tags\u201d in the billing console. For instance, you can split out your bill and understand your costs by project or by client.Manage access - control how users with access to your AWS account can edit, create, and delete Lightsail resources by using AWS Identity and Access Management policies. This allows you to more easily collaborate with others without needing to give them full access to your Lightsail resources.[Learn more about using tags in Lightsail >>](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en/articles/amazon-lightsail-tags/?lsm=docs)"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What resources can be tagged?"}, {"role": "assistant", "content": "Lightsail current supports tagging for the following resources:Instances (Linux and Windows)Container servicesBlock storage disksLoad balancersDatabasesDNS zonesInstance, disk, and database snapshotsManual snapshots also support tags and are automatically given the same tags as the source resource. You can edit these tags when you use a snapshot to create a new instance, disk, or database."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I tag my Lightsail snapshots?"}, {"role": "assistant", "content": "The Lightsail console automatically tags manual snapshots with the same tags as its parent resource. However, tags are not automatically copied over from a resource to its automatic snapshots. If you use the Lightsail API to create a snapshot, you can choose the tags for the snapshot yourself.Important:\u00a0Database snapshots tags are not currently included in billing reports (cost allocation tags)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the difference between key-value and key-only Tags?"}, {"role": "assistant", "content": "Lightsail tags are key-value pairs, allowing you to organize resources such as instances across different categories, e.g. project:Blog, project:Game, project:Test. This allows you full control across all use cases such as resource organization, bill reporting, and access management. The Lightsail console also allows you to tag your resources with key-only tags for quick filtering in the console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Amazon Lightsail support monitoring and alerting?"}, {"role": "assistant", "content": "Yes. With Amazon Lightsail you can collect metrics on various resources, including instances, load balancers and databases. For any individual resource you can setup to two alarms thresholds for each metric. If the alarm threshold is breached you will receive a notification in the Lightsail console, and, optionally, you can choose to receive an email message and/or SMS message. There is no additional charge for the alerting and monitoring feature in Lightsail, however, you may incur charges from your mobile carrier for SMS messaging."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is Lightsail's free tier?"}, {"role": "assistant", "content": "For a limited time, Lightsail is extending its free tier to include three months free on select bundles. The offer applies to new or existing AWS accounts who started Lightsail usage on or after 7/8/2021. Offer only applies to one bundle per account. Standard charges apply after first 750 hours of usage of the selected bundle each month. Check out the [pricing page](https://web.archive.org/web/20240727061427/https://aws.amazon.com/lightsail/pricing/) to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do Lightsail plans cost?"}, {"role": "assistant", "content": "Lightsail plans are billed on an on-demand hourly rate, so you pay only for what you use. For every Lightsail plan you use, we charge you the fixed hourly price, up to the maximum monthly plan cost. The least expensive Lightsail plan starts at $0.0047 USD/hour ($3.50 USD/month). Lightsail plans that include a Windows Server license start at $0.01075 USD/hour ($8 USD/month)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "When am I getting charged for a plan?"}, {"role": "assistant", "content": "Your Lightsail instances are charged only when they're in the running or stopped state. If you delete your Lightsail instance before the end of the month, we only charge you a prorated cost, based on the total number of hours that you used your Lightsail instance. For example, if you use the least expensive Lightsail plan for 100 hours in a month, you will be charged 47 cents (100*0.0047)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do Lightsail static IPs cost?"}, {"role": "assistant", "content": "Static IPs are not charged extra when attached to a Lightsail instance. Static IPs cannot be attached to IPv6-only instances. IPv4 addresses are a scarce resource and Lightsail is committed to helping to use them efficiently, so we charge a small $0.005 USD/hour fee for static IPs not attached to an instance for more than 1 hour."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does data transfer cost?"}, {"role": "assistant", "content": "Your plan includes a free data transfer allowance. Both data transfer in and data transfer out of your instance count toward your data transfer allowance. For Lightsail content delivery network (CDN) distributions, only data transfer out of your distribution counts toward your allowance.  If you exceed your data transfer allowance, you will only get charged for data transfer OUT from a Lightsail instance to the Internet or to AWS resources using the public IP address of the instance. This additional charge for data transfer beyond allowance is also payable for resources that are within their free trial period. Both data transfer IN to Lightsail instances and data transfer OUT from a Lightsail instance when using the instance\u2019s private IP address are free beyond your data transfer allowance. For Lightsail CDN distributions, all data transfer out of your distribution will incur a charge once you exceed your distribution data transfer allowance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is my data transfer plan allowance?"}, {"role": "assistant", "content": "Every single Lightsail plan also includes a healthy amount of free IN and OUT data transfer. For example, using the cheapest Lightsail instance bundle you can send and receive up to 1 TB of data to the Internet within the month, at no extra charge."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does my data transfer allowance work for instances?"}, {"role": "assistant", "content": "Every Lightsail instance plan includes a data transfer allowance. Both data transfer IN and data transfer OUT of your instance count toward your data transfer allowance. If you exceed your data transfer allowance, you will only be charged for the excess data transfer OUT from a Lightsail instance to the Internet or to AWS resources using the public IP address of the instance. You will not be charged for the excess data transfer IN to your Lightsail instance (see Example 1). Your data transfer allowance resets every month, and your instance can consume it whenever it needs to within the month. Data transfer allowance is aggregated for instances of the same bundle (i.e. [bundleId](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/lightsail/2016-11-28/api-reference/API_Bundle.html)) in a region (see Examples 2 and 3). Data transfer allowance is also aggregated for IPv4 and IPv6 instances of the same size (see Example 4). Deleting an instance and creating a new instance does not reset the data transfer allowance (see Example 5).  Example 1: Assume you have one $5/month instance bundle (or bundleId \u2018nano_3_0\u2019) with 1TB/month data transfer allowance. If you send 500GB of data to the Internet (data transfer OUT) and 400GB of data to the instance (data transfer IN), you will have consumed 900GB of your 1TB allowance. If you further send 200GB of data to the Internet, you will exceed your allowance by 100GB, and will be charged a data transfer OUT overage fee for 100GB. If you next send 200GB of data to the instance, you will not be charged for overage.  Example 2: If you have two $5/month instance bundles (or bundleId \u2018nano_3_0\u2019) for a full month in a region, each with 1TB/month data transfer allowance, you get 2TB data transfer allowance in aggregate. If you send 1.5TB of data to the Internet with the first instance and 100 GB of data to the Internet with the second instance, you will still be 400GB under your total allowance of 2TB, and you will not be charged any data transfer OUT overage fees.  Example 3: You create two sets of instance bundles: set A with two $5/month instance bundles (bundleId \u2018nano_3_0\u2019) and set B with three $7/month instance bundles (bundleId \u2018micro_3_0\u2019), both in US West (Oregon) Region. In aggregate, this gives you 2TB of data transfer allowance for set A, and 6TB of data transfer allowance for set B. If you transfer 3TB of data to the Internet through set A instances and 4TB of data to the Internet through Set B instances, you will exceed your data transfer allowance for Set A instances and will be charged a data transfer OUT overage fee for 1TB. You will still be within your allowance for Set B instances by 2TB.Example 4: Assume you have consumed 600GB of the total 1TB data transfer allowance for your $3.5/month IPv6 instance bundle (bundleId \u2018nano_ipv6_3_0\u2019) within the first 20 days of the billing month. You decide to switch the networking type of your instance to dual-stack (bundleId \u2018nano_3_0\u2019 charged at $5/month price) on the 21st day. Your data transfer utilization for the month will not reset, and will remain at 600GB, with 400GB allowance left. During the remainder of the billing month, if you send 500GB of data to the Internet, you will accrue data transfer OUT overage charges for 100GB.Example 5: You have three $5/month instance bundles (bundleId \u2018nano_3_0\u2019), each with 1TB/month data transfer allowance. Assume you have consumed 1TB of the total 3TB data transfer allowance within the billing month, which leaves you with 2TB of remaining data transfer allowance. If you delete all your instances, and create three new instances of the same bundle (bundleId \u2018nano_3_0\u2019) in the same region within the same billing month, your data transfer utilization will still be 1TB and remaining data transfer allowance will still be 2TB. You can transfer 2TB more data through your instances within the same month before you start accruing any data transfer OUT overage charges."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What if I exceed my data transfer plan allowance?"}, {"role": "assistant", "content": "We have designed our data transfer plans so that the vast majority of our customers will be fully covered by their allowance and not incur any additional charges. Even if you exceed your data instance transfer allowance, some types of data transfer are free. Data transfer IN to Lightsail instances is always free. Data transfer OUT from a Lightsail instance to another Lightsail instance or AWS resource in the same Region is also free if private IP addresses are used."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What types of data transfer do I get charged for?"}, {"role": "assistant", "content": "When you exceed the monthly free data transfer allowance of your instance plan, you will get charged for data transfer OUT from a Lightsail instance to the Internet or to another AWS Region or to AWS resources in the same Region when using public IP addresses. The charge for these types of data transfer above the free allowance is as follows:US East (N. Virginia): $0.09 USD/GBUS East (Ohio): $0.09 USD/GBUS West (Oregon): $0.09 USD/GBCanada (Central): $0.09 USD/GBEurope (Frankfurt): $0.09 USD/GBEurope (Ireland): $0.09 USD/GBEurope (London): $0.09 USD/GBEurope (Paris): $0.09 USD/GBEurope (Stockholm): $0.09 USD/GBAsia Pacific (Mumbai): $0.13 USD/GBAsia Pacific (Singapore): $0.12 USD/GBAsia Pacific (Sydney): $0.17 USD/GBAsia Pacific (Tokyo): $0.14 USD/GBAsia Pacific (Seoul): $0.13 USD/GBInstances created in different Availability Zones can communicate between zones privately and for free, and are much less likely to be impaired concurrently. Availability Zones enable you to build highly available applications and websites without increasing the cost of data transfer or compromising your application's security.When you exceed the data transfer allowance of your Lightsail CDN distribution plan, you are charged for all data transfer OUT. The charge for data transfer above your distribution\u2019s allowance is different from Lightsail instances and is as follows:Asia Pacific: $0.13 USD/GBAustralia: $0.17 USD/GBCanada: $0.09 USD/GBEurope: $0.09 USD/GBIndia: $0.13 USD/GBJapan: $0.14 USD/GBMiddle East: $0.11 USD/GBSouth Africa: $0.11 USD/GBSouth America: $0.11 USD/GBUnited States: $0.09 USD/GB"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do my instance data transfer plan allowances vary by Region?"}, {"role": "assistant", "content": "All AWS Regions have the same data transfer plan allowance as listed on amazonlightsail.com and amazonlightsail.com/pricing, with the exception of the Asia Pacific (Mumbai) and the Asia Pacific (Sydney) Regions. In these two AWS Regions, the data transfer plan allowance is as follows:512 MB plan: 500 GB1 GB plan: 1 TB2 GB plan: 1.5 TB4 GB plan: 2 TB8 GB plan: 2.5 TB16 GB plan: 3 TB32 GB plan: 3.5 TB"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does my data transfer allowance work with my load balancers?"}, {"role": "assistant", "content": "Your load balancer does not consume your data transfer allowance. Traffic between the load balancer and the target instances or distributions is metered and counts toward your data transfer allowance for your instances or distributions, in the same way that traffic in from and out to the internet is counted toward your data transfer allowance for Lightsail instances that are not behind a load balancer. Traffic into and out of your load balancer to the internet is not calculated toward the data transfer allowance for your instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does Lightsail DNS management cost?"}, {"role": "assistant", "content": "DNS management is free within Lightsail. You can create up to 6 DNS zones and as many records as you want for each DNS zone. You also get a monthly allowance of 3 million DNS queries per month to your zones. Beyond your first 3 million queries in a month, you are charged $0.40 USD/million DNS queries."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do Lightsail snapshots cost?"}, {"role": "assistant", "content": "Lightsail snapshots cost $0.05 USD/GB-month for both instance snapshots and for disk snapshots. This means if you take a snapshot of your 30 GB SSD instance and keep it for a month, you pay $1.50 USD at the end of the month.When you take multiple successive snapshots of the same instance, Lightsail automatically cost-optimizes your snapshots. For each new snapshot you take, you're charged only for the part of the instance that changed. In the example above, if your instance only changes by 2 GB, your second instance snapshot costs only $0.10 USD per month."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does Lightsail block storage cost?"}, {"role": "assistant", "content": "Lightsail Block storage costs $0.10 USD per GB per month."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do Lightsail load balancers cost?"}, {"role": "assistant", "content": "Lightsail load balancers cost $18 per month."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does certificate management cost?"}, {"role": "assistant", "content": "Lightsail certificates and certificate management are free with use of a Lightsail load balancer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I try Lightsail for free?"}, {"role": "assistant", "content": "Yes! For a limited time new Amazon Lightsail customers get up to three months free on select bundles. This offer only applies to new accounts created after 7/8/21. See the [pricing page](https://web.archive.org/web/20240727061427/https://aws.amazon.com/lightsail/pricing/) for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I manage my AWS account?"}, {"role": "assistant", "content": "Lightsail is an AWS service and runs on the AWS trusted and proven cloud infrastructure. You use the same AWS account and credentials to log in to Lightsail and the AWS Management Console.You can manage your AWS account, including changing your AWS account password, user name, contact information, or billing information from the [AWS Billing and Cost Management console](https://web.archive.org/web/20240727061427/https://console.aws.amazon.com/billing/home?fid=3BE5EA8FA64943AD-0284EED1954F5F15)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the Lightsail legal terms of use?"}, {"role": "assistant", "content": "Lightsail is an Amazon web service, so to use Lightsail, you first agree to the [AWS Customer Agreement and Service Terms](https://web.archive.org/web/20240727061427/https://aws.amazon.com/legal/?fid=3BE5EA8FA64943AD-0284EED1954F5F15). When creating Lightsail instances, you also agree that your use of software is also subject to the end user license agreement of the seller, available for your review on the create instance page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I pay my Lightsail bill?"}, {"role": "assistant", "content": "You can pay and manage your bill through the AWS Billing and Cost Management console. AWS accepts most major credit cards. Learn more about [managing your payment methods](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/manage-payments.html?fid=3BE5EA8FA64943AD-0284EED1954F5F15)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail for Research?"}, {"role": "assistant", "content": "Lightsail for Research makes it easy for you to create powerful virtual computers on the cloud with your preferred applications like Scilab, RStudio, and Jupyter pre-installed. You can access the applications running on these virtual computers and upload or download data directly through a web browser from anywhere via internet. You can create and terminate these virtual computers at any time, meaning you can access virtual computers on-demand while paying only for the duration you use the virtual computers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What applications are pre-installed for my research needs?"}, {"role": "assistant", "content": "Lightsail offers popular pre-installed applications such as Scilab, RStudio, and Jupyter.\u00a0Learn about all pre-installed applications available in [Lightsail for Research documentation](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/lightsail-for-research/latest/ug/blueprints-plans.html). You can also install additional packages and extensions through the interface of these applications. Moreover, you have access to the underlying virtual computer and can configure the environment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What resources are included in a Lightsail for Research bundle?"}, {"role": "assistant", "content": "A Lightsail for Research bundle (virtual computer) includes a virtual private server with a fixed amount of memory (RAM) and compute (vCPUs), SSD-based storage (disks), and a data transfer allowance. Lightsail features such as block storage, instance and disk snapshots, SSH access, remote desktop access (using NICE DCV), and APIs can be used with Lightsail for Research virtual computers. Lightsail features such as static IPs, DNS management, object storage, load balancers, containers, databases, and CDN distributions are not applicable and cannot be used with Lightsail for Research virtual computers."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What type of virtual computers does Lightsail offer?"}, {"role": "assistant", "content": "Lightsail for Research offers two types of virtual computers: non-GPU and GPU. For researchers who are using applications or analyzing data that do not need a GPU, we recommend using the non-GPU virtual computer. For researchers who are using analytical techniques like neural networks or are running advanced simulations, we recommend the GPU virtual computer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail block storage?"}, {"role": "assistant", "content": "Lightsail block storage provides additional storage volumes (called \u201cattached disks\u201d in Lightsail) that you can attach to your Lightsail instance, similar to an individual hard drive. Attached disks are useful for applications or software that need to separate out specific data from their core service and to protect application data in case of a failure or other issue with your instance and system disk. Attached disks offer consistent performance and low latency needed for applications or software that frequently access their stored data.Lightsail block storage uses solid-state drives (SSD). This type of block storage balances a low price and good performance and is intended to support the vast majority of workloads that run on Lightsail. For customers with applications that require sustained IOPS performance, high amounts of throughput per disk, or that are running large databases like MongoDB, Cassandra, etc., we recommend using EC2 with GP2 or Provisioned IOPS SSD storage instead of Lightsail."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How large can I make my attached disk?"}, {"role": "assistant", "content": "Each attached disk can be up to 16 TB."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How many disks can I attach per Lightsail instance?"}, {"role": "assistant", "content": "You can attach up to 15 disks per Lightsail instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I attach a disk to more than 1 instance?"}, {"role": "assistant", "content": "No, disks can only be attached to one instance at a time."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does my disk need to be attached to an instance?"}, {"role": "assistant", "content": "No, you can choose not to attach a disk to an instance. The disk will remain in your account in an unattached state. There is no difference in price if your disk is not attached to an instance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I increase the size of my attached disk?"}, {"role": "assistant", "content": "Yes, you can increase the size of a disk by taking a disk snapshot and then creating a new, larger disk from snapshot."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Lightsail block storage offer encryption?"}, {"role": "assistant", "content": "Yes, to help keep your data secure, all Lightsail attached disks and disk snapshots are encrypted at rest by default, using keys that Lightsail manages on your behalf. Lightsail also provides encryption of data as it moves between Lightsail instances and attached disks."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What availability can I expect from Lightsail block storage?"}, {"role": "assistant", "content": "Lightsail block storage is designed to be highly available and reliable. Each attached disk is automatically replicated within its Availability Zone to protect you from component failure. Although Lightsail does not guarantee SLAs, Lightsail block storage disks are designed for 99.99% availability and for an annual failure rate of less than 0.2%. Lightsail also supports disk snapshots to allow regular backups of your data."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I back up my attached disk?"}, {"role": "assistant", "content": "You can back up your disk by taking a disk snapshot. You can also backup your entire instance and any attached disks by taking an instance snapshot."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How are attached disks different than the storage included in my Lightsail plan?"}, {"role": "assistant", "content": "The system disk included with your Lightsail plan is your instance\u2019s root device. If you terminate your instance, the system disk will be deleted as well. If you experience an instance failure, the system disk could be impacted. You also cannot detach your system disk or back it up separately from your instance. Data stored on an attached disk persists independently of the instance. Attached disks can be detached and moved between instances and can be backed up independently from an instance using disk snapshot. To protect your data, we recommend that you use your Lightsail instance\u2019s system disk only for temporary data. For data requiring a higher level of durability, we recommend using attached disks and regularly backing up your disk using disk or instance snapshots."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail load balancers?"}, {"role": "assistant", "content": "Lightsail load balancers allow you to build highly available websites and applications. By distributing traffic across instances in different Availability Zones and pointing traffic to only healthy target instances, Lightsail load balancers reduce the risk of your application going down due to an issue with your instance or to a datacenter outage. With Lightsail load balancers and multiple target instances, your website or application can also accommodate increases in web traffic and maintain good performance for your visitors during peak load times.In addition, you can use Lightsail load balancers to build secure applications and accept HTTPS traffic. Lightsail takes the complexity out of requesting, provisioning, and maintaining SSL/TLS certificates. The built-in certificate management requests and renews certificates on your behalf and adds the certificate to your load balancer automatically."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use load balancers with instances in different AWS Regions or different Availability Zones?"}, {"role": "assistant", "content": "You cannot use load balancers with instances running in different AWS Regions. You can, however, use target instances across different Availability Zones with your load balancer. In fact, we recommend that you distribute your target instances across Availability Zones to maximize the availability of your application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does my Lightsail load balancer deal with traffic spikes?"}, {"role": "assistant", "content": "Lightsail load balancers scale automatically to handle traffic spikes to your application without you having to manually adjust them. If your application experiences a transient spike in traffic, your Lightsail load balancer will automatically scale and continue to efficiently direct traffic to your Lightsail instances. While your Lightsail load balancer is designed to easily manage traffic spikes, applications that consistently experience very high volume levels of traffic may experience performance degradation or throttling. If you expect your application consistently to manage more than 5 GB/hour of data or consistently to have a large number of connections (>400k new connections/hour, >15k active, concurrent connections), we recommend using Amazon EC2 with Application Load Balancing instead."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do Lightsail load balancers route traffic to my target instances?"}, {"role": "assistant", "content": "Lightsail load balancers direct traffic to your healthy target instances based on a round robin algorithm."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does Lightsail know if my target instances are healthy?"}, {"role": "assistant", "content": "During load balancer creation, you will be asked to specify a path (a common file or webpage URL) for Lightsail to ping. If the target instance can be reached using this path, then Lightsail will route traffic there. If one of your target instances is unresponsive, Lightsail will not route traffic to that instance. You can update the Health check path if needed in the load balancer management screens."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the difference between key-value and key-only Tags?"}, {"role": "assistant", "content": "Lightsail tags are key-value pairs, allowing you to organize resources such as instances across different categories, e.g. project:Blog, project:Game, project:Test. This allows you full control across all use cases such as resource organization, bill reporting, and access management. The Lightsail console also allows you to tag your resources with key-only tags for quick filtering in the console."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I assign one instance to multiple load balancers?"}, {"role": "assistant", "content": "Yes, Lightsail supports adding instances as target instances for more than one load balancer, if desired."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens to my target instances when I delete my load balancer?"}, {"role": "assistant", "content": "If you delete your load balancer, the attached target instances will continue to run normally and will appear in the Lightsail console as regular Lightsail instances. Please note that you will likely need to update your DNS records to direct traffic to one of your former target instances after you delete the load balancer."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is session persistence?"}, {"role": "assistant", "content": "Session persistence enables the load balancer to bind a visitor's session to a specific target instance. This ensures that all requests from the user during the session are sent to the same target instance. Lightsail supports session persistence for applications that require visitors to hit the same target instances for data consistency. For example, many applications that require user authentication can benefit from using session persistence. You can turn on session persistence for specific load balancer from the load balancer management screens after creation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What kind of connections do Lightsail load balancers support?"}, {"role": "assistant", "content": "Lightsail load balancers support HTTP and HTTPS connections."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I use Lightsail-provisioned certificates?"}, {"role": "assistant", "content": "SSL/TLS certificates are used to establish the identity of your website or application and secure connections between browsers and your website. Lightsail provides a signed certificate to use with your load balancer, and the load balancer provides SSL/TLS termination before routing verified traffic to your target instances over the secure AWS network. Lightsail certificates can only be used with Lightsail load balancers, not with individual Lightsail instances."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I validate my certificate?"}, {"role": "assistant", "content": "Lightsail certificates are domain validated, meaning that you need to provide proof of identity by validating that you own or have access to your website\u2019s domain before the certificate can be provisioned by the certificate authority. When you request a new certificate, Lightsail will prompt you to add a CNAME to the DNS zone(s) of the domain or domains you are validating. You will add this CNAME wherever you currently manage your DNS zones \u2013 either Lightsail DNS management or an external DNS hosting provider (e.g., Route 53, GoDaddy, Namecheap, etc.). Once your certificate is validated, you can remove the CNAME record from your DNS zone, if desired."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens if I cannot validate my domain?"}, {"role": "assistant", "content": "You must be able to validate that you own a domain for security purposes. This means if you or someone in your organization cannot add a DNS record to validate your certificate for any reason, you will not be able to use an HTTPS-enabled load balancer with Lightsail."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How many domains and subdomains can I add to my certificate?"}, {"role": "assistant", "content": "You can add up to 10 domains or subdomains per certificate. Lightsail does not currently support wild card domains."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I change the domains associated with my certificate?"}, {"role": "assistant", "content": "To change the domains (add/delete) associated with your certificate, you will need to resubmit the certificate and revalidate your ownership of the domain(s). Follow the steps in the certificate management screens to regenerate your certificate and add or remove domains when prompted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I renew my certificate?"}, {"role": "assistant", "content": "Lightsail provides managed renewal for your SSL/TLS certificates. This means that Lightsail tries to renew the certificates automatically before they expire with no action required from you. Your Lightsail certificate must be actively associated load balancer before it can be automatically renewed."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens to my certificate when I delete my load balancer?"}, {"role": "assistant", "content": "If your load balancer is deleted, your certificate is deleted as well. If you need to use a certificate for the same domain(s) in the future, you will need to request and validate a new certificate."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I download my certificate provided by Lightsail?"}, {"role": "assistant", "content": "No, Lightsail certificates are bound to your Lightsail account and cannot be removed and used outside of Lightsail."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is Upgrade to EC2?"}, {"role": "assistant", "content": "Upgrade to EC2 is a feature that allows you to create a copy of your Lightsail instance in Amazon EC2. When you upgrade to EC2, you can pick among the wide set of instance types, configurations, and pricing models that EC2 offers, and have even more fine-tuned control over your networking, storage, and compute environment."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why would I want to upgrade to EC2?"}, {"role": "assistant", "content": "Lightsail offers you an easy way to run and scale a wide set of cloud-based applications, at a bundled, predictable, and low price. Lightsail also automatically sets up your cloud environment configurations such as networking and access management.Upgrading to EC2 allows you to run your application on a wider set of instance types, ranging from virtual machines with more CPU power, memory, and networking capabilities, to specialized or accelerated instances with FPGAs and GPUs. In addition, EC2 performs less automatic management and set-up, allowing you more control over how you configure your cloud environment, such as your VPC."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does it work?"}, {"role": "assistant", "content": "To get started, you need to export your Lightsail instance manual snapshot. You'll then use the Upgrade to EC2 wizard to create an instance in EC2.Customers who are comfortable with EC2 can then use the EC2 creation wizard or API to create a new EC2 instance as they would from an existing EC2 AMI. Alternatively, Lightsail also provides a guided Lightsail console experience to help you easily create a new EC2 instance.Note: Exporting Ghost and Django instance manual snapshots to Amazon EC2 is not supported at this time. We apologize for the inconvenience."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How am I billed?"}, {"role": "assistant", "content": "Using the Upgrade to EC2 feature is free. Once you have exported your snapshots to EC2, you will be charged for the EC2 image separately and in addition to your Lightsail snapshot. Any new EC2 instances you launch will also be billed by EC2, including their EBS storage volume(s) and data transfer. Refer to the EC2 pricing page for details on the pricing for your new instance and resources. Lightsail resources that continue to run in your Lightsail account will continue to be billed at their regular rates until they are deleted."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I export managed database or disk snapshots?"}, {"role": "assistant", "content": "The upgrade feature allows you to export Lightsail disk manual snapshots but doesn't currently support managed database snapshots. Disk snapshots can be rehydrated as EBS volumes from the EC2 console or API."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What Lightsail resources can I upgrade?"}, {"role": "assistant", "content": "Lightsail's upgrade to EC2 feature is designed to support the export of Linux and Windows instances and their attached block storage (if applicable) to EC2. It also supports the export of unattached block storage disks to EBS. It does not currently support the export of load balancers, databases, static IPs or DNS records."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are Lightsail's managed databases?"}, {"role": "assistant", "content": "Lightsail's managed databases are instances that are dedicated to running databases, instead of other workloads like webserver, mail server, etc. A Lightsail database can contain multiple user-created databases, and you can access it by using the same tools and applications that you use with a stand-alone database. Lightsail maintains the security and health of your database\u2019s underlying infrastructure and operating system, so that you can run a database without deep expertise in infrastructure management.Like regular Lightsail instances, Lightsail databases come with a fixed amount of memory, computing power, and SSD based storage in their plans that you can scale up over time. Lightsail will automatically install and configure your chosen database for you upon creation."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail's managed databases?"}, {"role": "assistant", "content": "Lightsail managed databases provide an easy, low maintenance way to store your data in the cloud. You can run Lightsail databases either as a new databases or by migrating from an existing on-premises or hosted database to Lightsail.They can also allow you to scale your application to accept larger amounts of traffic and more intensive loads, by separating out your database into a dedicated instance. Lightsail databases are especially useful for stateful applications \u2013 like WordPress and most common CMSs \u2013 that need data to be kept in sync when you scale beyond a single instance. Lightsail databases can be paired with a Lightsail load balancer and two or more Lightsail instances to create a powerful, scaled application. By using Lightsail High Availability plans, you can also create add redundancy to your database, helping to ensure high uptime for your application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does Lightsail manage for me on my managed database?"}, {"role": "assistant", "content": "Lightsail manages a range of maintenance activities and security for your database and its underlying infrastructure. Lightsail automatically backs up your database and allows point in time restore from the past 7 days using the database restore tool, to help protect against data loss or component failure. Lightsail also automatically encrypts your data at rest and in motion for increased security and stores your database password for easy and secure connections to your database. On the maintenance side, Lightsail runs maintenance on your database during your set maintenance window. This maintenance include automatic upgrades to the latest minor database version and all management of the underlying infrastructure and operating system."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What managed database plans does Lightsail offer?"}, {"role": "assistant", "content": "Lightsail offers 4 sizes of databases in Standard and High Availability plans. Each plan comes with a fixed amount of storage and a monthly allowance of data transfer. You can also scale up to larger plans over time, as needed, and switch between Standard and High Availability plans. High Availability plans mirror the same resources as Standard plans and additionally include a standby database running in a separate Availability Zones from your primary database for redundancy."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a High Availability plan?"}, {"role": "assistant", "content": "Managed databases are available in Standard and High Availability plans. Standard and High availability plans have identical plan resources, including memory, storage, and data transfer allowance. High Availability plans add redundancy and durability to your database, by automatically creating standby database in a separate Availability Zone from your primary database, synchronously replicating data to the standby database, and providing failover to the standby database in case of infrastructure failure and during maintenance so that you ensure uptime even when databases is being automatically upgraded/maintained by Lightsail. Use High Availability plans for running production applications or software where high uptime is required."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I scale up or down my managed database?"}, {"role": "assistant", "content": "You can scale up your database by taking a snapshot of your database and creating a new, larger database plan from snapshot or by creating a new, larger database using the emergency restore feature. You can also switch from Standard to High Availability plans and vice versa using either method. You cannot scale down your database. To learn more, see [Creating a database from a snapshot in Amazon Lightsail](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en/articles/amazon-lightsail-creating-a-database-from-snapshot)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I back up my managed database?"}, {"role": "assistant", "content": "Lightsail backs up your data automatically and allows restore of this data from a specific point in time to a new database. Automatic backup is a free service for your database but only saves the last 7 days of data. If you delete your database, all automatic backup records are deleted and point in time restore is no longer possible. To retain backups of data after deleting your database or to retain a backup for more than 7 days in the past, use manual snapshots.You can take manual snapshots of your Lightsail managed databases from the database management pages. Manual snapshots contain all the data from your database and can be used as backups for data that you want to store permanently. You can also use manual snapshots to create a new, larger database or to switch between Standard and High Availability plans. Manual snapshots are stored until you delete them and are billed at $0.05 USD/GB-month."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens to my data if I delete my managed database?"}, {"role": "assistant", "content": "If you delete your managed database, both your database itself and all automatic backups will be deleted. There is no way to recover this data unless you take a manual snapshot before deleting your database. During deletion of your database, Lightsail provides a one-click option to take a manual snapshot, if desired, to help protect against accidental loss of data. Taking a manual snapshot before deletion is optional but highly recommended. You can delete your manual snapshot in the future when you no longer need the stored data."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do managed databases work with my Lightsail instances?"}, {"role": "assistant", "content": "After you create your managed database, you can start using your database with your application immediately, using your Lightsail instances as web servers or other dedicated workloads for your app. To connect your Lightsail instance to a database, use your database endpoint and reference your securely stored password to configure the database as your data store in the code of your application. You can find connection data in the database management screens. The file name and location for your database configuration file will vary by application. Note that you can connect many instances to one database, either using the same tables or using different ones."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail CDN distributions?"}, {"role": "assistant", "content": "Lightsail content delivery network (CDN) distributions make it easy for you to accelerate the delivery of content hosted on your Lightsail resources by storing and serving it on Amazon\u2019s global delivery network, powered by Amazon CloudFront. Distributions also help you enable your website to support HTTPS traffic by providing simple SSL certificate creation and hosting. Finally, distributions can help reduce the load on your Lightsail resources and help your website handle large traffic spikes. Like all of Lightsail\u2019s features, setup can be completed with just a few clicks, and you pay a simple monthly price."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What types of resources can I use as the origin of my distributions?"}, {"role": "assistant", "content": "Lightsail distributions allow you to use your Lightsail instances, containers, load balancers, or Lightsail buckets as origins."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Do I need to attach a static IP to my Lightsail instance in order to use it as an origin for my Lightsail distribution?"}, {"role": "assistant", "content": "Yes, static IPs are required to be attached to instances that are specified as origins."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I setup a Lightsail distribution with my WordPress website?"}, {"role": "assistant", "content": "Simply create your distribution, select your WordPress instance as the origin, choose your plan, and you\u2019re all set. Lightsail distributions automatically configure your distribution settings to optimize performance for most WordPress configurations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I attach multiple origins?"}, {"role": "assistant", "content": "Although you cannot attach multiple origins to your Lightsail distribution, you can attach multiple instances to a Lightsail load balancer and specify it as the origin of your distribution."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Do Lightsail distributions support certificate creation?"}, {"role": "assistant", "content": "Yes. Lightsail distributions makes it easy to create, verify, and attach certificates directly from your distribution\u2019s management page."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is a certificate required?"}, {"role": "assistant", "content": "A certificate is only required if you wish to use your custom domain name with your distribution. All Lightsail distributions are created with a unique Amazon CloudFront domain name that is HTTPS-enabled. However, if you wish to use your custom domain with your distribution, then you need to attach a certificate for your custom domain to your distribution."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is there a limit to the number of certificates I can create?"}, {"role": "assistant", "content": "Yes, refer to Lightsail\u2019s service quotas for more information."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I configure my distribution to redirect HTTP requests to HTTPS?"}, {"role": "assistant", "content": "Lightsail distributions automatically redirect all HTTP requests to HTTPS to ensure that your content is served securely."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I configure my apex domain to point to my Lightsail distribution?"}, {"role": "assistant", "content": "In order to point your apex domain to your CDN distribution, you must create an ALIAS record in the domain name system (DNS) of your domain that maps your apex domain to your distribution\u2019s default domain. If your DNS hosting provider does not support ALIAS records, you can use Lightsail DNS zones to easily configure your apex domain to point to your distribution\u2019s domain."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are the differences between Lightsail\u2019s instance data transfer quotas and distribution data transfer quotas?"}, {"role": "assistant", "content": "While data transfer IN and OUT count toward your instance\u2019s data transfer quota, only data transfer OUT counts toward you distribution\u2019s quota. In addition, all data transfer OUT in excess of your distribution\u2019s quota is charged an overage fee, whereas some types of data transfer OUT are free for instances. Finally, Lightsail distributions use a different regional overage model, though the majority of the rates are the same as those charged for instance data transfer overage."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I change the plan associated with my distribution?"}, {"role": "assistant", "content": "Yes, you can change your distribution's plan once per month. If you wish to change your plan a second time, you must wait until the beginning of the following month to do so."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I know if my distribution is working?"}, {"role": "assistant", "content": "Lightsail distributions provide you with a variety of metrics that track the performance of your distribution, including the total number of requests your distribution has received, the amount of data your distribution has sent to clients and to your origin, and the percentage of requests that have resulted in errors. Additionally, you can create alerts that are linked to distribution metrics."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "When should I use Lightsail distributions versus Amazon CloudFront distributions?"}, {"role": "assistant", "content": "Lightsail distributions are designed specifically for users who are hosting websites or web applications on Lightsail resources, such as instances and load balancers. If you\u2019re using another service in AWS to host your website or app, have complex configuration needs, or have a workload that involves a high number of requests per second or large amount of video streaming, we recommend that you use Amazon CloudFront."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How is Lightsail CDN intended to be used?"}, {"role": "assistant", "content": "Amazon Lightsail CDN distributions are created using fixed-priced bundles of data transfer to make the cost of using the service simple and predictable. Distribution bundles are designed to cover a month\u2019s worth of usage. Using distribution bundles in a way to avoid incurring overage fees (including, but not limited to, frequently upgrading or downgrading bundles, or using an excessively large number of distributions with a single origin) is beyond the intended scope of use and is not permitted. In addition, workloads that involve a high number of requests per second or large amount of video streaming are not permitted. Engaging in these behaviors may result in throttling or suspension of your data services or account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I move my Lightsail content delivery network (CDN) distribution to Amazon CloudFront?"}, {"role": "assistant", "content": "Yes, you can move your Lightsail distribution by creating a similarly configured distribution in CloudFront. All of the settings that can be configured in a Lightsail distribution can also be configured in a CloudFront distribution. Complete the following steps to move your distribution to CloudFront:1. Take a snapshot of your Lightsail instance that is configured as your distribution's origin. Export the snapshot to Amazon EC2, and then create a new instance from the snapshot in EC2. For more information, see\u00a0[Exporting Amazon Lightsail snapshots.](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-exporting-snapshots)Note:\u00a0Create an application load balancer in Elastic Load Balancing if you need to load balance your website or web application. For more information, see the\u00a0[Elastic Load Balancing User Guide](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html).2. Disable custom domains for your Amazon Lightsail distribution to detach certificates that you might have attached to it. For more information, see\u00a0[Disabling custom domains for your Amazon Lightsail distributions](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-disabling-distribution-custom-domains).3. Using the AWS Command Line Interface (CLI), run the get-distributions command to get a list of your Lightsail distribution\u2019s settings. For more information, see\u00a0[get-distributions](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/cli/latest/reference/lightsail/get-distributions.html)\u00a0in the AWS CLI Reference.4. Sign in to the\u00a0[Amazon CloudFront console](https://web.archive.org/web/20240727061427/https://console.aws.amazon.com/cloudfront/)\u00a0and create a distribution with the same configuration settings as your Lightsail distribution. For more information, see\u00a0[Creating a Distribution](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-creating-console.html)\u00a0in the Amazon CloudFront Developer Guide.5. Create a certificate in AWS Certificate Manager (ACM) that you will attach to your CloudFront distribution. For more information, see\u00a0[Request a Public Certificate](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html)\u00a0in the ACM User Guide.Update your CloudFront distribution to use the ACM certificate you created. For more information, see [Updating your CloudFront distribution](https://web.archive.org/web/20240727061427/https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-procedures.html) in the CloudFront User Guide."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail container services?"}, {"role": "assistant", "content": "Lightsail container services provide an easy way to run containerized applications in the cloud. You can run a variety of applications on a container service, ranging from simple web apps to multi-tiered micro services. You just specify the container image, power (CPU, RAM) and scale (number of nodes) required for your container service. Lightsail takes care of running the container service without you having to manage any underlying infrastructure. Lightsail will provide you with a load balanced TLS endpoint to access the application running on the container service."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can Lightsail container service run Docker containers?"}, {"role": "assistant", "content": "Yes. Lightsail supports Linux-based Docker containers. Windows containers are currently not supported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I use my Docker container images with Lightsail container service?"}, {"role": "assistant", "content": "You can use either container images on registries like Docker Hub or build your own custom image and push it to Lightsail in a few easy steps using the AWS CLI. For more information, see [Pushing and managing container images on your Amazon Lightsail container services](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-pushing-container-images)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I pull my container images from a private container registry?"}, {"role": "assistant", "content": "Currently, only public container registries are supported by Lightsail container services. Alternately, you can push your custom container images from your local machine to Lightsail to keep them private."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I change the power and scale of my service based on demand?"}, {"role": "assistant", "content": "Yes, container service power and scale can be changed at any time even after the service is created."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I customize the name of the HTTPS endpoint created by Lightsail container service?"}, {"role": "assistant", "content": "Lightsail provides a HTTPS endpoint for every container service in the format \u201c<service-name>.<random-guid>.<aws-region-name>.cs.amazonlightsail.com. Only the service name can be customized. Alternately, you can use a custom domain name. For more information, see\u00a0[Enabling and managing custom domains for your Amazon Lightsail container services](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-enabling-container-services-custom-domains)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use custom domains for the HTTPS endpoint of a Lightsail container service?"}, {"role": "assistant", "content": "Yes. You can create and attach SSL/TLS certificates with custom domain names to your container service in Lightsail. The certificates need to be domain validated. After the certificate is attached, if you manage your domain via Lightsail DNS, you can easily add A/AAAA/CNAME records to route traffic for your domain to your container services. Alternately, you can use a DNS hosting provider who supports adding ALIAS records, to map the apex of your domain to the public domain (public DNS) of your Lightsail container service. [For more information, see Enabling and managing custom domains for your Amazon Lightsail container service](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-enabling-container-services-custom-domains)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What do Lightsail container services cost?"}, {"role": "assistant", "content": "Lightsail container services are billed on an on-demand hourly rate, so you pay only for what you use. For every Lightsail container service you use, we charge you the fixed hourly price, up to the maximum monthly service price. Maximum monthly service price can be calculated by multiplying the base price of the power of your service with the scale of your service. For example, a service of Micro power and scale of 2 will cost a maximum of $10*2=$20/month. The least expensive Lightsail container service starts at $0.0094 USD/hour ($7 USD/month). Additional data transfer charges may apply for usage above the free-quota of 500 GB per month for each service."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Will I be charged for the whole month even if I run my container service for a few days?"}, {"role": "assistant", "content": "Your Lightsail container services are charged only when they're in the running or disabled state. If you delete your Lightsail container service before the end of the month, we charge you a prorated cost based on the total number of hours that you used your Lightsail container service. For example, if you use your Lightsail container service with a power of Micro and scale of 1 for 100 hours in a month, you will be charged $1.34 ($0.0134*100)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Will I be charged for data transfer in and out of the container service?"}, {"role": "assistant", "content": "Every container service comes with a data transfer quota (500 GB per month). This counts towards both the data transfer IN and OUT of your service. When you exceed the quota, you will get charged for data transfer OUT from a Lightsail container service to the Internet or to another AWS Region or to AWS resources in the same Region when using public IP addresses. The charge for these types of data transfer above the free allowance is as follows:US East (N. Virginia): $0.09 USD/GBUS East (Ohio): $0.09 USD/GBUS West (Oregon): $0.09 USD/GBCanada (Central): $0.09 USD/GBEurope (Frankfurt): $0.09 USD/GBEurope (Ireland): $0.09 USD/GBEurope (London): $0.09 USD/GBEurope (Paris): $0.09 USD/GBEurope (Stockholm): $0.09 USD/GBAsia Pacific (Mumbai): $0.13 USD/GBAsia Pacific (Singapore): $0.12 USD/GBAsia Pacific (Sydney): $0.17 USD/GBAsia Pacific (Tokyo): $0.14 USD/GBAsia Pacific (Seoul): $0.13 USD/GB"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the difference between stopping and deleting my container service?"}, {"role": "assistant", "content": "When you disable your container service, your container nodes are in a disabled state and the public endpoint of the service returns a HTTP status code \u2018503\u2019. Enabling the service restores it to the last active deployment. Power and scale configurations are also retained. Public endpoint name does not change after re-enabling. Deployment history and container images are preserved.When you delete your container service, you are performing a destructive action. All the container nodes of the service will be permanently deleted. The HTTPS public endpoint address, container images, deployment history, and logs associated with your service will also be permanently deleted. You will not be able to recover the endpoint address."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Will I be charged if my container service is in a disabled state?"}, {"role": "assistant", "content": "Yes, you are charged according to the power and scale configuration of your container service, even when it is in a disabled state."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use container services as the origin to my Lightsail content delivery network (CDN) distributions?"}, {"role": "assistant", "content": "Container services are currently not supported as origins for Lightsail CDN distributions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use container services as targets for my Lightsail load balancer?"}, {"role": "assistant", "content": "No. Container services are currently not available as targets for Lightsail load balancers. However, the public endpoints of container services come with built-in load balancing."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I configure the public endpoint of my container service to redirect HTTP requests to HTTPS?"}, {"role": "assistant", "content": "Lightsail container service public endpoints automatically redirect all HTTP requests to HTTPS to ensure that your content is served securely."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Do container services support monitoring and alerting?"}, {"role": "assistant", "content": "Container services provide metrics for CPU utilization and memory utilization across the nodes of your service. Alerting based on these metrics is currently not supported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What can I do with Lightsail object storage?"}, {"role": "assistant", "content": "Lightsail now provides you with the ability to store your static content such as images, videos or HTML files in an object storage that can be used for your websites and applications. Lightsail object storage can be associated to your Lightsail CDN distribution with a few simple clicks, making it quick and easy to accelerate the delivery of your content to a global audience. It can also be used as a low cost, secure backup solution."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What does Lightsail object storage cost?"}, {"role": "assistant", "content": "Lightsail object storage has three different fixed-priced bundles in all AWS Regions where Lightsail is available. The first bundle is $1 per month and is free for the first 12 months. This bundle includes 5 GB storage capacity and 25 GB data transfer. The second bundle is $3 per month and includes 100 GB storage capacity and 250 GB data transfer. Lastly, the third bundle is $5 per month and includes 250 GB of storage capacity and 500 GB of data transfer. Lightsail object storage includes unlimited data transfer into your bucket, as the bundled data transfer allowance is used only for data transfer out from your bucket."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Lightsail object storage have overage charges?"}, {"role": "assistant", "content": "When you exceed the monthly storage capacity or data transfer allowance of your object storage plan, you will get charged for the additional amount. For more information, see the Lightsail\u00a0[pricing page](https://web.archive.org/web/20240727061427/https://aws.amazon.com/lightsail/pricing/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does my data transfer allowance work with object storage?"}, {"role": "assistant", "content": "You can consume your data transfer allowance by transfering data into and out of Lightsail object storage, except for the following:Data transferred into Lightsail object storage from the internetData transfer between Lightsail object storage resourcesData transferred out from Lightsail object storage to another Lightsail resource in the same region (including to a different account in the same AWS Region)Data transferred out from Lightsail object storage to a Lightsail CDN distribution"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I change the plan associated with my Lightsail bucket?"}, {"role": "assistant", "content": "Yes, you can change your Lightsail object storage plan one time within your monthly AWS billing cycle."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I copy objects from Lightsail object storage to Amazon S3?"}, {"role": "assistant", "content": "Yes, copying from Lightsail object storage to Amazon S3 is supported. Documentation on the proper AWS CLI command can be found [here](https://web.archive.org/web/20240727061427/https://aws.amazon.com/premiumsupport/knowledge-center/move-objects-s3-bucket/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I get started with Lightsail object storage?"}, {"role": "assistant", "content": "To use Lightsail object storage, you must first create a bucket that is used to store your data. For more information, see [Creating buckets in Amazon Lightsail](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-creating-buckets). After your bucket is up and running, you can start adding objects to your bucket by uploading files using the Lightsail console or by configuring your application to put content like logs or other application data in the bucket. Alternatively, you can also get started with Lightsail object storage through the use of AWS Command Line Interface (AWS CLI)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I block public access to my bucket?"}, {"role": "assistant", "content": "Lightsail buckets and objects are set to private by default, meaning that only users with appropriate permissions have access to the bucket and objects. A user can change this default setting and either make individual objects public and read only in a private bucket or opt to make the entire bucket public and read only. When a user makes a bucket or object public, anyone in the world can read its content."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I provide programmatic access to my bucket?"}, {"role": "assistant", "content": "You can use either access keys or roles for programmatic access to your bucket. First, select the bucket you want to programmatically connect to in the Lightsail console. Second, under the \u201cPermissions\u201d tab, create an access key or assign a role to your Lightsail instance and then configure your website or application code to use your bucket. This behavior may vary depending on how you plan to use object storage with your website or application. See more documentation [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-configuring-bucket-permissions)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I share a bucket with other AWS accounts?"}, {"role": "assistant", "content": "Lightsail makes cross-account sharing easy by allowing you to share access to your bucket with the AWS account ID you specify in the \u201cCross-account access\u201d in the Lightsail console. After you specify an AWS account ID, that account will have read-only access to the bucket."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is versioning?"}, {"role": "assistant", "content": "Versioning allows you to preserve, retrieve, and restore every version of every object storage in your bucket, providing an additional level of protection from accidental overwrites and deletes. See more documentation on enabling versioning [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-managing-bucket-object-versioning)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I associate my Lightsail bucket to my Lightsail CDN distribution?"}, {"role": "assistant", "content": "Lightsail object storage can be associated to Lightsail CDN distributions with a few simple clicks, making it quick and easy to accelerate the delivery of your content to a global audience. To do so, create a Lightsail CDN distribution and simply select the Lightsail bucket as the origin of your Lightsail CDN distribution. See more documentation [here](https://web.archive.org/web/20240727061427/https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-using-distributions-with-buckets)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is there a limit to the number of Lightsail object storage bundles I can create?"}, {"role": "assistant", "content": "You can create up to 20 Lightsail object storage bundles per account. There is no limit to the number of objects that you can store in a bucket."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does Lightsail object storage support monitoring and alerting?"}, {"role": "assistant", "content": "With Lightsail object storage, customers can easily view metrics on the total used space within a bucket and number of objects within the bucket. Alerting based on these metrics is also supported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Why would I use AWS Outposts rack instead of operating in an AWS Region?"}, {"role": "assistant", "content": "You can use Outposts rack to support your applications that have low latency or local data processing requirements. These applications may need to generate near real-time responses to end user applications or need to communicate with other on-premises systems or control on-site equipment. These can include workloads running on factory floors for automated operations in manufacturing, real-time patient diagnosis or medical imaging, and content and media streaming.\u00a0You can use Outposts rack to securely store and process customer data that needs to remain on premises or in countries where there is no AWS Region. You can run data intensive workloads on Outposts rack and process data locally when transmitting data to AWS Regions is expensive and wasteful and for better control on data analysis, backup and restore."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "In which AWS Regions is Outposts rack available?"}, {"role": "assistant", "content": "Outposts rack is supported in the following AWS Regions and customers can connect their Outposts to the following AWS Regions:US East (Ohio)us-east-2US East (N. Virginia)us-east-1US West (N. California)us-west-1US West (Oregon)us-west-2Canada (Central)ca-central-1South America (S\u00e3o Paulo)sa-east-1EU (Frankfurt)eu-central-1EU (Ireland)eu-west-1EU (Stockholm)eu-north-1EU (Paris)eu-west-3EU (London)eu-west-2EU (Milan)eu-south-1Middle East (Bahrain)me-south-1Middle East (UAE)me-central-1Israel (Tel Aviv)il-central-1Africa (Cape Town)af-south-1Asia Pacific (Sydney)ap-southeast-2Asia Pacific (Tokyo)ap-northeast-1Asia Pacific (Seoul)ap-northeast-2Asia Pacific (Singapore)ap-southeast-1Asia Pacific (Mumbai)ap-south-1Asia Pacific (Osaka)ap-northeast-3Asia Pacific (Jakarta)ap-southeast-3AWS GovCloud (US-West)us-gov-west-1AWS GovCloud (US-East)us-gov-east-1"}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "In which countries and territories is Outposts rack available?"}, {"role": "assistant", "content": "Outposts rack can be shipped to and installed in the following countries and territories.NA - US, Canada, MexicoEMEA - All EU countries, United Kingdom (UK), Switzerland, Norway, Bahrain, the United Arab Emirates (UAE), Israel, South Africa, Gibraltar, Morocco, Nigeria, Kenya, Oman, Kazakhstan, Serbia, Qatar, Egypt, Iceland, Turkey, the Kingdom of Saudi Arabia*, SenegalAPAC - Australia, New Zealand, Japan, South Korea, Taiwan, Singapore, Indonesia, Malaysia, Thailand, the Philippines, Brunei, India, Vietnam, BangladeshSA - Brazil, Colombia, Argentina, Chile, Peru, Ecuador, Trinidad and Tobago, UruguayCA - Puerto Rico, Costa Rica, Panama, GuatemalaSupport for more countries and territories is coming soon.*\u00a0Customers deploying in\u00a0the Kingdom of Saudi Arabia may require additional authorization. Contact your AWS Sales Representative to learn more."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I order an Outpost to a country or territory where Outposts rack has not launched and link it back to a supported Region?"}, {"role": "assistant", "content": "No, we can deliver and install Outposts rack only in countries and territories where Outposts rack can be delivered and supported."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use Outposts rack when it is not connected to the AWS Region or in a disconnected environment?"}, {"role": "assistant", "content": "An Outpost relies on connectivity to the parent AWS Region. Outposts rack is not designed for disconnected operations or environments with limited to no connectivity. We recommend that customers have highly available networking connections back to their AWS Region. If interested in leveraging AWS services in disconnected environments such as cruise ships or remote mining locations, learn more about AWS services such as Snowball Edge, which is optimized to operate in environments with limited to no connectivity."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I reuse my existing servers in an Outpost?"}, {"role": "assistant", "content": "No, AWS Outposts rack leverages AWS designed infrastructure, and is only supported on AWS-designed hardware that is optimized for secure, high-performance, and reliable operations."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is there a software-only version of AWS Outposts rack?"}, {"role": "assistant", "content": "No, AWS Outposts rack is a fully managed service that provides you with native access to AWS services."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I order my own hardware that can be installed as part of my Outposts rack?"}, {"role": "assistant", "content": "No, AWS Outposts rack provides fully integrated AWS designed configurations with built in top-of-rack switches and redundant power supply to ensure an ideal AWS experience. You can order as much compute and storage infrastructure as you need by selecting from the range of available Outposts rack options, or work with us to create a custom combination with your desired\u00a0Amazon Elastic Compute Cloud (EC2), Amazon Elastic Block Store (EBS), and Amazon Simple Storage Service (S3) capacity. These are pre-validated and tested to ensure that you can get started quickly with no additional effort or configuration required on-site."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I create EC2 instances using an EBS backed AMI on my Outposts?"}, {"role": "assistant", "content": "Yes, you can launch EC2 instances using the AMIs backed with EBS gp2 volume types."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Where are EBS snapshots stored?"}, {"role": "assistant", "content": "EBS snapshots of EBS Volumes on Outposts rack are stored by default on Amazon S3 in the Region. If the Outpost is provisioned with Amazon S3 on Outposts you have the option to store your snapshots locally on your Outpost. EBS snapshots are incremental, which means that only the blocks on your Outpost that have changed after your most recent snapshot are saved. You can at any time restore (hydrate) EBS Volume on Outposts from the stored snapshots. To learn more, visit the EBS Snapshots\u00a0[documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshots-outposts.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I enforce data residency on Outposts rack using EBS Local Snapshots on Outposts?"}, {"role": "assistant", "content": "You can set resource-level IAM policies and permissions on your Outpost for EBS Local Snapshots on Outposts and AMI images to enforce data residency. Each account (or IAM user or role) can set up a data residency enforcement policy for single or multiple Outposts. This will block the creation or copy of local snapshots and images as well as API/CLI calls outside the specified Outposts rack ARN. All of the create, update, and copy operations are logged in CloudTrail audit logs, so you can track that local snapshots reside in your location. To learn more, visit the EBS Snapshots\u00a0[documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshots-outposts.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What use cases are best suited to run on S3 on Outposts?"}, {"role": "assistant", "content": "[S3 on Outposts](https://aws.amazon.com/s3/outposts/)\u00a0is ideal for customers with data residency requirements or those in regulated industries that need to securely store and process customer data that needs to remain on premises or in locations where there is no AWS region. Additionally, customers can use S3 on Outposts to run data intensive workloads to process data locally and store on-premises. S3 on Outposts will also help if you have applications that need to communicate with other on-premises systems or control on-site equipment, such as within a factory, hospital, or research facility."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I establish network connectivity between my Outpost and the AWS Region?"}, {"role": "assistant", "content": "You can choose to establish Outposts rack service link VPN connection to the parent AWS Region via an AWS Direct Connect private connection, a public virtual interface, or the public Internet."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is Application Load Balancer available on Outposts rack?"}, {"role": "assistant", "content": "Yes, Application Load Balancer is available on Outposts rack in all AWS Regions where Outposts rack is available,\u00a0except the AWS GovCloud (US) Regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can Outposts rack support real-time applications with low-latency requirements?"}, {"role": "assistant", "content": "Yes, with Amazon RDS on Outposts you can run managed Microsoft SQL Server, MySQL, and PostgreSQL databases on premises for low latency workloads that need to be run in close proximity to on premises data and applications. You can manage RDS databases both in the cloud and on premises using the same AWS Management Console, APIs, and CLI. For ultra low-latency applications, ElastiCache on Outposts enables sub-millisecond responses for real-time applications, including workloads running on factory floors for automated operations in manufacturing, real-time patient diagnosis, and media streaming."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can Outposts rack be used to meet data residency requirements?"}, {"role": "assistant", "content": "Yes. Customer data can be configured to remain on Outposts rack using Amazon Elastic Block Store (EBS) and Amazon Simple Storage Service (S3) on Outposts, in the customer\u2019s on-premises location or specified co-location facility. Well-architected applications using Outposts rack and AWS services and tools address the data residency requirements we most commonly hear from our customers. AWS Identity and Access Management (IAM) lets you control access to AWS resources. You can use IAM and granular data control rules to specify which types of data must remain on Outposts rack and cannot be replicated to the AWS Region. S3 on Outposts stores data on your Outpost by default, and you may choose to replicate some or all of your data to AWS Regions based on your specific residency requirements. ElastiCache on Outposts allows you to securely process customer data locally on the Outposts rack. Some limited meta-data (e.g. instance IDs, monitoring metrics, metering records, tags, bucket names, etc.) will flow back to the AWS Region.  To ensure your unique data residency requirements are met, we recommend you confirm and work closely with your compliance and security teams."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is Resource Sharing available on AWS Outposts rack?"}, {"role": "assistant", "content": "Yes. AWS Resource Access Manager (RAM) is a service that enables you to share your AWS resources with any AWS account or within your AWS Organization. RAM support lets you, the Outpost owner, create and manage Outpost resources\u00a0\u2014 EC2 instances, EBS volumes, subnets, and local gateways (LGWs) centrally\u00a0\u2014 and share the resources across multiple AWS accounts within the same AWS organization. This allows others to configure VPCs, launch and run instances, and create EBS volumes on the shared Outpost."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Which EC2 instances are available on Outposts rack?"}, {"role": "assistant", "content": "EC2 instances built on the\u00a0[AWS Nitro System](https://aws.amazon.com/ec2/nitro/), for general purpose, compute optimized, memory optimized, storage optimized, and GPU optimized with Intel Xeon Scalable processors are supported on AWS Outposts rack, and Graviton processors based EC2 instances are coming soon."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I use Route 53 Resolver on Outposts?"}, {"role": "assistant", "content": "You can use\u00a0[Route 53 Resolver](https://aws.amazon.com/route53/resolver/)\u00a0to resolve Domain Name Server (DNS) queries locally on Outposts racks, improving the availability and performance of your on-premises applications. When you enable Route 53 Resolver on Outposts, Route 53 automatically stores DNS responses on Outposts racks and provides continued DNS resolution for your applications even during unexpected network disconnects to the parent AWS Region. By serving DNS responses locally, Route 53 Resolver on Outposts also enables low-latency DNS resolution, improving the performance of your on-premises applications.In addition, you can connect the Route 53 Resolvers on Outposts racks with DNS servers in your on-premises data centers through Route 53 Resolver endpoints. This enables resolution of DNS queries between the Outposts racks and your other on-premises resources."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Are there any prerequisites for deploying Outposts 42U racks at my location?"}, {"role": "assistant", "content": "Your site must support the basic power, networking and space requirements to host an Outpost. An Outposts rack needs 5-15 kVA, can support 1/10/40/100 Gbps uplinks, and space for a 42U rack (80\u201d X 24\u201d X 48\u201d dimensions). As Outposts rack requires reliable network connectivity to the AWS Region, you should plan for a public internet connection. Customers must have Enterprise Support or Enterprise On-Ramp Support, which provides 24x7 remote support within 15 minutes or within 30 minutes depending on the Support plan selected."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens at term end?"}, {"role": "assistant", "content": "At the end of your Outposts rack term, you can either renew your subscription and keep your existing Outposts rack(s), or return your Outposts rack(s). If you do not notify AWS which option you intend to take, your Outposts rack(s) will be renewed on a monthly basis, at the rate of the No Upfront payment option corresponding to your AWS Outposts rack configuration. For more information, see term end documentation\u00a0[here](https://docs.aws.amazon.com/outposts/latest/userguide/term-end-racks.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Do the same compliance certifications for AWS Services today apply for services on Outposts rack?"}, {"role": "assistant", "content": "AWS Outposts rack itself is HIPAA eligible, PCI, SOC, ISMAP, IRAP and FINMA compliant, ISO, CSA STAR, and HITRUST certified, and we expect to add more compliance certifications in coming months.\u00a0You can see the latest certification status for\u00a0[AWS Services on Outposts rack on our Services in Scope](https://aws.amazon.com/compliance/services-in-scope/)\u00a0page. AWS Services on Outposts rack like RDS or Elasticache Redis that have achieved certifications like PCI are also considered certified on Outposts rack. As AWS Outposts rack runs at the customer\u2019s data center, under the AWS Shared Responsibility model customers own the responsibility for physical security and access controls around the Outpost for compliance certification."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Is AWS Outposts rack GxP Compatible?"}, {"role": "assistant", "content": "Yes, AWS Outposts rack is GxP compatible. AWS Outposts rack extends AWS services to AWS-managed infrastructure that is physically located at a customer site. Outposts rack capacity can be accessed locally over a local gateway that is mapped to the customer\u2019s local network, in addition to having a connection path back to the AWS Region. You can learn more about using the AWS Cloud, including Outposts rack, for GxP systems\u00a0[here](https://aws.amazon.com/compliance/gxp-part-11-annex-11/). GxP-regulated life sciences organizations using AWS services are responsible for designing and verifying their GxP compliance."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Who is responsible for the physical security of the Outposts rack at my datacenter?"}, {"role": "assistant", "content": "AWS provides services that allow data to be encrypted at rest and in-transit and other granular security controls and auditing mechanisms. In addition, customer data is wrapped to a physical Nitro Security Key. Destroying the device is equivalent to destroying the data.\u00a0 As part of the shared responsibility model, customers are responsible for attesting to physical security and access controls around the Outpost, as well as environmental requirements for facility, networking, and power as published\u00a0[here](https://docs.aws.amazon.com/outposts/latest/userguide/outposts-requirements.html).\u00a0Prior to returning the Outposts rack hardware, the Nitro Security Key will be removed to ensure customer content is crypto shredded."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is AWS Outposts FedRAMP authorization status?"}, {"role": "assistant", "content": "FedRAMP has granted authorization to AWS Outposts, excluding the hardware components of the service. The physical and environmental controls for the AWS Outposts protection while at the customers\u2019 sites are the customers\u2019 responsibilities. Customers and agencies can make a risk-based decision to use AWS Outposts or conduct a Type Accreditation to review the hardware components of AWS Outposts to process FedRAMP workloads. Assessment results previously conducted by the AWS Third Party Assessment Organization can be accessed via\u00a0[CapLinked](https://secure.caplinked.com/workspaces/aws-workspace)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does AWS maintain AWS Outposts rack infrastructure?"}, {"role": "assistant", "content": "When your Outpost is installed and is visible in the AWS Management Console, AWS will monitor it as part of the public Region and will automatically execute software upgrades and patches.If there is a need to perform physical maintenance, AWS will reach out to schedule a time to visit your site. AWS may replace a given module as appropriate but will not perform any host or network switch servicing on customer premises."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens when my facility's network connection goes down?"}, {"role": "assistant", "content": "EC2 instances and EBS volumes on the Outpost will continue to operate normally and can be accessed locally via the local gateway. Similarly, AWS service resources such as ECS worker nodes continue to run locally. However, API availability will be degraded, for instance run/start/stop/terminate APIs may not work. Instance metrics and logs will continue to be cached locally for a few hours, and will be pushed to the AWS Region when connectivity returns. Disconnection beyond a few hours however may result in loss of metrics and logs. If you expect to lose network connectivity, we strongly recommend regularly testing your workload to ensure it behaves properly in this state when an Outpost is disconnected. For S3 on Outposts, if the network connection to your Outpost is lost, you will not be able to access your objects. Requests to store and retrieve objects are authenticated using the regional AWS Identity and Access Management (IAM) service, and if the Outpost has no connectivity to the home AWS Region, you are not able to access your data. Your data remains safely stored on your Outpost during periods of disconnect, and once connectivity is restored authentication and requests can resume."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What type of control plane information flows back to the parent AWS Region?"}, {"role": "assistant", "content": "As an example, information about instance health, instance activity (launched, stopped), and the underlying hypervisor system may be sent back to the parent AWS Region. This information enables AWS to provide alerting on instance health and capacity, and apply patches and updates to the Outpost. Your team does not need to implement your own tooling to manage these elements, or to actively push security updates and patches for your Outpost. For S3 on Outposts, certain data management and telemetry data, such as bucket names and metrics, may be stored in the AWS Region for reporting and management. When disconnected, this information cannot be sent back to the parent Region."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does AWS support adding capacity to existing Outposts?"}, {"role": "assistant", "content": "There are two mechanisms to increase your compute and storage capacity of your AWS Outposts rack. First, you can increase capacity by adding additional Outposts racks from the Outposts rack catalog. Second, if your existing Outposts racks have available power and positions within the rack, you can increase from a \u201csmall\u201d to a \u201cmedium\u201d or \u201clarge\u201d configuration, or from a\u201d medium\u201d to a \u201clarge\u201d configuration. You will be able to add compute and storage capacity a maximum of twice within a rack that supports 10KVA \u2013 15KVA power consumption. Note: The 1U and 2U Outposts servers cannot be installed in the 42U Outposts form factor."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What are serverless applications?"}, {"role": "assistant", "content": "Serverless applications eliminate the need to provision, deploy, or manage servers or other infrastructure. They come with built-in high availability and they scale continuously and automatically. You can use one of the many fully managed AWS services to build and run serverless applications, including AWS Lambda for compute, Amazon API Gateway for APIs, and Amazon DynamoDB for databases."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is the AWS Serverless Application Repository?"}, {"role": "assistant", "content": "The AWS Serverless Application Repository offers a growing collection of serverless applications published by AWS and other AWS partners and developers. The Serverless Application Repository makes it easy to deploy applications for common use cases like web and mobile back-ends, stream processing, machine learning, and more, so you can quickly get started with the AWS Serverless platform."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "In which regions is the AWS Serverless Application Repository available?"}, {"role": "assistant", "content": "It is currently available in the following regions: US East (Ohio), US East (N. Virginia), US West (N. California), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), and South America (S\u00e3o Paulo)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What kinds of applications are available in the AWS Serverless Application Repository?"}, {"role": "assistant", "content": "The AWS Serverless Application Repository includes applications for Alexa Skills, chatbots, data processing, IoT, real time stream processing, web and mobile back-ends, social media trend analysis, image resizing, and more from publishers on AWS."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Does it cost anything to use the AWS Serverless Application Repository?"}, {"role": "assistant", "content": "There is no charge to browse applications, deploy applications, or publish applications in the AWS Serverless Application Repository. Standard AWS charges apply to the resources used by the applications you deploy."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How are applications in the AWS Serverless Application Repository licensed?"}, {"role": "assistant", "content": "Applications provided by AWS are available under the MIT open source license, while applications publicly provided by others can be made available under one or more open source license(s) approved by the Open Source Initiative (OSI). You can find licensing details by navigating to the licensing tab of an application on the AWS website."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Are applications in the AWS Serverless Application Repository verified by AWS?"}, {"role": "assistant", "content": "All applications published by AWS are vetted for license adherence and code quality. Applications published by third parties are validated for correct use of permissions to ensure that consumers know which resources can be modified or accessed by an application. You can review those details, along with the number of times an application has been deployed by AWS customers, prior to using an application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I use the AWS Serverless Application Repository in combination with GitHub?"}, {"role": "assistant", "content": "Yes. The AWS Serverless Application Repository enables developers to publish serverless applications developed in a GitHub repository. Using\u00a0[AWS CodePipeline](https://web.archive.org/web/20240727090753/https://aws.amazon.com/documentation/codepipeline/)\u00a0to link a GitHub source with the AWS Serverless Application Repository can make the publishing process even easier, and the process can be set up in minutes."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I manage serverless applications deployed to my account?"}, {"role": "assistant", "content": "Serverless applications are deployed as\u00a0[AWS CloudFormation](https://web.archive.org/web/20240727090753/https://aws.amazon.com/documentation/cloudformation/)\u00a0stacks, which make it easy for you to manage an application as a single unit. Each resource is tagged with the application\u2019s uniquely identifiable Amazon Resource Name (ARN), which helps you locate the resources using the AWS Tag Editor console. You can also use existing AWS and third-party tools to manage each resource separately."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I publish a serverless application to the AWS Serverless Application Repository?"}, {"role": "assistant", "content": "To publish a serverless application, describe the application using the AWS Serverless Application Model (SAM) format, package it using the AWS CLI, and publish it using the AWS Management Console, AWS CLI, or AWS SDKs. You must have a valid AWS account, and you will be required to provide a name, description, source code link, and a LICENSE.txt for your application. Applications that are intended to be made available to any AWS customer must be published in either the US East (N. Virginia) or US East (Ohio) regions."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Who can deploy the applications I publish to the AWS Serverless Application Repository?"}, {"role": "assistant", "content": "Publishers control who can find and deploy their applications in the Repository. You can limit access to your team (a group under the same AWS account), share an application with other accounts, or make it publicly available to any AWS customer. To learn more about the permissions and visibility of applications you publish, review our\u00a0[Resource-Based Policies documentation](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I charge a fee for serverless applications I publish?"}, {"role": "assistant", "content": "If you would like to charge a fee for the use of a serverless application, you can integrate AWS Lambda behind Amazon API Gateway, and then sell the API as a SaaS product through the AWS Marketplace. To learn more, review the steps to\u00a0[list on AWS Marketplace](https://web.archive.org/web/20240727090753/https://aws.amazon.com/marketplace/management/tour/)\u00a0and how to\u00a0[monetize your API using API Gateway](https://web.archive.org/web/20240727090753/https://aws.amazon.com/blogs/compute/monetize-your-apis-in-aws-marketplace-using-api-gateway/)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What is a nested application?"}, {"role": "assistant", "content": "A nested serverless application is a component that is deployed as part of another serverless application. As serverless architectures grow, common patterns emerge in which the same components are defined in multiple application templates. You can now separate out common patterns as dedicated applications and then nest them as part of new or existing application templates."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How are nested applications deployed?"}, {"role": "assistant", "content": "Nested applications are deployed as\u00a0[AWS CloudFormation nested stacks](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I include a nested application in my SAM template?"}, {"role": "assistant", "content": "Use the AWS:Serverless:Application resource type to add applications that you have developed locally or that have been shared with you via the Serverless Application Repository. You can define inputs for the nested application or reference outputs using simple AWS SAM syntax. For more details, see our\u00a0[documentation](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-nested-applications.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I handle resource name conflicts when nesting applications?"}, {"role": "assistant", "content": "Specify a unique name for each nested application in your SAM template. Resources created by the nested application will be scoped to the application's unique name."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I package a nested application?"}, {"role": "assistant", "content": "Use the SAM CLI\u00a0sam package\u00a0command to package your nested application. Publish your packaged application to the Serverless Application Repository using APIs or the AWS SDK. You can use the SAM CLI\u00a0sam deploy\u00a0command to deploy your application immediately."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I package a hierarchy of nested applications using SAM CLI?"}, {"role": "assistant", "content": "Yes. The SAM CLI\u00a0sam package\u00a0command will recursively package a hierarchy of nested applications. You can have a maximum of 199 applications nested in a single top-level application template."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I manage serverless applications deployed to my account?"}, {"role": "assistant", "content": "Serverless applications are deployed as\u00a0[AWS CloudFormation](https://web.archive.org/web/20240727090753/https://aws.amazon.com/documentation/cloudformation/)\u00a0stacks, which make it easy for you to manage an application as a single unit. Each resource is tagged with the application\u2019s uniquely identifiable Amazon Resource Name (ARN), which helps you locate the resources using the AWS Tag Editor console. You can also use existing AWS and third-party tools to manage each resource separately."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I nest applications shared with me via the Serverless Application Repository?"}, {"role": "assistant", "content": "Configure the AWS:Serverless:Application SAM resource with the application ARN and any necessary input parameters required by the application. For more details, see our\u00a0[documentation](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-nested-applications.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I package a nested app that I used from the Serverless Application Repository?"}, {"role": "assistant", "content": "Nested applications from the Serverless Application Repository are already packaged and ready for you to use. You can use the existing SAM CLI\u00a0sam package\u00a0command to ensure that nested applications are still available to you before you deploy the application in your account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "What happens if an application that I nested is no longer available?"}, {"role": "assistant", "content": "Applications that you nest which get deleted or that you no longer have access to will have no impact on the existing deployments of your application. You will be required to update your application if you attempt to deploy it with dependencies that no longer exist."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How can I tell if an application contains other nested applications?"}, {"role": "assistant", "content": "Applications that contain one or more nested applications use CAPABILITY_AUTO_EXPAND."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I publish nested applications to the Serverless Application Repository?"}, {"role": "assistant", "content": "Yes. You can publish nested applications to the Serverless Application Repository just like you publish stand-alone applications today. Use the AWS console, AWS CLI, SAM CLI, or Serverless Application Repository APIs to publish nested applications."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I share an application that contains nested applications?"}, {"role": "assistant", "content": "Serverless applications follow the same model used by Lambda functions today. Access to serverless applications in the Serverless Application Repository can be controlled using\u00a0[AWS IAM resource-based policies](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_identity-vs-resource.html). You can use policies to keep your application private, grant cross-account access, or make it publicly available."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How does sharing work when there is a hierarchy of nested applications?"}, {"role": "assistant", "content": "With a hierarchy of nested applications, each nested application has to be made available to the AWS account with whom you are sharing the top-level application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I share applications with all accounts that belong to an AWS Organization?"}, {"role": "assistant", "content": "Yes. You can now share application with all accounts that belong to an AWS Organization. Serverless apps follow the same model used by Lambda functions today. Access to serverless applications in the AWS Serverless Application Repository can be controlled using AWS IAM resource-based policies. You can use policies to keep your app private, grant cross-account access, grant organization access or make it available publicly. To learn more about resource-based policies for serverless applications, see\u00a0[here](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I update resource-based policies to share an app with an AWS organization?"}, {"role": "assistant", "content": "To get started, find the application in the AWS Serverless Application Repository console, click on the \u2018Share\u2019 tab and then click on \u2018Create Statement\u2019. Here you can add the AWS Organization principal to grant the organization with access to the app. You can also use the AWS Serverless Application Repository APIs to update resource-based policies to share apps across an organization. For more details on resource based polices, see our documentation\u00a0[here](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I share an application with multiple AWS Organizations?"}, {"role": "assistant", "content": "No. You can share an application only with accounts that belong to the same AWS Organization as your account."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I share an application with a particular organizational unit within my organization?"}, {"role": "assistant", "content": "Sharing of applications within an organizational unit isn\u2019t supported. You can use policies to keep your app private, grant cross-account access, grant organization access or make it available publicly."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "How do I share an application with specific accounts in an organization?"}, {"role": "assistant", "content": "To provide access to your application for certain accounts in an organization, simply update the resource-based policy to include AWS accounts along with the AWS organization ID with whom you would like to share the application."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "Can I update permissions for an organization to only view an application?"}, {"role": "assistant", "content": "Yes. You can set actions on your resource-based policy which can restrict the type of operations someone can take on an application that you have shared. Updating actions for a resource-based policy is supported through the AWS Serverless Application Repository APIs and console. For more details on actions you can set for resource-based polices, see our documentation\u00a0[here](https://web.archive.org/web/20240727090753/https://docs.aws.amazon.com/lambda/latest/dg/access-control-resource-based.html)."}]}
{"messages": [{"role": "system", "content": "You are an assistant for question-answering tasks about amazon web service."}, {"role": "user", "content": "User terms"}, {"role": "assistant", "content": "1. Publishers, who are AWS customers, may submit their AWS serverless applications and components (\u201cAWS Serverless Applications\u201d) to be made available through the AWS Serverless Application repository (\u201cRepository\u201d) either privately, across specified AWS accounts or to all AWS customers using the Repository pursuant to the Repository console publication process. AWS Serverless Applications to be made available either privately or across specified AWS accounts may be in binary or source code form; AWS Serverless Applications made available to all AWS customers may be in binary or source code form, and must include sufficient details to enable the user access to the source code.2. Publishers must have all licenses and necessary permissions or rights to submit their AWS Serverless Applications to the Repository. Publisher must submit to the Repository, along with its AWS Serverless Application, the terms of the AWS Serverless Application\u2019s license(s), including any open source license attribution requirements. Publisher is responsible for reviewing, evaluating and testing any AWS Serverless Application before submitting it to the Repository.3. Publisher hereby grants AWS and its affiliates the rights to reproduce, distribute, display publicly or within specified AWS accounts (as applicable), perform, transmit, use and otherwise digitally make available (via all means of online and electronic distribution) its AWS Serverless Applications in the Repository.4. Publisher represents and warrants it has all rights to submit its AWS Serverless Application to the Repository, has all rights to allow downloading of its AWS Serverless Application from the Repository and has provided all required attributions. Publisher will not submit AWS Serverless Applications with malware, malicious or other harmful content with the intent or purpose to harm others. AWS may remove and take down any AWS Serverless Application in the sole discretion of AWS for this or other reasons.5. AWS customers will comply with the license(s) (including any attribution or other requirements) for any AWS Serverless Application they download.6. Any AWS customer who creates a derivative work of any AWS Serverless Application is responsible for determining whether it has the appropriate rights under the AWS Serverless Application\u2019s license(s) to do so and must comply with any attribution or other requirements.7. Any Publisher\u2019s AWS Serverless Application license or other agreement is solely between the Publisher and AWS customers. Neither AWS nor any of its affiliates are a party to that license or other agreement and none of them will have any liability or obligations under that license or other agreement. AWS is not responsible and has no liability for ensuring that Publishers or AWS customers comply with licensing (including attribution) or other requirements.8. AWS Serverless Applications and any other third-party materials available in the Repository are \u201cRepository Content.\u201d THE Repository Content IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL PUBLISHERS, COPYRIGHT HOLDERS, AWS OR ITS AFFILIATES BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE Repository Content OR THE USE OR OTHER DEALINGS IN THE Repository Content.9. Publishers and AWS customers acknowledge they will comply with all of these terms in their use of the Repository and these terms may be updated by AWS from time to time."}]}